{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44b44666",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered S3 method overwritten by 'quantmod':\n",
      "  method            from\n",
      "  as.zoo.data.frame zoo \n",
      "\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tsfeatures)\n",
    "library(imputeTS)\n",
    "library(forecast)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f7fb81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b287d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=read.csv('Imports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b6b30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 47</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>月份</th><th scope=col>日本</th><th scope=col>经合组织成员国</th><th scope=col>OECD成员国_欧洲</th><th scope=col>OECD和六个非成员经济体</th><th scope=col>主要亚洲五国.OECD.</th><th scope=col>瑞士</th><th scope=col>韩国</th><th scope=col>土耳其</th><th scope=col>比利时</th><th scope=col>⋯</th><th scope=col>中华人民共和国</th><th scope=col>南非</th><th scope=col>哥伦比亚</th><th scope=col>墨西哥</th><th scope=col>新西兰</th><th scope=col>以色列</th><th scope=col>哥斯达黎加</th><th scope=col>欧元区</th><th scope=col>俄罗斯</th><th scope=col>爱尔兰</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1995-01</td><td>100.86</td><td>100.98</td><td>100.79</td><td>100.34</td><td>100.74</td><td>99.21</td><td>NA</td><td>NA</td><td>100.50</td><td>⋯</td><td>101.44</td><td>101.91</td><td>NA</td><td>NA</td><td>101.35</td><td>NA</td><td>NA</td><td>100.62</td><td>NA</td><td>102.04</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1995-02</td><td>100.60</td><td>100.85</td><td>100.73</td><td>100.26</td><td>100.78</td><td>98.84</td><td>NA</td><td>NA</td><td>100.42</td><td>⋯</td><td>101.95</td><td>101.79</td><td>NA</td><td>NA</td><td>101.32</td><td>NA</td><td>NA</td><td>100.56</td><td>NA</td><td>102.02</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>1995-03</td><td>100.34</td><td>100.71</td><td>100.69</td><td>100.15</td><td>100.80</td><td>98.80</td><td>NA</td><td>NA</td><td>100.46</td><td>⋯</td><td>102.36</td><td>101.73</td><td>NA</td><td>NA</td><td>101.38</td><td>NA</td><td>NA</td><td>100.57</td><td>NA</td><td>101.89</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1995-04</td><td>100.14</td><td>100.66</td><td>100.75</td><td>100.11</td><td>100.79</td><td>98.97</td><td>NA</td><td>NA</td><td>100.47</td><td>⋯</td><td>102.63</td><td>101.73</td><td>NA</td><td>NA</td><td>101.55</td><td>NA</td><td>NA</td><td>100.67</td><td>NA</td><td>101.70</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>1995-05</td><td>100.05</td><td>100.69</td><td>100.85</td><td>100.12</td><td>100.77</td><td>99.18</td><td>NA</td><td>NA</td><td>100.46</td><td>⋯</td><td>102.72</td><td>101.78</td><td>NA</td><td>NA</td><td>101.77</td><td>NA</td><td>NA</td><td>100.78</td><td>NA</td><td>101.67</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>1995-06</td><td>100.04</td><td>100.78</td><td>100.97</td><td>100.18</td><td>100.73</td><td>99.33</td><td>NA</td><td>NA</td><td>100.44</td><td>⋯</td><td>102.63</td><td>101.83</td><td>NA</td><td>NA</td><td>101.94</td><td>NA</td><td>NA</td><td>100.80</td><td>NA</td><td>101.76</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 47\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & 月份 & 日本 & 经合组织成员国 & OECD成员国\\_欧洲 & OECD和六个非成员经济体 & 主要亚洲五国.OECD. & 瑞士 & 韩国 & 土耳其 & 比利时 & ⋯ & 中华人民共和国 & 南非 & 哥伦比亚 & 墨西哥 & 新西兰 & 以色列 & 哥斯达黎加 & 欧元区 & 俄罗斯 & 爱尔兰\\\\\n",
       "  & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 1995-01 & 100.86 & 100.98 & 100.79 & 100.34 & 100.74 & 99.21 & NA & NA & 100.50 & ⋯ & 101.44 & 101.91 & NA & NA & 101.35 & NA & NA & 100.62 & NA & 102.04\\\\\n",
       "\t2 & 1995-02 & 100.60 & 100.85 & 100.73 & 100.26 & 100.78 & 98.84 & NA & NA & 100.42 & ⋯ & 101.95 & 101.79 & NA & NA & 101.32 & NA & NA & 100.56 & NA & 102.02\\\\\n",
       "\t3 & 1995-03 & 100.34 & 100.71 & 100.69 & 100.15 & 100.80 & 98.80 & NA & NA & 100.46 & ⋯ & 102.36 & 101.73 & NA & NA & 101.38 & NA & NA & 100.57 & NA & 101.89\\\\\n",
       "\t4 & 1995-04 & 100.14 & 100.66 & 100.75 & 100.11 & 100.79 & 98.97 & NA & NA & 100.47 & ⋯ & 102.63 & 101.73 & NA & NA & 101.55 & NA & NA & 100.67 & NA & 101.70\\\\\n",
       "\t5 & 1995-05 & 100.05 & 100.69 & 100.85 & 100.12 & 100.77 & 99.18 & NA & NA & 100.46 & ⋯ & 102.72 & 101.78 & NA & NA & 101.77 & NA & NA & 100.78 & NA & 101.67\\\\\n",
       "\t6 & 1995-06 & 100.04 & 100.78 & 100.97 & 100.18 & 100.73 & 99.33 & NA & NA & 100.44 & ⋯ & 102.63 & 101.83 & NA & NA & 101.94 & NA & NA & 100.80 & NA & 101.76\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 47\n",
       "\n",
       "| <!--/--> | 月份 &lt;chr&gt; | 日本 &lt;dbl&gt; | 经合组织成员国 &lt;dbl&gt; | OECD成员国_欧洲 &lt;dbl&gt; | OECD和六个非成员经济体 &lt;dbl&gt; | 主要亚洲五国.OECD. &lt;dbl&gt; | 瑞士 &lt;dbl&gt; | 韩国 &lt;dbl&gt; | 土耳其 &lt;dbl&gt; | 比利时 &lt;dbl&gt; | ⋯ ⋯ | 中华人民共和国 &lt;dbl&gt; | 南非 &lt;dbl&gt; | 哥伦比亚 &lt;dbl&gt; | 墨西哥 &lt;dbl&gt; | 新西兰 &lt;dbl&gt; | 以色列 &lt;dbl&gt; | 哥斯达黎加 &lt;dbl&gt; | 欧元区 &lt;dbl&gt; | 俄罗斯 &lt;dbl&gt; | 爱尔兰 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1995-01 | 100.86 | 100.98 | 100.79 | 100.34 | 100.74 | 99.21 | NA | NA | 100.50 | ⋯ | 101.44 | 101.91 | NA | NA | 101.35 | NA | NA | 100.62 | NA | 102.04 |\n",
       "| 2 | 1995-02 | 100.60 | 100.85 | 100.73 | 100.26 | 100.78 | 98.84 | NA | NA | 100.42 | ⋯ | 101.95 | 101.79 | NA | NA | 101.32 | NA | NA | 100.56 | NA | 102.02 |\n",
       "| 3 | 1995-03 | 100.34 | 100.71 | 100.69 | 100.15 | 100.80 | 98.80 | NA | NA | 100.46 | ⋯ | 102.36 | 101.73 | NA | NA | 101.38 | NA | NA | 100.57 | NA | 101.89 |\n",
       "| 4 | 1995-04 | 100.14 | 100.66 | 100.75 | 100.11 | 100.79 | 98.97 | NA | NA | 100.47 | ⋯ | 102.63 | 101.73 | NA | NA | 101.55 | NA | NA | 100.67 | NA | 101.70 |\n",
       "| 5 | 1995-05 | 100.05 | 100.69 | 100.85 | 100.12 | 100.77 | 99.18 | NA | NA | 100.46 | ⋯ | 102.72 | 101.78 | NA | NA | 101.77 | NA | NA | 100.78 | NA | 101.67 |\n",
       "| 6 | 1995-06 | 100.04 | 100.78 | 100.97 | 100.18 | 100.73 | 99.33 | NA | NA | 100.44 | ⋯ | 102.63 | 101.83 | NA | NA | 101.94 | NA | NA | 100.80 | NA | 101.76 |\n",
       "\n"
      ],
      "text/plain": [
       "  月份    日本   经合组织成员国 OECD成员国_欧洲 OECD和六个非成员经济体\n",
       "1 1995-01 100.86 100.98         100.79          100.34                \n",
       "2 1995-02 100.60 100.85         100.73          100.26                \n",
       "3 1995-03 100.34 100.71         100.69          100.15                \n",
       "4 1995-04 100.14 100.66         100.75          100.11                \n",
       "5 1995-05 100.05 100.69         100.85          100.12                \n",
       "6 1995-06 100.04 100.78         100.97          100.18                \n",
       "  主要亚洲五国.OECD. 瑞士  韩国 土耳其 比利时 ⋯ 中华人民共和国 南非   哥伦比亚\n",
       "1 100.74             99.21 NA   NA     100.50 ⋯ 101.44         101.91 NA      \n",
       "2 100.78             98.84 NA   NA     100.42 ⋯ 101.95         101.79 NA      \n",
       "3 100.80             98.80 NA   NA     100.46 ⋯ 102.36         101.73 NA      \n",
       "4 100.79             98.97 NA   NA     100.47 ⋯ 102.63         101.73 NA      \n",
       "5 100.77             99.18 NA   NA     100.46 ⋯ 102.72         101.78 NA      \n",
       "6 100.73             99.33 NA   NA     100.44 ⋯ 102.63         101.83 NA      \n",
       "  墨西哥 新西兰 以色列 哥斯达黎加 欧元区 俄罗斯 爱尔兰\n",
       "1 NA     101.35 NA     NA         100.62 NA     102.04\n",
       "2 NA     101.32 NA     NA         100.56 NA     102.02\n",
       "3 NA     101.38 NA     NA         100.57 NA     101.89\n",
       "4 NA     101.55 NA     NA         100.67 NA     101.70\n",
       "5 NA     101.77 NA     NA         100.78 NA     101.67\n",
       "6 NA     101.94 NA     NA         100.80 NA     101.76"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f4015a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 47</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>月份</th><th scope=col>日本</th><th scope=col>经合组织成员国</th><th scope=col>OECD成员国_欧洲</th><th scope=col>OECD和六个非成员经济体</th><th scope=col>主要亚洲五国.OECD.</th><th scope=col>瑞士</th><th scope=col>韩国</th><th scope=col>土耳其</th><th scope=col>比利时</th><th scope=col>⋯</th><th scope=col>中华人民共和国</th><th scope=col>南非</th><th scope=col>哥伦比亚</th><th scope=col>墨西哥</th><th scope=col>新西兰</th><th scope=col>以色列</th><th scope=col>哥斯达黎加</th><th scope=col>欧元区</th><th scope=col>俄罗斯</th><th scope=col>爱尔兰</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>341</th><td>2023-05</td><td>98.40</td><td>98.30</td><td>98.63</td><td>97.17</td><td>95.11</td><td>96.91</td><td> 99.64</td><td>99.75</td><td>99.31</td><td>⋯</td><td>93.33</td><td>96.46</td><td>95.95</td><td>103.91</td><td>96.67</td><td>97.84</td><td>101.81</td><td>98.16</td><td>99.61</td><td>NA</td></tr>\n",
       "\t<tr><th scope=row>342</th><td>2023-06</td><td>98.53</td><td>98.49</td><td>98.73</td><td>97.21</td><td>94.89</td><td>96.99</td><td>100.02</td><td>98.74</td><td>99.40</td><td>⋯</td><td>92.96</td><td>96.54</td><td>96.52</td><td>104.36</td><td>96.79</td><td>97.71</td><td>102.00</td><td>98.39</td><td>   NA</td><td>NA</td></tr>\n",
       "\t<tr><th scope=row>343</th><td>2023-07</td><td>98.57</td><td>98.59</td><td>98.61</td><td>97.26</td><td>94.81</td><td>97.04</td><td>100.26</td><td>96.99</td><td>99.56</td><td>⋯</td><td>92.84</td><td>96.85</td><td>96.68</td><td>104.87</td><td>96.78</td><td>97.74</td><td>102.38</td><td>   NA</td><td>   NA</td><td>NA</td></tr>\n",
       "\t<tr><th scope=row>344</th><td>2023-08</td><td>98.48</td><td>98.50</td><td>98.36</td><td>97.22</td><td>94.82</td><td>96.93</td><td>100.24</td><td>95.26</td><td>99.63</td><td>⋯</td><td>92.88</td><td>97.28</td><td>96.64</td><td>105.27</td><td>96.70</td><td>97.62</td><td>102.82</td><td>   NA</td><td>   NA</td><td>NA</td></tr>\n",
       "\t<tr><th scope=row>345</th><td>2023-09</td><td>98.35</td><td>98.33</td><td>98.13</td><td>97.14</td><td>94.86</td><td>96.56</td><td> 99.99</td><td>94.77</td><td>99.60</td><td>⋯</td><td>93.00</td><td>97.76</td><td>96.59</td><td>105.55</td><td>96.58</td><td>   NA</td><td>    NA</td><td>   NA</td><td>   NA</td><td>NA</td></tr>\n",
       "\t<tr><th scope=row>346</th><td>2023-10</td><td>98.27</td><td>98.09</td><td>97.90</td><td>96.90</td><td>   NA</td><td>96.02</td><td> 99.69</td><td>94.95</td><td>99.55</td><td>⋯</td><td>   NA</td><td>   NA</td><td>   NA</td><td>    NA</td><td>   NA</td><td>   NA</td><td>    NA</td><td>   NA</td><td>   NA</td><td>NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 47\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & 月份 & 日本 & 经合组织成员国 & OECD成员国\\_欧洲 & OECD和六个非成员经济体 & 主要亚洲五国.OECD. & 瑞士 & 韩国 & 土耳其 & 比利时 & ⋯ & 中华人民共和国 & 南非 & 哥伦比亚 & 墨西哥 & 新西兰 & 以色列 & 哥斯达黎加 & 欧元区 & 俄罗斯 & 爱尔兰\\\\\n",
       "  & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t341 & 2023-05 & 98.40 & 98.30 & 98.63 & 97.17 & 95.11 & 96.91 &  99.64 & 99.75 & 99.31 & ⋯ & 93.33 & 96.46 & 95.95 & 103.91 & 96.67 & 97.84 & 101.81 & 98.16 & 99.61 & NA\\\\\n",
       "\t342 & 2023-06 & 98.53 & 98.49 & 98.73 & 97.21 & 94.89 & 96.99 & 100.02 & 98.74 & 99.40 & ⋯ & 92.96 & 96.54 & 96.52 & 104.36 & 96.79 & 97.71 & 102.00 & 98.39 &    NA & NA\\\\\n",
       "\t343 & 2023-07 & 98.57 & 98.59 & 98.61 & 97.26 & 94.81 & 97.04 & 100.26 & 96.99 & 99.56 & ⋯ & 92.84 & 96.85 & 96.68 & 104.87 & 96.78 & 97.74 & 102.38 &    NA &    NA & NA\\\\\n",
       "\t344 & 2023-08 & 98.48 & 98.50 & 98.36 & 97.22 & 94.82 & 96.93 & 100.24 & 95.26 & 99.63 & ⋯ & 92.88 & 97.28 & 96.64 & 105.27 & 96.70 & 97.62 & 102.82 &    NA &    NA & NA\\\\\n",
       "\t345 & 2023-09 & 98.35 & 98.33 & 98.13 & 97.14 & 94.86 & 96.56 &  99.99 & 94.77 & 99.60 & ⋯ & 93.00 & 97.76 & 96.59 & 105.55 & 96.58 &    NA &     NA &    NA &    NA & NA\\\\\n",
       "\t346 & 2023-10 & 98.27 & 98.09 & 97.90 & 96.90 &    NA & 96.02 &  99.69 & 94.95 & 99.55 & ⋯ &    NA &    NA &    NA &     NA &    NA &    NA &     NA &    NA &    NA & NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 47\n",
       "\n",
       "| <!--/--> | 月份 &lt;chr&gt; | 日本 &lt;dbl&gt; | 经合组织成员国 &lt;dbl&gt; | OECD成员国_欧洲 &lt;dbl&gt; | OECD和六个非成员经济体 &lt;dbl&gt; | 主要亚洲五国.OECD. &lt;dbl&gt; | 瑞士 &lt;dbl&gt; | 韩国 &lt;dbl&gt; | 土耳其 &lt;dbl&gt; | 比利时 &lt;dbl&gt; | ⋯ ⋯ | 中华人民共和国 &lt;dbl&gt; | 南非 &lt;dbl&gt; | 哥伦比亚 &lt;dbl&gt; | 墨西哥 &lt;dbl&gt; | 新西兰 &lt;dbl&gt; | 以色列 &lt;dbl&gt; | 哥斯达黎加 &lt;dbl&gt; | 欧元区 &lt;dbl&gt; | 俄罗斯 &lt;dbl&gt; | 爱尔兰 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 341 | 2023-05 | 98.40 | 98.30 | 98.63 | 97.17 | 95.11 | 96.91 |  99.64 | 99.75 | 99.31 | ⋯ | 93.33 | 96.46 | 95.95 | 103.91 | 96.67 | 97.84 | 101.81 | 98.16 | 99.61 | NA |\n",
       "| 342 | 2023-06 | 98.53 | 98.49 | 98.73 | 97.21 | 94.89 | 96.99 | 100.02 | 98.74 | 99.40 | ⋯ | 92.96 | 96.54 | 96.52 | 104.36 | 96.79 | 97.71 | 102.00 | 98.39 |    NA | NA |\n",
       "| 343 | 2023-07 | 98.57 | 98.59 | 98.61 | 97.26 | 94.81 | 97.04 | 100.26 | 96.99 | 99.56 | ⋯ | 92.84 | 96.85 | 96.68 | 104.87 | 96.78 | 97.74 | 102.38 |    NA |    NA | NA |\n",
       "| 344 | 2023-08 | 98.48 | 98.50 | 98.36 | 97.22 | 94.82 | 96.93 | 100.24 | 95.26 | 99.63 | ⋯ | 92.88 | 97.28 | 96.64 | 105.27 | 96.70 | 97.62 | 102.82 |    NA |    NA | NA |\n",
       "| 345 | 2023-09 | 98.35 | 98.33 | 98.13 | 97.14 | 94.86 | 96.56 |  99.99 | 94.77 | 99.60 | ⋯ | 93.00 | 97.76 | 96.59 | 105.55 | 96.58 |    NA |     NA |    NA |    NA | NA |\n",
       "| 346 | 2023-10 | 98.27 | 98.09 | 97.90 | 96.90 |    NA | 96.02 |  99.69 | 94.95 | 99.55 | ⋯ |    NA |    NA |    NA |     NA |    NA |    NA |     NA |    NA |    NA | NA |\n",
       "\n"
      ],
      "text/plain": [
       "    月份    日本  经合组织成员国 OECD成员国_欧洲 OECD和六个非成员经济体\n",
       "341 2023-05 98.40 98.30          98.63           97.17                 \n",
       "342 2023-06 98.53 98.49          98.73           97.21                 \n",
       "343 2023-07 98.57 98.59          98.61           97.26                 \n",
       "344 2023-08 98.48 98.50          98.36           97.22                 \n",
       "345 2023-09 98.35 98.33          98.13           97.14                 \n",
       "346 2023-10 98.27 98.09          97.90           96.90                 \n",
       "    主要亚洲五国.OECD. 瑞士  韩国   土耳其 比利时 ⋯ 中华人民共和国 南非 \n",
       "341 95.11              96.91  99.64 99.75  99.31  ⋯ 93.33          96.46\n",
       "342 94.89              96.99 100.02 98.74  99.40  ⋯ 92.96          96.54\n",
       "343 94.81              97.04 100.26 96.99  99.56  ⋯ 92.84          96.85\n",
       "344 94.82              96.93 100.24 95.26  99.63  ⋯ 92.88          97.28\n",
       "345 94.86              96.56  99.99 94.77  99.60  ⋯ 93.00          97.76\n",
       "346    NA              96.02  99.69 94.95  99.55  ⋯    NA             NA\n",
       "    哥伦比亚 墨西哥 新西兰 以色列 哥斯达黎加 欧元区 俄罗斯 爱尔兰\n",
       "341 95.95    103.91 96.67  97.84  101.81     98.16  99.61  NA    \n",
       "342 96.52    104.36 96.79  97.71  102.00     98.39     NA  NA    \n",
       "343 96.68    104.87 96.78  97.74  102.38        NA     NA  NA    \n",
       "344 96.64    105.27 96.70  97.62  102.82        NA     NA  NA    \n",
       "345 96.59    105.55 96.58     NA      NA        NA     NA  NA    \n",
       "346    NA        NA    NA     NA      NA        NA     NA  NA    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tail(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d56a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[1:285,c(2:dim(data)[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a3092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f1a8f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>345</li><li>46</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 345\n",
       "\\item 46\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 345\n",
       "2. 46\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 345  46"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78dce697",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_baddata=function(data){\n",
    "baddata=c()\n",
    "for(i in 1:dim(data)[2])\n",
    "{loc=min(which(is.na(data[,i])==FALSE))-1\n",
    "if((dim(data)[1]-loc)<40)\n",
    "    {\n",
    "    baddata=append(baddata,i)\n",
    "}\n",
    "if(sum(is.na(data[loc:dim(data)[1],i])==TRUE)>10)\n",
    " {\n",
    "     baddata=append(baddata,i)\n",
    " }\n",
    " if(sum(is.na(data[(dim(data)[1]-11):dim(data)[1],i])==TRUE)>3)\n",
    " {\n",
    "     baddata=append(baddata,i)\n",
    " }\n",
    "}\n",
    "baddata=unique(baddata)\n",
    "return(baddata)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "750cb9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "baddata=which_baddata(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10158836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>45</li><li>46</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 45\n",
       "\\item 46\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 45\n",
       "2. 46\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 45 46"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6676f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[,-1*baddata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d181bb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f579aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 345 × 44</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>日本</th><th scope=col>经合组织成员国</th><th scope=col>OECD成员国_欧洲</th><th scope=col>OECD和六个非成员经济体</th><th scope=col>主要亚洲五国.OECD.</th><th scope=col>瑞士</th><th scope=col>韩国</th><th scope=col>土耳其</th><th scope=col>比利时</th><th scope=col>丹麦</th><th scope=col>⋯</th><th scope=col>西方七国</th><th scope=col>印尼</th><th scope=col>中华人民共和国</th><th scope=col>南非</th><th scope=col>哥伦比亚</th><th scope=col>墨西哥</th><th scope=col>新西兰</th><th scope=col>以色列</th><th scope=col>哥斯达黎加</th><th scope=col>欧元区</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>100.86</td><td>100.98</td><td>100.79</td><td>100.34</td><td>100.74</td><td>99.21</td><td>NA</td><td>NA</td><td>100.50</td><td>101.19</td><td>⋯</td><td>100.79</td><td>NA</td><td>101.44</td><td>101.91</td><td>NA</td><td>NA</td><td>101.35</td><td>NA</td><td>NA</td><td>100.62</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>100.60</td><td>100.85</td><td>100.73</td><td>100.26</td><td>100.78</td><td>98.84</td><td>NA</td><td>NA</td><td>100.42</td><td>101.24</td><td>⋯</td><td>100.67</td><td>NA</td><td>101.95</td><td>101.79</td><td>NA</td><td>NA</td><td>101.32</td><td>NA</td><td>NA</td><td>100.56</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>100.34</td><td>100.71</td><td>100.69</td><td>100.15</td><td>100.80</td><td>98.80</td><td>NA</td><td>NA</td><td>100.46</td><td>101.22</td><td>⋯</td><td>100.51</td><td>NA</td><td>102.36</td><td>101.73</td><td>NA</td><td>NA</td><td>101.38</td><td>NA</td><td>NA</td><td>100.57</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>100.14</td><td>100.66</td><td>100.75</td><td>100.11</td><td>100.79</td><td>98.97</td><td>NA</td><td>NA</td><td>100.47</td><td>101.16</td><td>⋯</td><td>100.46</td><td>NA</td><td>102.63</td><td>101.73</td><td>NA</td><td>NA</td><td>101.55</td><td>NA</td><td>NA</td><td>100.67</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>100.05</td><td>100.69</td><td>100.85</td><td>100.12</td><td>100.77</td><td>99.18</td><td>NA</td><td>NA</td><td>100.46</td><td>101.09</td><td>⋯</td><td>100.49</td><td>NA</td><td>102.72</td><td>101.78</td><td>NA</td><td>NA</td><td>101.77</td><td>NA</td><td>NA</td><td>100.78</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>100.04</td><td>100.78</td><td>100.97</td><td>100.18</td><td>100.73</td><td>99.33</td><td>NA</td><td>NA</td><td>100.44</td><td>101.01</td><td>⋯</td><td>100.60</td><td>NA</td><td>102.63</td><td>101.83</td><td>NA</td><td>NA</td><td>101.94</td><td>NA</td><td>NA</td><td>100.80</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>100.10</td><td>100.86</td><td>101.00</td><td>100.21</td><td>100.68</td><td>99.41</td><td>NA</td><td>NA</td><td>100.27</td><td>101.03</td><td>⋯</td><td>100.69</td><td>NA</td><td>102.40</td><td>101.89</td><td>NA</td><td>NA</td><td>102.02</td><td>NA</td><td>NA</td><td>100.72</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>100.24</td><td>100.83</td><td>100.94</td><td>100.17</td><td>100.65</td><td>99.46</td><td>NA</td><td>NA</td><td> 99.91</td><td>101.13</td><td>⋯</td><td>100.66</td><td>NA</td><td>102.14</td><td>101.95</td><td>NA</td><td>NA</td><td>102.01</td><td>NA</td><td>NA</td><td>100.56</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>100.41</td><td>100.70</td><td>100.80</td><td>100.03</td><td>100.66</td><td>99.47</td><td>NA</td><td>NA</td><td> 99.50</td><td>101.18</td><td>⋯</td><td>100.50</td><td>NA</td><td>101.93</td><td>102.03</td><td>NA</td><td>NA</td><td>101.93</td><td>NA</td><td>NA</td><td>100.34</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>100.57</td><td>100.58</td><td>100.64</td><td> 99.93</td><td>100.71</td><td>99.42</td><td>NA</td><td>NA</td><td> 99.01</td><td>101.16</td><td>⋯</td><td>100.37</td><td>NA</td><td>101.81</td><td>102.13</td><td>NA</td><td>NA</td><td>101.81</td><td>NA</td><td>NA</td><td>100.10</td></tr>\n",
       "\t<tr><th scope=row>11</th><td>100.70</td><td>100.50</td><td>100.49</td><td> 99.86</td><td>100.79</td><td>99.27</td><td>NA</td><td>NA</td><td> 98.54</td><td>101.17</td><td>⋯</td><td>100.28</td><td>NA</td><td>101.81</td><td>102.21</td><td>NA</td><td>NA</td><td>101.71</td><td>NA</td><td>NA</td><td> 99.89</td></tr>\n",
       "\t<tr><th scope=row>12</th><td>100.80</td><td>100.48</td><td>100.36</td><td> 99.86</td><td>100.89</td><td>98.97</td><td>NA</td><td>NA</td><td> 98.35</td><td>101.09</td><td>⋯</td><td>100.25</td><td>NA</td><td>101.91</td><td>102.22</td><td>NA</td><td>NA</td><td>101.70</td><td>NA</td><td>NA</td><td> 99.67</td></tr>\n",
       "\t<tr><th scope=row>13</th><td>100.90</td><td>100.48</td><td>100.28</td><td> 99.88</td><td>101.00</td><td>98.59</td><td>NA</td><td>NA</td><td> 98.30</td><td>100.99</td><td>⋯</td><td>100.25</td><td>NA</td><td>102.05</td><td>102.11</td><td>NA</td><td>NA</td><td>101.85</td><td>NA</td><td>NA</td><td> 99.50</td></tr>\n",
       "\t<tr><th scope=row>14</th><td>100.99</td><td>100.52</td><td>100.23</td><td> 99.93</td><td>101.10</td><td>98.22</td><td>NA</td><td>NA</td><td> 98.36</td><td>100.78</td><td>⋯</td><td>100.30</td><td>NA</td><td>102.16</td><td>101.91</td><td>NA</td><td>NA</td><td>102.00</td><td>NA</td><td>NA</td><td> 99.41</td></tr>\n",
       "\t<tr><th scope=row>15</th><td>101.06</td><td>100.61</td><td>100.25</td><td>100.01</td><td>101.16</td><td>97.91</td><td>NA</td><td>NA</td><td> 98.51</td><td>100.66</td><td>⋯</td><td>100.41</td><td>NA</td><td>102.19</td><td>101.67</td><td>NA</td><td>NA</td><td>101.97</td><td>NA</td><td>NA</td><td> 99.40</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>101.10</td><td>100.63</td><td>100.27</td><td>100.03</td><td>101.17</td><td>97.66</td><td>NA</td><td>NA</td><td> 98.66</td><td>100.61</td><td>⋯</td><td>100.45</td><td>NA</td><td>102.16</td><td>101.41</td><td>NA</td><td>NA</td><td>101.62</td><td>NA</td><td>NA</td><td> 99.40</td></tr>\n",
       "\t<tr><th scope=row>17</th><td>101.07</td><td>100.62</td><td>100.28</td><td>100.01</td><td>101.13</td><td>97.46</td><td>NA</td><td>NA</td><td> 98.69</td><td>100.50</td><td>⋯</td><td>100.44</td><td>NA</td><td>102.11</td><td>101.18</td><td>NA</td><td>NA</td><td>101.14</td><td>NA</td><td>NA</td><td> 99.43</td></tr>\n",
       "\t<tr><th scope=row>18</th><td>101.00</td><td>100.65</td><td>100.28</td><td>100.02</td><td>101.06</td><td>97.32</td><td>NA</td><td>NA</td><td> 98.75</td><td>100.41</td><td>⋯</td><td>100.48</td><td>NA</td><td>102.04</td><td>101.03</td><td>NA</td><td>NA</td><td>100.80</td><td>NA</td><td>NA</td><td> 99.44</td></tr>\n",
       "\t<tr><th scope=row>19</th><td>100.92</td><td>100.69</td><td>100.26</td><td>100.05</td><td>100.99</td><td>97.26</td><td>NA</td><td>NA</td><td> 98.90</td><td>100.43</td><td>⋯</td><td>100.54</td><td>NA</td><td>102.00</td><td>101.02</td><td>NA</td><td>NA</td><td>100.82</td><td>NA</td><td>NA</td><td> 99.42</td></tr>\n",
       "\t<tr><th scope=row>20</th><td>100.82</td><td>100.73</td><td>100.29</td><td>100.09</td><td>100.92</td><td>97.32</td><td>NA</td><td>NA</td><td> 99.14</td><td>100.47</td><td>⋯</td><td>100.58</td><td>NA</td><td>101.95</td><td>101.10</td><td>NA</td><td>NA</td><td>101.04</td><td>NA</td><td>NA</td><td> 99.43</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>100.68</td><td>100.75</td><td>100.32</td><td>100.11</td><td>100.83</td><td>97.58</td><td>NA</td><td>NA</td><td> 99.30</td><td>100.66</td><td>⋯</td><td>100.59</td><td>NA</td><td>101.93</td><td>101.20</td><td>NA</td><td>NA</td><td>101.28</td><td>NA</td><td>NA</td><td> 99.42</td></tr>\n",
       "\t<tr><th scope=row>22</th><td>100.42</td><td>100.76</td><td>100.31</td><td>100.12</td><td>100.66</td><td>97.92</td><td>NA</td><td>NA</td><td> 99.35</td><td>100.85</td><td>⋯</td><td>100.57</td><td>NA</td><td>101.88</td><td>101.28</td><td>NA</td><td>NA</td><td>101.41</td><td>NA</td><td>NA</td><td> 99.38</td></tr>\n",
       "\t<tr><th scope=row>23</th><td> 99.99</td><td>100.74</td><td>100.33</td><td>100.10</td><td>100.34</td><td>98.22</td><td>NA</td><td>NA</td><td> 99.38</td><td>100.91</td><td>⋯</td><td>100.53</td><td>NA</td><td>101.72</td><td>101.32</td><td>NA</td><td>NA</td><td>101.43</td><td>NA</td><td>NA</td><td> 99.36</td></tr>\n",
       "\t<tr><th scope=row>24</th><td> 99.55</td><td>100.71</td><td>100.38</td><td>100.04</td><td> 99.91</td><td>98.39</td><td>NA</td><td>NA</td><td> 99.27</td><td>100.98</td><td>⋯</td><td>100.48</td><td>NA</td><td>101.29</td><td>101.29</td><td>NA</td><td>NA</td><td>101.36</td><td>NA</td><td>NA</td><td> 99.42</td></tr>\n",
       "\t<tr><th scope=row>25</th><td> 99.28</td><td>100.74</td><td>100.47</td><td>100.01</td><td> 99.45</td><td>98.48</td><td>NA</td><td>NA</td><td> 98.99</td><td>101.12</td><td>⋯</td><td>100.49</td><td>NA</td><td>100.58</td><td>101.15</td><td>NA</td><td>NA</td><td>101.20</td><td>NA</td><td>NA</td><td> 99.52</td></tr>\n",
       "\t<tr><th scope=row>26</th><td> 99.36</td><td>100.82</td><td>100.52</td><td>100.03</td><td> 99.28</td><td>98.55</td><td>NA</td><td>NA</td><td> 98.81</td><td>101.20</td><td>⋯</td><td>100.59</td><td>NA</td><td>100.08</td><td>101.00</td><td>NA</td><td>NA</td><td>100.99</td><td>NA</td><td>NA</td><td> 99.52</td></tr>\n",
       "\t<tr><th scope=row>27</th><td> 99.65</td><td>100.94</td><td>100.55</td><td>100.11</td><td> 99.34</td><td>98.65</td><td>NA</td><td>NA</td><td> 98.73</td><td>101.23</td><td>⋯</td><td>100.72</td><td>NA</td><td> 99.84</td><td>100.91</td><td>NA</td><td>NA</td><td>100.78</td><td>NA</td><td>NA</td><td> 99.53</td></tr>\n",
       "\t<tr><th scope=row>28</th><td> 99.96</td><td>101.09</td><td>100.63</td><td>100.23</td><td> 99.52</td><td>98.80</td><td>NA</td><td>NA</td><td> 98.76</td><td>101.12</td><td>⋯</td><td>100.89</td><td>NA</td><td> 99.84</td><td>100.95</td><td>NA</td><td>NA</td><td>100.59</td><td>NA</td><td>NA</td><td> 99.61</td></tr>\n",
       "\t<tr><th scope=row>29</th><td>100.17</td><td>101.26</td><td>100.78</td><td>100.37</td><td> 99.70</td><td>99.03</td><td>NA</td><td>NA</td><td> 98.92</td><td>100.95</td><td>⋯</td><td>101.09</td><td>NA</td><td> 99.98</td><td>101.03</td><td>NA</td><td>NA</td><td>100.42</td><td>NA</td><td>NA</td><td> 99.76</td></tr>\n",
       "\t<tr><th scope=row>30</th><td>100.25</td><td>101.42</td><td>100.94</td><td>100.51</td><td> 99.82</td><td>99.38</td><td>NA</td><td>NA</td><td> 99.14</td><td>101.01</td><td>⋯</td><td>101.25</td><td>NA</td><td>100.17</td><td>101.01</td><td>NA</td><td>NA</td><td>100.28</td><td>NA</td><td>NA</td><td> 99.97</td></tr>\n",
       "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋱</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><th scope=row>316</th><td>98.21</td><td>100.04</td><td>100.37</td><td>100.68</td><td>102.12</td><td> 99.62</td><td>100.36</td><td>97.88</td><td>101.52</td><td>101.23</td><td>⋯</td><td> 99.99</td><td> 99.65</td><td>103.71</td><td>98.67</td><td>95.25</td><td>101.58</td><td>99.62</td><td>102.69</td><td> 97.96</td><td>100.57</td></tr>\n",
       "\t<tr><th scope=row>317</th><td>98.32</td><td>100.29</td><td>100.87</td><td>100.82</td><td>102.03</td><td>100.08</td><td>100.72</td><td>97.37</td><td>101.90</td><td>101.38</td><td>⋯</td><td>100.22</td><td> 99.77</td><td>103.51</td><td>98.50</td><td>95.11</td><td>102.31</td><td>99.66</td><td>102.87</td><td> 97.89</td><td>101.31</td></tr>\n",
       "\t<tr><th scope=row>318</th><td>98.55</td><td>100.45</td><td>101.23</td><td>100.86</td><td>101.87</td><td>100.66</td><td>100.89</td><td>97.34</td><td>102.15</td><td>101.45</td><td>⋯</td><td>100.33</td><td> 99.46</td><td>103.25</td><td>98.40</td><td>96.01</td><td>102.87</td><td>99.66</td><td>102.54</td><td> 98.17</td><td>101.86</td></tr>\n",
       "\t<tr><th scope=row>319</th><td>98.72</td><td>100.35</td><td>101.29</td><td>100.68</td><td>101.53</td><td>101.23</td><td>100.70</td><td>97.23</td><td>102.08</td><td>101.50</td><td>⋯</td><td>100.15</td><td> 98.82</td><td>102.81</td><td>98.44</td><td>97.27</td><td>103.05</td><td>99.57</td><td>101.81</td><td> 98.63</td><td>101.95</td></tr>\n",
       "\t<tr><th scope=row>320</th><td>98.83</td><td>100.10</td><td>101.15</td><td>100.47</td><td>101.44</td><td>101.63</td><td>100.56</td><td>97.04</td><td>101.77</td><td>101.57</td><td>⋯</td><td> 99.81</td><td> 98.71</td><td>102.69</td><td>98.56</td><td>98.14</td><td>102.98</td><td>99.42</td><td>101.01</td><td> 99.06</td><td>101.85</td></tr>\n",
       "\t<tr><th scope=row>321</th><td>98.98</td><td> 99.93</td><td>100.93</td><td>100.42</td><td>101.69</td><td>101.71</td><td>100.62</td><td>96.71</td><td>101.44</td><td>101.58</td><td>⋯</td><td> 99.60</td><td> 99.36</td><td>102.92</td><td>98.70</td><td>98.72</td><td>103.16</td><td>99.25</td><td>100.99</td><td> 99.29</td><td>101.72</td></tr>\n",
       "\t<tr><th scope=row>322</th><td>99.15</td><td> 99.75</td><td>100.56</td><td>100.35</td><td>101.92</td><td>101.59</td><td>100.79</td><td>95.96</td><td>100.97</td><td>101.21</td><td>⋯</td><td> 99.42</td><td>100.26</td><td>103.08</td><td>98.80</td><td>98.93</td><td>103.53</td><td>99.10</td><td>100.79</td><td> 99.41</td><td>101.41</td></tr>\n",
       "\t<tr><th scope=row>323</th><td>99.21</td><td> 99.52</td><td>100.13</td><td>100.25</td><td>102.09</td><td>101.37</td><td>100.84</td><td>95.04</td><td>100.54</td><td>100.70</td><td>⋯</td><td> 99.24</td><td>100.86</td><td>103.22</td><td>98.85</td><td>98.72</td><td>103.89</td><td>98.95</td><td>100.19</td><td> 99.56</td><td>100.98</td></tr>\n",
       "\t<tr><th scope=row>324</th><td>99.04</td><td> 99.28</td><td> 99.76</td><td>100.14</td><td>102.17</td><td>101.07</td><td>100.72</td><td>94.57</td><td>100.20</td><td>100.36</td><td>⋯</td><td> 99.03</td><td>101.07</td><td>103.36</td><td>98.84</td><td>98.11</td><td>103.57</td><td>98.77</td><td> 99.49</td><td> 99.82</td><td>100.57</td></tr>\n",
       "\t<tr><th scope=row>325</th><td>98.66</td><td> 98.95</td><td> 99.34</td><td> 99.88</td><td>101.99</td><td>100.68</td><td>100.61</td><td>94.63</td><td> 99.84</td><td> 99.99</td><td>⋯</td><td> 98.67</td><td>101.01</td><td>103.20</td><td>98.71</td><td>97.36</td><td>103.07</td><td>98.53</td><td> 98.66</td><td>100.11</td><td>100.09</td></tr>\n",
       "\t<tr><th scope=row>326</th><td>98.19</td><td> 98.48</td><td> 98.66</td><td> 99.27</td><td>101.05</td><td>100.09</td><td>100.54</td><td>94.58</td><td> 99.30</td><td> 99.31</td><td>⋯</td><td> 98.15</td><td>100.81</td><td>101.97</td><td>98.47</td><td>96.81</td><td>102.86</td><td>98.23</td><td> 98.25</td><td>100.30</td><td> 99.21</td></tr>\n",
       "\t<tr><th scope=row>327</th><td>97.74</td><td> 97.94</td><td> 97.67</td><td> 98.21</td><td> 99.07</td><td> 99.22</td><td>100.50</td><td>94.30</td><td> 98.55</td><td> 98.16</td><td>⋯</td><td> 97.60</td><td>100.76</td><td> 99.21</td><td>98.11</td><td>96.65</td><td>102.94</td><td>97.85</td><td> 98.22</td><td>100.27</td><td> 97.83</td></tr>\n",
       "\t<tr><th scope=row>328</th><td>97.50</td><td> 97.54</td><td> 96.93</td><td> 97.04</td><td> 96.57</td><td> 98.21</td><td>100.38</td><td>93.64</td><td> 98.23</td><td> 97.24</td><td>⋯</td><td> 97.22</td><td>101.01</td><td> 95.62</td><td>97.58</td><td>96.91</td><td>103.01</td><td>97.38</td><td> 98.41</td><td>100.11</td><td> 96.96</td></tr>\n",
       "\t<tr><th scope=row>329</th><td>97.38</td><td> 97.16</td><td> 96.49</td><td> 96.31</td><td> 95.21</td><td> 97.23</td><td> 99.99</td><td>93.13</td><td> 98.16</td><td> 96.72</td><td>⋯</td><td> 96.83</td><td>101.44</td><td> 93.65</td><td>97.04</td><td>97.57</td><td>102.77</td><td>96.94</td><td> 98.39</td><td> 99.92</td><td> 96.48</td></tr>\n",
       "\t<tr><th scope=row>330</th><td>97.22</td><td> 96.79</td><td> 96.14</td><td> 95.96</td><td> 94.76</td><td> 96.41</td><td> 99.29</td><td>92.94</td><td> 98.11</td><td> 96.45</td><td>⋯</td><td> 96.47</td><td>101.63</td><td> 93.07</td><td>96.67</td><td>98.33</td><td>102.14</td><td>96.70</td><td> 97.76</td><td> 99.77</td><td> 96.03</td></tr>\n",
       "\t<tr><th scope=row>331</th><td>97.09</td><td> 96.58</td><td> 95.89</td><td> 95.84</td><td> 94.62</td><td> 95.73</td><td> 98.58</td><td>93.51</td><td> 97.93</td><td> 96.36</td><td>⋯</td><td> 96.32</td><td>101.57</td><td> 92.97</td><td>96.65</td><td>98.40</td><td>101.40</td><td>96.79</td><td> 97.32</td><td> 99.71</td><td> 95.62</td></tr>\n",
       "\t<tr><th scope=row>332</th><td>97.09</td><td> 96.59</td><td> 95.76</td><td> 95.88</td><td> 94.57</td><td> 95.19</td><td> 98.34</td><td>94.39</td><td> 97.58</td><td> 96.27</td><td>⋯</td><td> 96.37</td><td>101.42</td><td> 92.94</td><td>96.89</td><td>98.21</td><td>100.98</td><td>97.01</td><td> 97.43</td><td> 99.81</td><td> 95.42</td></tr>\n",
       "\t<tr><th scope=row>333</th><td>97.00</td><td> 96.61</td><td> 95.68</td><td> 95.91</td><td> 94.52</td><td> 94.83</td><td> 98.32</td><td>95.13</td><td> 97.11</td><td> 95.94</td><td>⋯</td><td> 96.40</td><td>101.22</td><td> 92.92</td><td>97.32</td><td>97.50</td><td>100.96</td><td>97.10</td><td> 97.64</td><td>100.14</td><td> 95.26</td></tr>\n",
       "\t<tr><th scope=row>334</th><td>96.89</td><td> 96.71</td><td> 95.86</td><td> 95.97</td><td> 94.47</td><td> 94.67</td><td> 98.25</td><td>95.77</td><td> 97.11</td><td> 95.78</td><td>⋯</td><td> 96.49</td><td>101.15</td><td> 92.89</td><td>97.88</td><td>96.62</td><td>101.24</td><td>96.90</td><td> 98.07</td><td>100.61</td><td> 95.50</td></tr>\n",
       "\t<tr><th scope=row>335</th><td>96.85</td><td> 96.89</td><td> 96.25</td><td> 96.13</td><td> 94.56</td><td> 94.78</td><td> 98.21</td><td>96.14</td><td> 97.59</td><td> 96.11</td><td>⋯</td><td> 96.64</td><td>101.15</td><td> 93.04</td><td>98.38</td><td>95.93</td><td>101.80</td><td>96.53</td><td> 98.42</td><td>101.13</td><td> 96.08</td></tr>\n",
       "\t<tr><th scope=row>336</th><td>96.94</td><td> 97.16</td><td> 96.67</td><td> 96.45</td><td> 94.98</td><td> 95.26</td><td> 98.32</td><td>96.45</td><td> 98.23</td><td> 96.58</td><td>⋯</td><td> 96.89</td><td>101.22</td><td> 93.59</td><td>98.57</td><td>95.55</td><td>102.50</td><td>96.22</td><td> 98.30</td><td>101.62</td><td> 96.66</td></tr>\n",
       "\t<tr><th scope=row>337</th><td>97.10</td><td> 97.47</td><td> 97.07</td><td> 96.84</td><td> 95.52</td><td> 95.90</td><td> 98.44</td><td>97.05</td><td> 98.79</td><td> 97.05</td><td>⋯</td><td> 97.16</td><td>101.32</td><td> 94.33</td><td>98.21</td><td>95.20</td><td>103.20</td><td>96.10</td><td> 98.03</td><td>102.01</td><td> 97.14</td></tr>\n",
       "\t<tr><th scope=row>338</th><td>97.36</td><td> 97.72</td><td> 97.47</td><td> 97.15</td><td> 95.93</td><td> 96.45</td><td> 98.57</td><td>97.79</td><td> 99.16</td><td> 97.41</td><td>⋯</td><td> 97.38</td><td>101.41</td><td> 94.83</td><td>97.57</td><td>95.05</td><td>103.59</td><td>96.15</td><td> 98.01</td><td>102.20</td><td> 97.49</td></tr>\n",
       "\t<tr><th scope=row>339</th><td>97.76</td><td> 97.90</td><td> 97.85</td><td> 97.23</td><td> 95.90</td><td> 96.73</td><td> 98.82</td><td>98.52</td><td> 99.30</td><td> 97.77</td><td>⋯</td><td> 97.52</td><td>101.52</td><td> 94.66</td><td>96.96</td><td>95.08</td><td>103.66</td><td>96.29</td><td> 97.91</td><td>102.10</td><td> 97.72</td></tr>\n",
       "\t<tr><th scope=row>340</th><td>98.14</td><td> 98.11</td><td> 98.29</td><td> 97.18</td><td> 95.44</td><td> 96.84</td><td> 99.21</td><td>99.47</td><td> 99.35</td><td> 98.19</td><td>⋯</td><td> 97.66</td><td>101.64</td><td> 93.89</td><td>96.60</td><td>95.37</td><td>103.68</td><td>96.48</td><td> 97.88</td><td>101.90</td><td> 97.95</td></tr>\n",
       "\t<tr><th scope=row>341</th><td>98.40</td><td> 98.30</td><td> 98.63</td><td> 97.17</td><td> 95.11</td><td> 96.91</td><td> 99.64</td><td>99.75</td><td> 99.31</td><td> 98.59</td><td>⋯</td><td> 97.80</td><td>101.72</td><td> 93.33</td><td>96.46</td><td>95.95</td><td>103.91</td><td>96.67</td><td> 97.84</td><td>101.81</td><td> 98.16</td></tr>\n",
       "\t<tr><th scope=row>342</th><td>98.53</td><td> 98.49</td><td> 98.73</td><td> 97.21</td><td> 94.89</td><td> 96.99</td><td>100.02</td><td>98.74</td><td> 99.40</td><td> 98.85</td><td>⋯</td><td> 98.02</td><td>101.69</td><td> 92.96</td><td>96.54</td><td>96.52</td><td>104.36</td><td>96.79</td><td> 97.71</td><td>102.00</td><td> 98.39</td></tr>\n",
       "\t<tr><th scope=row>343</th><td>98.57</td><td> 98.59</td><td> 98.61</td><td> 97.26</td><td> 94.81</td><td> 97.04</td><td>100.26</td><td>96.99</td><td> 99.56</td><td> 98.91</td><td>⋯</td><td> 98.20</td><td>101.59</td><td> 92.84</td><td>96.85</td><td>96.68</td><td>104.87</td><td>96.78</td><td> 97.74</td><td>102.38</td><td>    NA</td></tr>\n",
       "\t<tr><th scope=row>344</th><td>98.48</td><td> 98.50</td><td> 98.36</td><td> 97.22</td><td> 94.82</td><td> 96.93</td><td>100.24</td><td>95.26</td><td> 99.63</td><td> 98.82</td><td>⋯</td><td> 98.20</td><td>101.50</td><td> 92.88</td><td>97.28</td><td>96.64</td><td>105.27</td><td>96.70</td><td> 97.62</td><td>102.82</td><td>    NA</td></tr>\n",
       "\t<tr><th scope=row>345</th><td>98.35</td><td> 98.33</td><td> 98.13</td><td> 97.14</td><td> 94.86</td><td> 96.56</td><td> 99.99</td><td>94.77</td><td> 99.60</td><td> 98.66</td><td>⋯</td><td> 98.04</td><td>101.36</td><td> 93.00</td><td>97.76</td><td>96.59</td><td>105.55</td><td>96.58</td><td>    NA</td><td>    NA</td><td>    NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 345 × 44\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & 日本 & 经合组织成员国 & OECD成员国\\_欧洲 & OECD和六个非成员经济体 & 主要亚洲五国.OECD. & 瑞士 & 韩国 & 土耳其 & 比利时 & 丹麦 & ⋯ & 西方七国 & 印尼 & 中华人民共和国 & 南非 & 哥伦比亚 & 墨西哥 & 新西兰 & 以色列 & 哥斯达黎加 & 欧元区\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 100.86 & 100.98 & 100.79 & 100.34 & 100.74 & 99.21 & NA & NA & 100.50 & 101.19 & ⋯ & 100.79 & NA & 101.44 & 101.91 & NA & NA & 101.35 & NA & NA & 100.62\\\\\n",
       "\t2 & 100.60 & 100.85 & 100.73 & 100.26 & 100.78 & 98.84 & NA & NA & 100.42 & 101.24 & ⋯ & 100.67 & NA & 101.95 & 101.79 & NA & NA & 101.32 & NA & NA & 100.56\\\\\n",
       "\t3 & 100.34 & 100.71 & 100.69 & 100.15 & 100.80 & 98.80 & NA & NA & 100.46 & 101.22 & ⋯ & 100.51 & NA & 102.36 & 101.73 & NA & NA & 101.38 & NA & NA & 100.57\\\\\n",
       "\t4 & 100.14 & 100.66 & 100.75 & 100.11 & 100.79 & 98.97 & NA & NA & 100.47 & 101.16 & ⋯ & 100.46 & NA & 102.63 & 101.73 & NA & NA & 101.55 & NA & NA & 100.67\\\\\n",
       "\t5 & 100.05 & 100.69 & 100.85 & 100.12 & 100.77 & 99.18 & NA & NA & 100.46 & 101.09 & ⋯ & 100.49 & NA & 102.72 & 101.78 & NA & NA & 101.77 & NA & NA & 100.78\\\\\n",
       "\t6 & 100.04 & 100.78 & 100.97 & 100.18 & 100.73 & 99.33 & NA & NA & 100.44 & 101.01 & ⋯ & 100.60 & NA & 102.63 & 101.83 & NA & NA & 101.94 & NA & NA & 100.80\\\\\n",
       "\t7 & 100.10 & 100.86 & 101.00 & 100.21 & 100.68 & 99.41 & NA & NA & 100.27 & 101.03 & ⋯ & 100.69 & NA & 102.40 & 101.89 & NA & NA & 102.02 & NA & NA & 100.72\\\\\n",
       "\t8 & 100.24 & 100.83 & 100.94 & 100.17 & 100.65 & 99.46 & NA & NA &  99.91 & 101.13 & ⋯ & 100.66 & NA & 102.14 & 101.95 & NA & NA & 102.01 & NA & NA & 100.56\\\\\n",
       "\t9 & 100.41 & 100.70 & 100.80 & 100.03 & 100.66 & 99.47 & NA & NA &  99.50 & 101.18 & ⋯ & 100.50 & NA & 101.93 & 102.03 & NA & NA & 101.93 & NA & NA & 100.34\\\\\n",
       "\t10 & 100.57 & 100.58 & 100.64 &  99.93 & 100.71 & 99.42 & NA & NA &  99.01 & 101.16 & ⋯ & 100.37 & NA & 101.81 & 102.13 & NA & NA & 101.81 & NA & NA & 100.10\\\\\n",
       "\t11 & 100.70 & 100.50 & 100.49 &  99.86 & 100.79 & 99.27 & NA & NA &  98.54 & 101.17 & ⋯ & 100.28 & NA & 101.81 & 102.21 & NA & NA & 101.71 & NA & NA &  99.89\\\\\n",
       "\t12 & 100.80 & 100.48 & 100.36 &  99.86 & 100.89 & 98.97 & NA & NA &  98.35 & 101.09 & ⋯ & 100.25 & NA & 101.91 & 102.22 & NA & NA & 101.70 & NA & NA &  99.67\\\\\n",
       "\t13 & 100.90 & 100.48 & 100.28 &  99.88 & 101.00 & 98.59 & NA & NA &  98.30 & 100.99 & ⋯ & 100.25 & NA & 102.05 & 102.11 & NA & NA & 101.85 & NA & NA &  99.50\\\\\n",
       "\t14 & 100.99 & 100.52 & 100.23 &  99.93 & 101.10 & 98.22 & NA & NA &  98.36 & 100.78 & ⋯ & 100.30 & NA & 102.16 & 101.91 & NA & NA & 102.00 & NA & NA &  99.41\\\\\n",
       "\t15 & 101.06 & 100.61 & 100.25 & 100.01 & 101.16 & 97.91 & NA & NA &  98.51 & 100.66 & ⋯ & 100.41 & NA & 102.19 & 101.67 & NA & NA & 101.97 & NA & NA &  99.40\\\\\n",
       "\t16 & 101.10 & 100.63 & 100.27 & 100.03 & 101.17 & 97.66 & NA & NA &  98.66 & 100.61 & ⋯ & 100.45 & NA & 102.16 & 101.41 & NA & NA & 101.62 & NA & NA &  99.40\\\\\n",
       "\t17 & 101.07 & 100.62 & 100.28 & 100.01 & 101.13 & 97.46 & NA & NA &  98.69 & 100.50 & ⋯ & 100.44 & NA & 102.11 & 101.18 & NA & NA & 101.14 & NA & NA &  99.43\\\\\n",
       "\t18 & 101.00 & 100.65 & 100.28 & 100.02 & 101.06 & 97.32 & NA & NA &  98.75 & 100.41 & ⋯ & 100.48 & NA & 102.04 & 101.03 & NA & NA & 100.80 & NA & NA &  99.44\\\\\n",
       "\t19 & 100.92 & 100.69 & 100.26 & 100.05 & 100.99 & 97.26 & NA & NA &  98.90 & 100.43 & ⋯ & 100.54 & NA & 102.00 & 101.02 & NA & NA & 100.82 & NA & NA &  99.42\\\\\n",
       "\t20 & 100.82 & 100.73 & 100.29 & 100.09 & 100.92 & 97.32 & NA & NA &  99.14 & 100.47 & ⋯ & 100.58 & NA & 101.95 & 101.10 & NA & NA & 101.04 & NA & NA &  99.43\\\\\n",
       "\t21 & 100.68 & 100.75 & 100.32 & 100.11 & 100.83 & 97.58 & NA & NA &  99.30 & 100.66 & ⋯ & 100.59 & NA & 101.93 & 101.20 & NA & NA & 101.28 & NA & NA &  99.42\\\\\n",
       "\t22 & 100.42 & 100.76 & 100.31 & 100.12 & 100.66 & 97.92 & NA & NA &  99.35 & 100.85 & ⋯ & 100.57 & NA & 101.88 & 101.28 & NA & NA & 101.41 & NA & NA &  99.38\\\\\n",
       "\t23 &  99.99 & 100.74 & 100.33 & 100.10 & 100.34 & 98.22 & NA & NA &  99.38 & 100.91 & ⋯ & 100.53 & NA & 101.72 & 101.32 & NA & NA & 101.43 & NA & NA &  99.36\\\\\n",
       "\t24 &  99.55 & 100.71 & 100.38 & 100.04 &  99.91 & 98.39 & NA & NA &  99.27 & 100.98 & ⋯ & 100.48 & NA & 101.29 & 101.29 & NA & NA & 101.36 & NA & NA &  99.42\\\\\n",
       "\t25 &  99.28 & 100.74 & 100.47 & 100.01 &  99.45 & 98.48 & NA & NA &  98.99 & 101.12 & ⋯ & 100.49 & NA & 100.58 & 101.15 & NA & NA & 101.20 & NA & NA &  99.52\\\\\n",
       "\t26 &  99.36 & 100.82 & 100.52 & 100.03 &  99.28 & 98.55 & NA & NA &  98.81 & 101.20 & ⋯ & 100.59 & NA & 100.08 & 101.00 & NA & NA & 100.99 & NA & NA &  99.52\\\\\n",
       "\t27 &  99.65 & 100.94 & 100.55 & 100.11 &  99.34 & 98.65 & NA & NA &  98.73 & 101.23 & ⋯ & 100.72 & NA &  99.84 & 100.91 & NA & NA & 100.78 & NA & NA &  99.53\\\\\n",
       "\t28 &  99.96 & 101.09 & 100.63 & 100.23 &  99.52 & 98.80 & NA & NA &  98.76 & 101.12 & ⋯ & 100.89 & NA &  99.84 & 100.95 & NA & NA & 100.59 & NA & NA &  99.61\\\\\n",
       "\t29 & 100.17 & 101.26 & 100.78 & 100.37 &  99.70 & 99.03 & NA & NA &  98.92 & 100.95 & ⋯ & 101.09 & NA &  99.98 & 101.03 & NA & NA & 100.42 & NA & NA &  99.76\\\\\n",
       "\t30 & 100.25 & 101.42 & 100.94 & 100.51 &  99.82 & 99.38 & NA & NA &  99.14 & 101.01 & ⋯ & 101.25 & NA & 100.17 & 101.01 & NA & NA & 100.28 & NA & NA &  99.97\\\\\n",
       "\t⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t316 & 98.21 & 100.04 & 100.37 & 100.68 & 102.12 &  99.62 & 100.36 & 97.88 & 101.52 & 101.23 & ⋯ &  99.99 &  99.65 & 103.71 & 98.67 & 95.25 & 101.58 & 99.62 & 102.69 &  97.96 & 100.57\\\\\n",
       "\t317 & 98.32 & 100.29 & 100.87 & 100.82 & 102.03 & 100.08 & 100.72 & 97.37 & 101.90 & 101.38 & ⋯ & 100.22 &  99.77 & 103.51 & 98.50 & 95.11 & 102.31 & 99.66 & 102.87 &  97.89 & 101.31\\\\\n",
       "\t318 & 98.55 & 100.45 & 101.23 & 100.86 & 101.87 & 100.66 & 100.89 & 97.34 & 102.15 & 101.45 & ⋯ & 100.33 &  99.46 & 103.25 & 98.40 & 96.01 & 102.87 & 99.66 & 102.54 &  98.17 & 101.86\\\\\n",
       "\t319 & 98.72 & 100.35 & 101.29 & 100.68 & 101.53 & 101.23 & 100.70 & 97.23 & 102.08 & 101.50 & ⋯ & 100.15 &  98.82 & 102.81 & 98.44 & 97.27 & 103.05 & 99.57 & 101.81 &  98.63 & 101.95\\\\\n",
       "\t320 & 98.83 & 100.10 & 101.15 & 100.47 & 101.44 & 101.63 & 100.56 & 97.04 & 101.77 & 101.57 & ⋯ &  99.81 &  98.71 & 102.69 & 98.56 & 98.14 & 102.98 & 99.42 & 101.01 &  99.06 & 101.85\\\\\n",
       "\t321 & 98.98 &  99.93 & 100.93 & 100.42 & 101.69 & 101.71 & 100.62 & 96.71 & 101.44 & 101.58 & ⋯ &  99.60 &  99.36 & 102.92 & 98.70 & 98.72 & 103.16 & 99.25 & 100.99 &  99.29 & 101.72\\\\\n",
       "\t322 & 99.15 &  99.75 & 100.56 & 100.35 & 101.92 & 101.59 & 100.79 & 95.96 & 100.97 & 101.21 & ⋯ &  99.42 & 100.26 & 103.08 & 98.80 & 98.93 & 103.53 & 99.10 & 100.79 &  99.41 & 101.41\\\\\n",
       "\t323 & 99.21 &  99.52 & 100.13 & 100.25 & 102.09 & 101.37 & 100.84 & 95.04 & 100.54 & 100.70 & ⋯ &  99.24 & 100.86 & 103.22 & 98.85 & 98.72 & 103.89 & 98.95 & 100.19 &  99.56 & 100.98\\\\\n",
       "\t324 & 99.04 &  99.28 &  99.76 & 100.14 & 102.17 & 101.07 & 100.72 & 94.57 & 100.20 & 100.36 & ⋯ &  99.03 & 101.07 & 103.36 & 98.84 & 98.11 & 103.57 & 98.77 &  99.49 &  99.82 & 100.57\\\\\n",
       "\t325 & 98.66 &  98.95 &  99.34 &  99.88 & 101.99 & 100.68 & 100.61 & 94.63 &  99.84 &  99.99 & ⋯ &  98.67 & 101.01 & 103.20 & 98.71 & 97.36 & 103.07 & 98.53 &  98.66 & 100.11 & 100.09\\\\\n",
       "\t326 & 98.19 &  98.48 &  98.66 &  99.27 & 101.05 & 100.09 & 100.54 & 94.58 &  99.30 &  99.31 & ⋯ &  98.15 & 100.81 & 101.97 & 98.47 & 96.81 & 102.86 & 98.23 &  98.25 & 100.30 &  99.21\\\\\n",
       "\t327 & 97.74 &  97.94 &  97.67 &  98.21 &  99.07 &  99.22 & 100.50 & 94.30 &  98.55 &  98.16 & ⋯ &  97.60 & 100.76 &  99.21 & 98.11 & 96.65 & 102.94 & 97.85 &  98.22 & 100.27 &  97.83\\\\\n",
       "\t328 & 97.50 &  97.54 &  96.93 &  97.04 &  96.57 &  98.21 & 100.38 & 93.64 &  98.23 &  97.24 & ⋯ &  97.22 & 101.01 &  95.62 & 97.58 & 96.91 & 103.01 & 97.38 &  98.41 & 100.11 &  96.96\\\\\n",
       "\t329 & 97.38 &  97.16 &  96.49 &  96.31 &  95.21 &  97.23 &  99.99 & 93.13 &  98.16 &  96.72 & ⋯ &  96.83 & 101.44 &  93.65 & 97.04 & 97.57 & 102.77 & 96.94 &  98.39 &  99.92 &  96.48\\\\\n",
       "\t330 & 97.22 &  96.79 &  96.14 &  95.96 &  94.76 &  96.41 &  99.29 & 92.94 &  98.11 &  96.45 & ⋯ &  96.47 & 101.63 &  93.07 & 96.67 & 98.33 & 102.14 & 96.70 &  97.76 &  99.77 &  96.03\\\\\n",
       "\t331 & 97.09 &  96.58 &  95.89 &  95.84 &  94.62 &  95.73 &  98.58 & 93.51 &  97.93 &  96.36 & ⋯ &  96.32 & 101.57 &  92.97 & 96.65 & 98.40 & 101.40 & 96.79 &  97.32 &  99.71 &  95.62\\\\\n",
       "\t332 & 97.09 &  96.59 &  95.76 &  95.88 &  94.57 &  95.19 &  98.34 & 94.39 &  97.58 &  96.27 & ⋯ &  96.37 & 101.42 &  92.94 & 96.89 & 98.21 & 100.98 & 97.01 &  97.43 &  99.81 &  95.42\\\\\n",
       "\t333 & 97.00 &  96.61 &  95.68 &  95.91 &  94.52 &  94.83 &  98.32 & 95.13 &  97.11 &  95.94 & ⋯ &  96.40 & 101.22 &  92.92 & 97.32 & 97.50 & 100.96 & 97.10 &  97.64 & 100.14 &  95.26\\\\\n",
       "\t334 & 96.89 &  96.71 &  95.86 &  95.97 &  94.47 &  94.67 &  98.25 & 95.77 &  97.11 &  95.78 & ⋯ &  96.49 & 101.15 &  92.89 & 97.88 & 96.62 & 101.24 & 96.90 &  98.07 & 100.61 &  95.50\\\\\n",
       "\t335 & 96.85 &  96.89 &  96.25 &  96.13 &  94.56 &  94.78 &  98.21 & 96.14 &  97.59 &  96.11 & ⋯ &  96.64 & 101.15 &  93.04 & 98.38 & 95.93 & 101.80 & 96.53 &  98.42 & 101.13 &  96.08\\\\\n",
       "\t336 & 96.94 &  97.16 &  96.67 &  96.45 &  94.98 &  95.26 &  98.32 & 96.45 &  98.23 &  96.58 & ⋯ &  96.89 & 101.22 &  93.59 & 98.57 & 95.55 & 102.50 & 96.22 &  98.30 & 101.62 &  96.66\\\\\n",
       "\t337 & 97.10 &  97.47 &  97.07 &  96.84 &  95.52 &  95.90 &  98.44 & 97.05 &  98.79 &  97.05 & ⋯ &  97.16 & 101.32 &  94.33 & 98.21 & 95.20 & 103.20 & 96.10 &  98.03 & 102.01 &  97.14\\\\\n",
       "\t338 & 97.36 &  97.72 &  97.47 &  97.15 &  95.93 &  96.45 &  98.57 & 97.79 &  99.16 &  97.41 & ⋯ &  97.38 & 101.41 &  94.83 & 97.57 & 95.05 & 103.59 & 96.15 &  98.01 & 102.20 &  97.49\\\\\n",
       "\t339 & 97.76 &  97.90 &  97.85 &  97.23 &  95.90 &  96.73 &  98.82 & 98.52 &  99.30 &  97.77 & ⋯ &  97.52 & 101.52 &  94.66 & 96.96 & 95.08 & 103.66 & 96.29 &  97.91 & 102.10 &  97.72\\\\\n",
       "\t340 & 98.14 &  98.11 &  98.29 &  97.18 &  95.44 &  96.84 &  99.21 & 99.47 &  99.35 &  98.19 & ⋯ &  97.66 & 101.64 &  93.89 & 96.60 & 95.37 & 103.68 & 96.48 &  97.88 & 101.90 &  97.95\\\\\n",
       "\t341 & 98.40 &  98.30 &  98.63 &  97.17 &  95.11 &  96.91 &  99.64 & 99.75 &  99.31 &  98.59 & ⋯ &  97.80 & 101.72 &  93.33 & 96.46 & 95.95 & 103.91 & 96.67 &  97.84 & 101.81 &  98.16\\\\\n",
       "\t342 & 98.53 &  98.49 &  98.73 &  97.21 &  94.89 &  96.99 & 100.02 & 98.74 &  99.40 &  98.85 & ⋯ &  98.02 & 101.69 &  92.96 & 96.54 & 96.52 & 104.36 & 96.79 &  97.71 & 102.00 &  98.39\\\\\n",
       "\t343 & 98.57 &  98.59 &  98.61 &  97.26 &  94.81 &  97.04 & 100.26 & 96.99 &  99.56 &  98.91 & ⋯ &  98.20 & 101.59 &  92.84 & 96.85 & 96.68 & 104.87 & 96.78 &  97.74 & 102.38 &     NA\\\\\n",
       "\t344 & 98.48 &  98.50 &  98.36 &  97.22 &  94.82 &  96.93 & 100.24 & 95.26 &  99.63 &  98.82 & ⋯ &  98.20 & 101.50 &  92.88 & 97.28 & 96.64 & 105.27 & 96.70 &  97.62 & 102.82 &     NA\\\\\n",
       "\t345 & 98.35 &  98.33 &  98.13 &  97.14 &  94.86 &  96.56 &  99.99 & 94.77 &  99.60 &  98.66 & ⋯ &  98.04 & 101.36 &  93.00 & 97.76 & 96.59 & 105.55 & 96.58 &     NA &     NA &     NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 345 × 44\n",
       "\n",
       "| <!--/--> | 日本 &lt;dbl&gt; | 经合组织成员国 &lt;dbl&gt; | OECD成员国_欧洲 &lt;dbl&gt; | OECD和六个非成员经济体 &lt;dbl&gt; | 主要亚洲五国.OECD. &lt;dbl&gt; | 瑞士 &lt;dbl&gt; | 韩国 &lt;dbl&gt; | 土耳其 &lt;dbl&gt; | 比利时 &lt;dbl&gt; | 丹麦 &lt;dbl&gt; | ⋯ ⋯ | 西方七国 &lt;dbl&gt; | 印尼 &lt;dbl&gt; | 中华人民共和国 &lt;dbl&gt; | 南非 &lt;dbl&gt; | 哥伦比亚 &lt;dbl&gt; | 墨西哥 &lt;dbl&gt; | 新西兰 &lt;dbl&gt; | 以色列 &lt;dbl&gt; | 哥斯达黎加 &lt;dbl&gt; | 欧元区 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 100.86 | 100.98 | 100.79 | 100.34 | 100.74 | 99.21 | NA | NA | 100.50 | 101.19 | ⋯ | 100.79 | NA | 101.44 | 101.91 | NA | NA | 101.35 | NA | NA | 100.62 |\n",
       "| 2 | 100.60 | 100.85 | 100.73 | 100.26 | 100.78 | 98.84 | NA | NA | 100.42 | 101.24 | ⋯ | 100.67 | NA | 101.95 | 101.79 | NA | NA | 101.32 | NA | NA | 100.56 |\n",
       "| 3 | 100.34 | 100.71 | 100.69 | 100.15 | 100.80 | 98.80 | NA | NA | 100.46 | 101.22 | ⋯ | 100.51 | NA | 102.36 | 101.73 | NA | NA | 101.38 | NA | NA | 100.57 |\n",
       "| 4 | 100.14 | 100.66 | 100.75 | 100.11 | 100.79 | 98.97 | NA | NA | 100.47 | 101.16 | ⋯ | 100.46 | NA | 102.63 | 101.73 | NA | NA | 101.55 | NA | NA | 100.67 |\n",
       "| 5 | 100.05 | 100.69 | 100.85 | 100.12 | 100.77 | 99.18 | NA | NA | 100.46 | 101.09 | ⋯ | 100.49 | NA | 102.72 | 101.78 | NA | NA | 101.77 | NA | NA | 100.78 |\n",
       "| 6 | 100.04 | 100.78 | 100.97 | 100.18 | 100.73 | 99.33 | NA | NA | 100.44 | 101.01 | ⋯ | 100.60 | NA | 102.63 | 101.83 | NA | NA | 101.94 | NA | NA | 100.80 |\n",
       "| 7 | 100.10 | 100.86 | 101.00 | 100.21 | 100.68 | 99.41 | NA | NA | 100.27 | 101.03 | ⋯ | 100.69 | NA | 102.40 | 101.89 | NA | NA | 102.02 | NA | NA | 100.72 |\n",
       "| 8 | 100.24 | 100.83 | 100.94 | 100.17 | 100.65 | 99.46 | NA | NA |  99.91 | 101.13 | ⋯ | 100.66 | NA | 102.14 | 101.95 | NA | NA | 102.01 | NA | NA | 100.56 |\n",
       "| 9 | 100.41 | 100.70 | 100.80 | 100.03 | 100.66 | 99.47 | NA | NA |  99.50 | 101.18 | ⋯ | 100.50 | NA | 101.93 | 102.03 | NA | NA | 101.93 | NA | NA | 100.34 |\n",
       "| 10 | 100.57 | 100.58 | 100.64 |  99.93 | 100.71 | 99.42 | NA | NA |  99.01 | 101.16 | ⋯ | 100.37 | NA | 101.81 | 102.13 | NA | NA | 101.81 | NA | NA | 100.10 |\n",
       "| 11 | 100.70 | 100.50 | 100.49 |  99.86 | 100.79 | 99.27 | NA | NA |  98.54 | 101.17 | ⋯ | 100.28 | NA | 101.81 | 102.21 | NA | NA | 101.71 | NA | NA |  99.89 |\n",
       "| 12 | 100.80 | 100.48 | 100.36 |  99.86 | 100.89 | 98.97 | NA | NA |  98.35 | 101.09 | ⋯ | 100.25 | NA | 101.91 | 102.22 | NA | NA | 101.70 | NA | NA |  99.67 |\n",
       "| 13 | 100.90 | 100.48 | 100.28 |  99.88 | 101.00 | 98.59 | NA | NA |  98.30 | 100.99 | ⋯ | 100.25 | NA | 102.05 | 102.11 | NA | NA | 101.85 | NA | NA |  99.50 |\n",
       "| 14 | 100.99 | 100.52 | 100.23 |  99.93 | 101.10 | 98.22 | NA | NA |  98.36 | 100.78 | ⋯ | 100.30 | NA | 102.16 | 101.91 | NA | NA | 102.00 | NA | NA |  99.41 |\n",
       "| 15 | 101.06 | 100.61 | 100.25 | 100.01 | 101.16 | 97.91 | NA | NA |  98.51 | 100.66 | ⋯ | 100.41 | NA | 102.19 | 101.67 | NA | NA | 101.97 | NA | NA |  99.40 |\n",
       "| 16 | 101.10 | 100.63 | 100.27 | 100.03 | 101.17 | 97.66 | NA | NA |  98.66 | 100.61 | ⋯ | 100.45 | NA | 102.16 | 101.41 | NA | NA | 101.62 | NA | NA |  99.40 |\n",
       "| 17 | 101.07 | 100.62 | 100.28 | 100.01 | 101.13 | 97.46 | NA | NA |  98.69 | 100.50 | ⋯ | 100.44 | NA | 102.11 | 101.18 | NA | NA | 101.14 | NA | NA |  99.43 |\n",
       "| 18 | 101.00 | 100.65 | 100.28 | 100.02 | 101.06 | 97.32 | NA | NA |  98.75 | 100.41 | ⋯ | 100.48 | NA | 102.04 | 101.03 | NA | NA | 100.80 | NA | NA |  99.44 |\n",
       "| 19 | 100.92 | 100.69 | 100.26 | 100.05 | 100.99 | 97.26 | NA | NA |  98.90 | 100.43 | ⋯ | 100.54 | NA | 102.00 | 101.02 | NA | NA | 100.82 | NA | NA |  99.42 |\n",
       "| 20 | 100.82 | 100.73 | 100.29 | 100.09 | 100.92 | 97.32 | NA | NA |  99.14 | 100.47 | ⋯ | 100.58 | NA | 101.95 | 101.10 | NA | NA | 101.04 | NA | NA |  99.43 |\n",
       "| 21 | 100.68 | 100.75 | 100.32 | 100.11 | 100.83 | 97.58 | NA | NA |  99.30 | 100.66 | ⋯ | 100.59 | NA | 101.93 | 101.20 | NA | NA | 101.28 | NA | NA |  99.42 |\n",
       "| 22 | 100.42 | 100.76 | 100.31 | 100.12 | 100.66 | 97.92 | NA | NA |  99.35 | 100.85 | ⋯ | 100.57 | NA | 101.88 | 101.28 | NA | NA | 101.41 | NA | NA |  99.38 |\n",
       "| 23 |  99.99 | 100.74 | 100.33 | 100.10 | 100.34 | 98.22 | NA | NA |  99.38 | 100.91 | ⋯ | 100.53 | NA | 101.72 | 101.32 | NA | NA | 101.43 | NA | NA |  99.36 |\n",
       "| 24 |  99.55 | 100.71 | 100.38 | 100.04 |  99.91 | 98.39 | NA | NA |  99.27 | 100.98 | ⋯ | 100.48 | NA | 101.29 | 101.29 | NA | NA | 101.36 | NA | NA |  99.42 |\n",
       "| 25 |  99.28 | 100.74 | 100.47 | 100.01 |  99.45 | 98.48 | NA | NA |  98.99 | 101.12 | ⋯ | 100.49 | NA | 100.58 | 101.15 | NA | NA | 101.20 | NA | NA |  99.52 |\n",
       "| 26 |  99.36 | 100.82 | 100.52 | 100.03 |  99.28 | 98.55 | NA | NA |  98.81 | 101.20 | ⋯ | 100.59 | NA | 100.08 | 101.00 | NA | NA | 100.99 | NA | NA |  99.52 |\n",
       "| 27 |  99.65 | 100.94 | 100.55 | 100.11 |  99.34 | 98.65 | NA | NA |  98.73 | 101.23 | ⋯ | 100.72 | NA |  99.84 | 100.91 | NA | NA | 100.78 | NA | NA |  99.53 |\n",
       "| 28 |  99.96 | 101.09 | 100.63 | 100.23 |  99.52 | 98.80 | NA | NA |  98.76 | 101.12 | ⋯ | 100.89 | NA |  99.84 | 100.95 | NA | NA | 100.59 | NA | NA |  99.61 |\n",
       "| 29 | 100.17 | 101.26 | 100.78 | 100.37 |  99.70 | 99.03 | NA | NA |  98.92 | 100.95 | ⋯ | 101.09 | NA |  99.98 | 101.03 | NA | NA | 100.42 | NA | NA |  99.76 |\n",
       "| 30 | 100.25 | 101.42 | 100.94 | 100.51 |  99.82 | 99.38 | NA | NA |  99.14 | 101.01 | ⋯ | 101.25 | NA | 100.17 | 101.01 | NA | NA | 100.28 | NA | NA |  99.97 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋱ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 316 | 98.21 | 100.04 | 100.37 | 100.68 | 102.12 |  99.62 | 100.36 | 97.88 | 101.52 | 101.23 | ⋯ |  99.99 |  99.65 | 103.71 | 98.67 | 95.25 | 101.58 | 99.62 | 102.69 |  97.96 | 100.57 |\n",
       "| 317 | 98.32 | 100.29 | 100.87 | 100.82 | 102.03 | 100.08 | 100.72 | 97.37 | 101.90 | 101.38 | ⋯ | 100.22 |  99.77 | 103.51 | 98.50 | 95.11 | 102.31 | 99.66 | 102.87 |  97.89 | 101.31 |\n",
       "| 318 | 98.55 | 100.45 | 101.23 | 100.86 | 101.87 | 100.66 | 100.89 | 97.34 | 102.15 | 101.45 | ⋯ | 100.33 |  99.46 | 103.25 | 98.40 | 96.01 | 102.87 | 99.66 | 102.54 |  98.17 | 101.86 |\n",
       "| 319 | 98.72 | 100.35 | 101.29 | 100.68 | 101.53 | 101.23 | 100.70 | 97.23 | 102.08 | 101.50 | ⋯ | 100.15 |  98.82 | 102.81 | 98.44 | 97.27 | 103.05 | 99.57 | 101.81 |  98.63 | 101.95 |\n",
       "| 320 | 98.83 | 100.10 | 101.15 | 100.47 | 101.44 | 101.63 | 100.56 | 97.04 | 101.77 | 101.57 | ⋯ |  99.81 |  98.71 | 102.69 | 98.56 | 98.14 | 102.98 | 99.42 | 101.01 |  99.06 | 101.85 |\n",
       "| 321 | 98.98 |  99.93 | 100.93 | 100.42 | 101.69 | 101.71 | 100.62 | 96.71 | 101.44 | 101.58 | ⋯ |  99.60 |  99.36 | 102.92 | 98.70 | 98.72 | 103.16 | 99.25 | 100.99 |  99.29 | 101.72 |\n",
       "| 322 | 99.15 |  99.75 | 100.56 | 100.35 | 101.92 | 101.59 | 100.79 | 95.96 | 100.97 | 101.21 | ⋯ |  99.42 | 100.26 | 103.08 | 98.80 | 98.93 | 103.53 | 99.10 | 100.79 |  99.41 | 101.41 |\n",
       "| 323 | 99.21 |  99.52 | 100.13 | 100.25 | 102.09 | 101.37 | 100.84 | 95.04 | 100.54 | 100.70 | ⋯ |  99.24 | 100.86 | 103.22 | 98.85 | 98.72 | 103.89 | 98.95 | 100.19 |  99.56 | 100.98 |\n",
       "| 324 | 99.04 |  99.28 |  99.76 | 100.14 | 102.17 | 101.07 | 100.72 | 94.57 | 100.20 | 100.36 | ⋯ |  99.03 | 101.07 | 103.36 | 98.84 | 98.11 | 103.57 | 98.77 |  99.49 |  99.82 | 100.57 |\n",
       "| 325 | 98.66 |  98.95 |  99.34 |  99.88 | 101.99 | 100.68 | 100.61 | 94.63 |  99.84 |  99.99 | ⋯ |  98.67 | 101.01 | 103.20 | 98.71 | 97.36 | 103.07 | 98.53 |  98.66 | 100.11 | 100.09 |\n",
       "| 326 | 98.19 |  98.48 |  98.66 |  99.27 | 101.05 | 100.09 | 100.54 | 94.58 |  99.30 |  99.31 | ⋯ |  98.15 | 100.81 | 101.97 | 98.47 | 96.81 | 102.86 | 98.23 |  98.25 | 100.30 |  99.21 |\n",
       "| 327 | 97.74 |  97.94 |  97.67 |  98.21 |  99.07 |  99.22 | 100.50 | 94.30 |  98.55 |  98.16 | ⋯ |  97.60 | 100.76 |  99.21 | 98.11 | 96.65 | 102.94 | 97.85 |  98.22 | 100.27 |  97.83 |\n",
       "| 328 | 97.50 |  97.54 |  96.93 |  97.04 |  96.57 |  98.21 | 100.38 | 93.64 |  98.23 |  97.24 | ⋯ |  97.22 | 101.01 |  95.62 | 97.58 | 96.91 | 103.01 | 97.38 |  98.41 | 100.11 |  96.96 |\n",
       "| 329 | 97.38 |  97.16 |  96.49 |  96.31 |  95.21 |  97.23 |  99.99 | 93.13 |  98.16 |  96.72 | ⋯ |  96.83 | 101.44 |  93.65 | 97.04 | 97.57 | 102.77 | 96.94 |  98.39 |  99.92 |  96.48 |\n",
       "| 330 | 97.22 |  96.79 |  96.14 |  95.96 |  94.76 |  96.41 |  99.29 | 92.94 |  98.11 |  96.45 | ⋯ |  96.47 | 101.63 |  93.07 | 96.67 | 98.33 | 102.14 | 96.70 |  97.76 |  99.77 |  96.03 |\n",
       "| 331 | 97.09 |  96.58 |  95.89 |  95.84 |  94.62 |  95.73 |  98.58 | 93.51 |  97.93 |  96.36 | ⋯ |  96.32 | 101.57 |  92.97 | 96.65 | 98.40 | 101.40 | 96.79 |  97.32 |  99.71 |  95.62 |\n",
       "| 332 | 97.09 |  96.59 |  95.76 |  95.88 |  94.57 |  95.19 |  98.34 | 94.39 |  97.58 |  96.27 | ⋯ |  96.37 | 101.42 |  92.94 | 96.89 | 98.21 | 100.98 | 97.01 |  97.43 |  99.81 |  95.42 |\n",
       "| 333 | 97.00 |  96.61 |  95.68 |  95.91 |  94.52 |  94.83 |  98.32 | 95.13 |  97.11 |  95.94 | ⋯ |  96.40 | 101.22 |  92.92 | 97.32 | 97.50 | 100.96 | 97.10 |  97.64 | 100.14 |  95.26 |\n",
       "| 334 | 96.89 |  96.71 |  95.86 |  95.97 |  94.47 |  94.67 |  98.25 | 95.77 |  97.11 |  95.78 | ⋯ |  96.49 | 101.15 |  92.89 | 97.88 | 96.62 | 101.24 | 96.90 |  98.07 | 100.61 |  95.50 |\n",
       "| 335 | 96.85 |  96.89 |  96.25 |  96.13 |  94.56 |  94.78 |  98.21 | 96.14 |  97.59 |  96.11 | ⋯ |  96.64 | 101.15 |  93.04 | 98.38 | 95.93 | 101.80 | 96.53 |  98.42 | 101.13 |  96.08 |\n",
       "| 336 | 96.94 |  97.16 |  96.67 |  96.45 |  94.98 |  95.26 |  98.32 | 96.45 |  98.23 |  96.58 | ⋯ |  96.89 | 101.22 |  93.59 | 98.57 | 95.55 | 102.50 | 96.22 |  98.30 | 101.62 |  96.66 |\n",
       "| 337 | 97.10 |  97.47 |  97.07 |  96.84 |  95.52 |  95.90 |  98.44 | 97.05 |  98.79 |  97.05 | ⋯ |  97.16 | 101.32 |  94.33 | 98.21 | 95.20 | 103.20 | 96.10 |  98.03 | 102.01 |  97.14 |\n",
       "| 338 | 97.36 |  97.72 |  97.47 |  97.15 |  95.93 |  96.45 |  98.57 | 97.79 |  99.16 |  97.41 | ⋯ |  97.38 | 101.41 |  94.83 | 97.57 | 95.05 | 103.59 | 96.15 |  98.01 | 102.20 |  97.49 |\n",
       "| 339 | 97.76 |  97.90 |  97.85 |  97.23 |  95.90 |  96.73 |  98.82 | 98.52 |  99.30 |  97.77 | ⋯ |  97.52 | 101.52 |  94.66 | 96.96 | 95.08 | 103.66 | 96.29 |  97.91 | 102.10 |  97.72 |\n",
       "| 340 | 98.14 |  98.11 |  98.29 |  97.18 |  95.44 |  96.84 |  99.21 | 99.47 |  99.35 |  98.19 | ⋯ |  97.66 | 101.64 |  93.89 | 96.60 | 95.37 | 103.68 | 96.48 |  97.88 | 101.90 |  97.95 |\n",
       "| 341 | 98.40 |  98.30 |  98.63 |  97.17 |  95.11 |  96.91 |  99.64 | 99.75 |  99.31 |  98.59 | ⋯ |  97.80 | 101.72 |  93.33 | 96.46 | 95.95 | 103.91 | 96.67 |  97.84 | 101.81 |  98.16 |\n",
       "| 342 | 98.53 |  98.49 |  98.73 |  97.21 |  94.89 |  96.99 | 100.02 | 98.74 |  99.40 |  98.85 | ⋯ |  98.02 | 101.69 |  92.96 | 96.54 | 96.52 | 104.36 | 96.79 |  97.71 | 102.00 |  98.39 |\n",
       "| 343 | 98.57 |  98.59 |  98.61 |  97.26 |  94.81 |  97.04 | 100.26 | 96.99 |  99.56 |  98.91 | ⋯ |  98.20 | 101.59 |  92.84 | 96.85 | 96.68 | 104.87 | 96.78 |  97.74 | 102.38 |     NA |\n",
       "| 344 | 98.48 |  98.50 |  98.36 |  97.22 |  94.82 |  96.93 | 100.24 | 95.26 |  99.63 |  98.82 | ⋯ |  98.20 | 101.50 |  92.88 | 97.28 | 96.64 | 105.27 | 96.70 |  97.62 | 102.82 |     NA |\n",
       "| 345 | 98.35 |  98.33 |  98.13 |  97.14 |  94.86 |  96.56 |  99.99 | 94.77 |  99.60 |  98.66 | ⋯ |  98.04 | 101.36 |  93.00 | 97.76 | 96.59 | 105.55 | 96.58 |     NA |     NA |     NA |\n",
       "\n"
      ],
      "text/plain": [
       "    日本   经合组织成员国 OECD成员国_欧洲 OECD和六个非成员经济体\n",
       "1   100.86 100.98         100.79          100.34                \n",
       "2   100.60 100.85         100.73          100.26                \n",
       "3   100.34 100.71         100.69          100.15                \n",
       "4   100.14 100.66         100.75          100.11                \n",
       "5   100.05 100.69         100.85          100.12                \n",
       "6   100.04 100.78         100.97          100.18                \n",
       "7   100.10 100.86         101.00          100.21                \n",
       "8   100.24 100.83         100.94          100.17                \n",
       "9   100.41 100.70         100.80          100.03                \n",
       "10  100.57 100.58         100.64           99.93                \n",
       "11  100.70 100.50         100.49           99.86                \n",
       "12  100.80 100.48         100.36           99.86                \n",
       "13  100.90 100.48         100.28           99.88                \n",
       "14  100.99 100.52         100.23           99.93                \n",
       "15  101.06 100.61         100.25          100.01                \n",
       "16  101.10 100.63         100.27          100.03                \n",
       "17  101.07 100.62         100.28          100.01                \n",
       "18  101.00 100.65         100.28          100.02                \n",
       "19  100.92 100.69         100.26          100.05                \n",
       "20  100.82 100.73         100.29          100.09                \n",
       "21  100.68 100.75         100.32          100.11                \n",
       "22  100.42 100.76         100.31          100.12                \n",
       "23   99.99 100.74         100.33          100.10                \n",
       "24   99.55 100.71         100.38          100.04                \n",
       "25   99.28 100.74         100.47          100.01                \n",
       "26   99.36 100.82         100.52          100.03                \n",
       "27   99.65 100.94         100.55          100.11                \n",
       "28   99.96 101.09         100.63          100.23                \n",
       "29  100.17 101.26         100.78          100.37                \n",
       "30  100.25 101.42         100.94          100.51                \n",
       "⋮   ⋮      ⋮              ⋮               ⋮                     \n",
       "316 98.21  100.04         100.37          100.68                \n",
       "317 98.32  100.29         100.87          100.82                \n",
       "318 98.55  100.45         101.23          100.86                \n",
       "319 98.72  100.35         101.29          100.68                \n",
       "320 98.83  100.10         101.15          100.47                \n",
       "321 98.98   99.93         100.93          100.42                \n",
       "322 99.15   99.75         100.56          100.35                \n",
       "323 99.21   99.52         100.13          100.25                \n",
       "324 99.04   99.28          99.76          100.14                \n",
       "325 98.66   98.95          99.34           99.88                \n",
       "326 98.19   98.48          98.66           99.27                \n",
       "327 97.74   97.94          97.67           98.21                \n",
       "328 97.50   97.54          96.93           97.04                \n",
       "329 97.38   97.16          96.49           96.31                \n",
       "330 97.22   96.79          96.14           95.96                \n",
       "331 97.09   96.58          95.89           95.84                \n",
       "332 97.09   96.59          95.76           95.88                \n",
       "333 97.00   96.61          95.68           95.91                \n",
       "334 96.89   96.71          95.86           95.97                \n",
       "335 96.85   96.89          96.25           96.13                \n",
       "336 96.94   97.16          96.67           96.45                \n",
       "337 97.10   97.47          97.07           96.84                \n",
       "338 97.36   97.72          97.47           97.15                \n",
       "339 97.76   97.90          97.85           97.23                \n",
       "340 98.14   98.11          98.29           97.18                \n",
       "341 98.40   98.30          98.63           97.17                \n",
       "342 98.53   98.49          98.73           97.21                \n",
       "343 98.57   98.59          98.61           97.26                \n",
       "344 98.48   98.50          98.36           97.22                \n",
       "345 98.35   98.33          98.13           97.14                \n",
       "    主要亚洲五国.OECD. 瑞士   韩国   土耳其 比利时 丹麦   ⋯ 西方七国 印尼  \n",
       "1   100.74             99.21  NA     NA     100.50 101.19 ⋯ 100.79   NA    \n",
       "2   100.78             98.84  NA     NA     100.42 101.24 ⋯ 100.67   NA    \n",
       "3   100.80             98.80  NA     NA     100.46 101.22 ⋯ 100.51   NA    \n",
       "4   100.79             98.97  NA     NA     100.47 101.16 ⋯ 100.46   NA    \n",
       "5   100.77             99.18  NA     NA     100.46 101.09 ⋯ 100.49   NA    \n",
       "6   100.73             99.33  NA     NA     100.44 101.01 ⋯ 100.60   NA    \n",
       "7   100.68             99.41  NA     NA     100.27 101.03 ⋯ 100.69   NA    \n",
       "8   100.65             99.46  NA     NA      99.91 101.13 ⋯ 100.66   NA    \n",
       "9   100.66             99.47  NA     NA      99.50 101.18 ⋯ 100.50   NA    \n",
       "10  100.71             99.42  NA     NA      99.01 101.16 ⋯ 100.37   NA    \n",
       "11  100.79             99.27  NA     NA      98.54 101.17 ⋯ 100.28   NA    \n",
       "12  100.89             98.97  NA     NA      98.35 101.09 ⋯ 100.25   NA    \n",
       "13  101.00             98.59  NA     NA      98.30 100.99 ⋯ 100.25   NA    \n",
       "14  101.10             98.22  NA     NA      98.36 100.78 ⋯ 100.30   NA    \n",
       "15  101.16             97.91  NA     NA      98.51 100.66 ⋯ 100.41   NA    \n",
       "16  101.17             97.66  NA     NA      98.66 100.61 ⋯ 100.45   NA    \n",
       "17  101.13             97.46  NA     NA      98.69 100.50 ⋯ 100.44   NA    \n",
       "18  101.06             97.32  NA     NA      98.75 100.41 ⋯ 100.48   NA    \n",
       "19  100.99             97.26  NA     NA      98.90 100.43 ⋯ 100.54   NA    \n",
       "20  100.92             97.32  NA     NA      99.14 100.47 ⋯ 100.58   NA    \n",
       "21  100.83             97.58  NA     NA      99.30 100.66 ⋯ 100.59   NA    \n",
       "22  100.66             97.92  NA     NA      99.35 100.85 ⋯ 100.57   NA    \n",
       "23  100.34             98.22  NA     NA      99.38 100.91 ⋯ 100.53   NA    \n",
       "24   99.91             98.39  NA     NA      99.27 100.98 ⋯ 100.48   NA    \n",
       "25   99.45             98.48  NA     NA      98.99 101.12 ⋯ 100.49   NA    \n",
       "26   99.28             98.55  NA     NA      98.81 101.20 ⋯ 100.59   NA    \n",
       "27   99.34             98.65  NA     NA      98.73 101.23 ⋯ 100.72   NA    \n",
       "28   99.52             98.80  NA     NA      98.76 101.12 ⋯ 100.89   NA    \n",
       "29   99.70             99.03  NA     NA      98.92 100.95 ⋯ 101.09   NA    \n",
       "30   99.82             99.38  NA     NA      99.14 101.01 ⋯ 101.25   NA    \n",
       "⋮   ⋮                  ⋮      ⋮      ⋮      ⋮      ⋮      ⋱ ⋮        ⋮     \n",
       "316 102.12              99.62 100.36 97.88  101.52 101.23 ⋯  99.99    99.65\n",
       "317 102.03             100.08 100.72 97.37  101.90 101.38 ⋯ 100.22    99.77\n",
       "318 101.87             100.66 100.89 97.34  102.15 101.45 ⋯ 100.33    99.46\n",
       "319 101.53             101.23 100.70 97.23  102.08 101.50 ⋯ 100.15    98.82\n",
       "320 101.44             101.63 100.56 97.04  101.77 101.57 ⋯  99.81    98.71\n",
       "321 101.69             101.71 100.62 96.71  101.44 101.58 ⋯  99.60    99.36\n",
       "322 101.92             101.59 100.79 95.96  100.97 101.21 ⋯  99.42   100.26\n",
       "323 102.09             101.37 100.84 95.04  100.54 100.70 ⋯  99.24   100.86\n",
       "324 102.17             101.07 100.72 94.57  100.20 100.36 ⋯  99.03   101.07\n",
       "325 101.99             100.68 100.61 94.63   99.84  99.99 ⋯  98.67   101.01\n",
       "326 101.05             100.09 100.54 94.58   99.30  99.31 ⋯  98.15   100.81\n",
       "327  99.07              99.22 100.50 94.30   98.55  98.16 ⋯  97.60   100.76\n",
       "328  96.57              98.21 100.38 93.64   98.23  97.24 ⋯  97.22   101.01\n",
       "329  95.21              97.23  99.99 93.13   98.16  96.72 ⋯  96.83   101.44\n",
       "330  94.76              96.41  99.29 92.94   98.11  96.45 ⋯  96.47   101.63\n",
       "331  94.62              95.73  98.58 93.51   97.93  96.36 ⋯  96.32   101.57\n",
       "332  94.57              95.19  98.34 94.39   97.58  96.27 ⋯  96.37   101.42\n",
       "333  94.52              94.83  98.32 95.13   97.11  95.94 ⋯  96.40   101.22\n",
       "334  94.47              94.67  98.25 95.77   97.11  95.78 ⋯  96.49   101.15\n",
       "335  94.56              94.78  98.21 96.14   97.59  96.11 ⋯  96.64   101.15\n",
       "336  94.98              95.26  98.32 96.45   98.23  96.58 ⋯  96.89   101.22\n",
       "337  95.52              95.90  98.44 97.05   98.79  97.05 ⋯  97.16   101.32\n",
       "338  95.93              96.45  98.57 97.79   99.16  97.41 ⋯  97.38   101.41\n",
       "339  95.90              96.73  98.82 98.52   99.30  97.77 ⋯  97.52   101.52\n",
       "340  95.44              96.84  99.21 99.47   99.35  98.19 ⋯  97.66   101.64\n",
       "341  95.11              96.91  99.64 99.75   99.31  98.59 ⋯  97.80   101.72\n",
       "342  94.89              96.99 100.02 98.74   99.40  98.85 ⋯  98.02   101.69\n",
       "343  94.81              97.04 100.26 96.99   99.56  98.91 ⋯  98.20   101.59\n",
       "344  94.82              96.93 100.24 95.26   99.63  98.82 ⋯  98.20   101.50\n",
       "345  94.86              96.56  99.99 94.77   99.60  98.66 ⋯  98.04   101.36\n",
       "    中华人民共和国 南非   哥伦比亚 墨西哥 新西兰 以色列 哥斯达黎加 欧元区\n",
       "1   101.44         101.91 NA       NA     101.35 NA     NA         100.62\n",
       "2   101.95         101.79 NA       NA     101.32 NA     NA         100.56\n",
       "3   102.36         101.73 NA       NA     101.38 NA     NA         100.57\n",
       "4   102.63         101.73 NA       NA     101.55 NA     NA         100.67\n",
       "5   102.72         101.78 NA       NA     101.77 NA     NA         100.78\n",
       "6   102.63         101.83 NA       NA     101.94 NA     NA         100.80\n",
       "7   102.40         101.89 NA       NA     102.02 NA     NA         100.72\n",
       "8   102.14         101.95 NA       NA     102.01 NA     NA         100.56\n",
       "9   101.93         102.03 NA       NA     101.93 NA     NA         100.34\n",
       "10  101.81         102.13 NA       NA     101.81 NA     NA         100.10\n",
       "11  101.81         102.21 NA       NA     101.71 NA     NA          99.89\n",
       "12  101.91         102.22 NA       NA     101.70 NA     NA          99.67\n",
       "13  102.05         102.11 NA       NA     101.85 NA     NA          99.50\n",
       "14  102.16         101.91 NA       NA     102.00 NA     NA          99.41\n",
       "15  102.19         101.67 NA       NA     101.97 NA     NA          99.40\n",
       "16  102.16         101.41 NA       NA     101.62 NA     NA          99.40\n",
       "17  102.11         101.18 NA       NA     101.14 NA     NA          99.43\n",
       "18  102.04         101.03 NA       NA     100.80 NA     NA          99.44\n",
       "19  102.00         101.02 NA       NA     100.82 NA     NA          99.42\n",
       "20  101.95         101.10 NA       NA     101.04 NA     NA          99.43\n",
       "21  101.93         101.20 NA       NA     101.28 NA     NA          99.42\n",
       "22  101.88         101.28 NA       NA     101.41 NA     NA          99.38\n",
       "23  101.72         101.32 NA       NA     101.43 NA     NA          99.36\n",
       "24  101.29         101.29 NA       NA     101.36 NA     NA          99.42\n",
       "25  100.58         101.15 NA       NA     101.20 NA     NA          99.52\n",
       "26  100.08         101.00 NA       NA     100.99 NA     NA          99.52\n",
       "27   99.84         100.91 NA       NA     100.78 NA     NA          99.53\n",
       "28   99.84         100.95 NA       NA     100.59 NA     NA          99.61\n",
       "29   99.98         101.03 NA       NA     100.42 NA     NA          99.76\n",
       "30  100.17         101.01 NA       NA     100.28 NA     NA          99.97\n",
       "⋮   ⋮              ⋮      ⋮        ⋮      ⋮      ⋮      ⋮          ⋮     \n",
       "316 103.71         98.67  95.25    101.58 99.62  102.69  97.96     100.57\n",
       "317 103.51         98.50  95.11    102.31 99.66  102.87  97.89     101.31\n",
       "318 103.25         98.40  96.01    102.87 99.66  102.54  98.17     101.86\n",
       "319 102.81         98.44  97.27    103.05 99.57  101.81  98.63     101.95\n",
       "320 102.69         98.56  98.14    102.98 99.42  101.01  99.06     101.85\n",
       "321 102.92         98.70  98.72    103.16 99.25  100.99  99.29     101.72\n",
       "322 103.08         98.80  98.93    103.53 99.10  100.79  99.41     101.41\n",
       "323 103.22         98.85  98.72    103.89 98.95  100.19  99.56     100.98\n",
       "324 103.36         98.84  98.11    103.57 98.77   99.49  99.82     100.57\n",
       "325 103.20         98.71  97.36    103.07 98.53   98.66 100.11     100.09\n",
       "326 101.97         98.47  96.81    102.86 98.23   98.25 100.30      99.21\n",
       "327  99.21         98.11  96.65    102.94 97.85   98.22 100.27      97.83\n",
       "328  95.62         97.58  96.91    103.01 97.38   98.41 100.11      96.96\n",
       "329  93.65         97.04  97.57    102.77 96.94   98.39  99.92      96.48\n",
       "330  93.07         96.67  98.33    102.14 96.70   97.76  99.77      96.03\n",
       "331  92.97         96.65  98.40    101.40 96.79   97.32  99.71      95.62\n",
       "332  92.94         96.89  98.21    100.98 97.01   97.43  99.81      95.42\n",
       "333  92.92         97.32  97.50    100.96 97.10   97.64 100.14      95.26\n",
       "334  92.89         97.88  96.62    101.24 96.90   98.07 100.61      95.50\n",
       "335  93.04         98.38  95.93    101.80 96.53   98.42 101.13      96.08\n",
       "336  93.59         98.57  95.55    102.50 96.22   98.30 101.62      96.66\n",
       "337  94.33         98.21  95.20    103.20 96.10   98.03 102.01      97.14\n",
       "338  94.83         97.57  95.05    103.59 96.15   98.01 102.20      97.49\n",
       "339  94.66         96.96  95.08    103.66 96.29   97.91 102.10      97.72\n",
       "340  93.89         96.60  95.37    103.68 96.48   97.88 101.90      97.95\n",
       "341  93.33         96.46  95.95    103.91 96.67   97.84 101.81      98.16\n",
       "342  92.96         96.54  96.52    104.36 96.79   97.71 102.00      98.39\n",
       "343  92.84         96.85  96.68    104.87 96.78   97.74 102.38         NA\n",
       "344  92.88         97.28  96.64    105.27 96.70   97.62 102.82         NA\n",
       "345  93.00         97.76  96.59    105.55 96.58      NA     NA         NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f28e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq=12\n",
    "ll=dim(data)[2]\n",
    "hh=12\n",
    "start=c(2000,1)\n",
    "m=5\n",
    "n=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b4979f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data <- function(data, start, freq, hh, ll) {\n",
    "  data_ts <- list()\n",
    "  data_tstrain <- list()\n",
    "  data_features <- NULL\n",
    "  \n",
    "  for (i in 1:ll) {\n",
    "    # 寻找第一个非NA值的位置\n",
    "    loc <- min(which(is.na(data[, i]) == FALSE)) - 1\n",
    "    zc <- loc %/% freq\n",
    "    yu <- loc %% freq\n",
    "    \n",
    "    # 提取子序列\n",
    "    x <- data[(loc + 1):dim(data)[1], i]\n",
    "    \n",
    "    # 检测并处理NA值\n",
    "    r <- which(is.na(x) == TRUE)\n",
    "    if (length(r) != 0) {\n",
    "      x <- na_kalman(x) # 假设na_kalman是一个处理NA值的函数\n",
    "    }\n",
    "    \n",
    "    # 创建时间序列对象\n",
    "    da <- ts(x[1:(length(x) - hh)], start = c(start[1] + zc, start[2] + yu), frequency = freq)\n",
    "    da1 <- ts(x, start = c(start[1] + zc, start[2] + yu), frequency = freq)\n",
    "    \n",
    "    # 保存时间序列对象\n",
    "    data_ts[[i]] <- da1\n",
    "    data_tstrain[[i]] <- da\n",
    "    \n",
    "    # 提取时间序列特征\n",
    "    f <- tsfeatures(da)\n",
    "    if (is.null(data_features)) {\n",
    "      data_features <- f\n",
    "    } else {\n",
    "      data_features <- rbind(data_features, f)\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # 函数返回一个列表，包含处理后的时间序列和特征\n",
    "  list(time_series = data_ts, time_series_train = data_tstrain, features = data_features)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "358c2538",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data <- process_data(data, start = c(1995, 1), freq, hh, ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f85c803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ts=processed_data$time_series\n",
    "data_tstrain=processed_data$time_series_train\n",
    "data_features=processed_data$features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca0a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d35a9716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 20</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>frequency</th><th scope=col>nperiods</th><th scope=col>seasonal_period</th><th scope=col>trend</th><th scope=col>spike</th><th scope=col>linearity</th><th scope=col>curvature</th><th scope=col>e_acf1</th><th scope=col>e_acf10</th><th scope=col>seasonal_strength</th><th scope=col>peak</th><th scope=col>trough</th><th scope=col>entropy</th><th scope=col>x_acf1</th><th scope=col>x_acf10</th><th scope=col>diff1_acf1</th><th scope=col>diff1_acf10</th><th scope=col>diff2_acf1</th><th scope=col>diff2_acf10</th><th scope=col>seas_acf1</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>12</td><td>1</td><td>12</td><td>0.9414541</td><td>1.469496e-07</td><td>-4.148065</td><td>-3.765981</td><td>0.8454210</td><td>1.159314</td><td>0.12604369</td><td>12</td><td>5</td><td>0.5977804</td><td>0.9774598</td><td>5.517595</td><td>0.8238031</td><td>0.9675078</td><td>0.5318010</td><td>0.9109732</td><td>0.3526531</td></tr>\n",
       "\t<tr><td>12</td><td>1</td><td>12</td><td>0.9630601</td><td>8.844036e-08</td><td>-8.774571</td><td> 2.937463</td><td>0.8582569</td><td>1.183075</td><td>0.09641165</td><td> 1</td><td>5</td><td>0.5427694</td><td>0.9757847</td><td>6.052019</td><td>0.8190963</td><td>0.9426224</td><td>0.4867796</td><td>0.6482644</td><td>0.5042263</td></tr>\n",
       "\t<tr><td>12</td><td>1</td><td>12</td><td>0.9656192</td><td>5.579385e-08</td><td>-8.151818</td><td> 1.956549</td><td>0.8807846</td><td>1.410732</td><td>0.10045470</td><td> 9</td><td>4</td><td>0.5458390</td><td>0.9712250</td><td>5.603514</td><td>0.8506849</td><td>1.2190287</td><td>0.4892918</td><td>0.5528145</td><td>0.4555680</td></tr>\n",
       "\t<tr><td>12</td><td>1</td><td>12</td><td>0.9531315</td><td>1.222234e-07</td><td>-3.941638</td><td> 1.944559</td><td>0.8604031</td><td>1.131996</td><td>0.24430725</td><td> 1</td><td>5</td><td>0.5882649</td><td>0.9620671</td><td>4.573657</td><td>0.8462332</td><td>1.0444014</td><td>0.5709416</td><td>0.8613847</td><td>0.3172945</td></tr>\n",
       "\t<tr><td>12</td><td>1</td><td>12</td><td>0.9492339</td><td>1.599164e-07</td><td> 3.179791</td><td> 5.670570</td><td>0.8527939</td><td>1.177701</td><td>0.39023178</td><td> 1</td><td>6</td><td>0.6173344</td><td>0.9634733</td><td>4.700404</td><td>0.8277382</td><td>1.0134493</td><td>0.5072502</td><td>0.6229488</td><td>0.4188087</td></tr>\n",
       "\t<tr><td>12</td><td>1</td><td>12</td><td>0.9320480</td><td>1.708380e-07</td><td>-2.018620</td><td>-6.632152</td><td>0.8763513</td><td>1.222079</td><td>0.25096789</td><td>11</td><td>5</td><td>0.6383962</td><td>0.9543605</td><td>3.877693</td><td>0.8660764</td><td>1.1364421</td><td>0.6677847</td><td>0.9972327</td><td>0.1575627</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 20\n",
       "\\begin{tabular}{llllllllllllllllllll}\n",
       " frequency & nperiods & seasonal\\_period & trend & spike & linearity & curvature & e\\_acf1 & e\\_acf10 & seasonal\\_strength & peak & trough & entropy & x\\_acf1 & x\\_acf10 & diff1\\_acf1 & diff1\\_acf10 & diff2\\_acf1 & diff2\\_acf10 & seas\\_acf1\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 12 & 1 & 12 & 0.9414541 & 1.469496e-07 & -4.148065 & -3.765981 & 0.8454210 & 1.159314 & 0.12604369 & 12 & 5 & 0.5977804 & 0.9774598 & 5.517595 & 0.8238031 & 0.9675078 & 0.5318010 & 0.9109732 & 0.3526531\\\\\n",
       "\t 12 & 1 & 12 & 0.9630601 & 8.844036e-08 & -8.774571 &  2.937463 & 0.8582569 & 1.183075 & 0.09641165 &  1 & 5 & 0.5427694 & 0.9757847 & 6.052019 & 0.8190963 & 0.9426224 & 0.4867796 & 0.6482644 & 0.5042263\\\\\n",
       "\t 12 & 1 & 12 & 0.9656192 & 5.579385e-08 & -8.151818 &  1.956549 & 0.8807846 & 1.410732 & 0.10045470 &  9 & 4 & 0.5458390 & 0.9712250 & 5.603514 & 0.8506849 & 1.2190287 & 0.4892918 & 0.5528145 & 0.4555680\\\\\n",
       "\t 12 & 1 & 12 & 0.9531315 & 1.222234e-07 & -3.941638 &  1.944559 & 0.8604031 & 1.131996 & 0.24430725 &  1 & 5 & 0.5882649 & 0.9620671 & 4.573657 & 0.8462332 & 1.0444014 & 0.5709416 & 0.8613847 & 0.3172945\\\\\n",
       "\t 12 & 1 & 12 & 0.9492339 & 1.599164e-07 &  3.179791 &  5.670570 & 0.8527939 & 1.177701 & 0.39023178 &  1 & 6 & 0.6173344 & 0.9634733 & 4.700404 & 0.8277382 & 1.0134493 & 0.5072502 & 0.6229488 & 0.4188087\\\\\n",
       "\t 12 & 1 & 12 & 0.9320480 & 1.708380e-07 & -2.018620 & -6.632152 & 0.8763513 & 1.222079 & 0.25096789 & 11 & 5 & 0.6383962 & 0.9543605 & 3.877693 & 0.8660764 & 1.1364421 & 0.6677847 & 0.9972327 & 0.1575627\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 20\n",
       "\n",
       "| frequency &lt;dbl&gt; | nperiods &lt;dbl&gt; | seasonal_period &lt;dbl&gt; | trend &lt;dbl&gt; | spike &lt;dbl&gt; | linearity &lt;dbl&gt; | curvature &lt;dbl&gt; | e_acf1 &lt;dbl&gt; | e_acf10 &lt;dbl&gt; | seasonal_strength &lt;dbl&gt; | peak &lt;dbl&gt; | trough &lt;dbl&gt; | entropy &lt;dbl&gt; | x_acf1 &lt;dbl&gt; | x_acf10 &lt;dbl&gt; | diff1_acf1 &lt;dbl&gt; | diff1_acf10 &lt;dbl&gt; | diff2_acf1 &lt;dbl&gt; | diff2_acf10 &lt;dbl&gt; | seas_acf1 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 12 | 1 | 12 | 0.9414541 | 1.469496e-07 | -4.148065 | -3.765981 | 0.8454210 | 1.159314 | 0.12604369 | 12 | 5 | 0.5977804 | 0.9774598 | 5.517595 | 0.8238031 | 0.9675078 | 0.5318010 | 0.9109732 | 0.3526531 |\n",
       "| 12 | 1 | 12 | 0.9630601 | 8.844036e-08 | -8.774571 |  2.937463 | 0.8582569 | 1.183075 | 0.09641165 |  1 | 5 | 0.5427694 | 0.9757847 | 6.052019 | 0.8190963 | 0.9426224 | 0.4867796 | 0.6482644 | 0.5042263 |\n",
       "| 12 | 1 | 12 | 0.9656192 | 5.579385e-08 | -8.151818 |  1.956549 | 0.8807846 | 1.410732 | 0.10045470 |  9 | 4 | 0.5458390 | 0.9712250 | 5.603514 | 0.8506849 | 1.2190287 | 0.4892918 | 0.5528145 | 0.4555680 |\n",
       "| 12 | 1 | 12 | 0.9531315 | 1.222234e-07 | -3.941638 |  1.944559 | 0.8604031 | 1.131996 | 0.24430725 |  1 | 5 | 0.5882649 | 0.9620671 | 4.573657 | 0.8462332 | 1.0444014 | 0.5709416 | 0.8613847 | 0.3172945 |\n",
       "| 12 | 1 | 12 | 0.9492339 | 1.599164e-07 |  3.179791 |  5.670570 | 0.8527939 | 1.177701 | 0.39023178 |  1 | 6 | 0.6173344 | 0.9634733 | 4.700404 | 0.8277382 | 1.0134493 | 0.5072502 | 0.6229488 | 0.4188087 |\n",
       "| 12 | 1 | 12 | 0.9320480 | 1.708380e-07 | -2.018620 | -6.632152 | 0.8763513 | 1.222079 | 0.25096789 | 11 | 5 | 0.6383962 | 0.9543605 | 3.877693 | 0.8660764 | 1.1364421 | 0.6677847 | 0.9972327 | 0.1575627 |\n",
       "\n"
      ],
      "text/plain": [
       "  frequency nperiods seasonal_period trend     spike        linearity curvature\n",
       "1 12        1        12              0.9414541 1.469496e-07 -4.148065 -3.765981\n",
       "2 12        1        12              0.9630601 8.844036e-08 -8.774571  2.937463\n",
       "3 12        1        12              0.9656192 5.579385e-08 -8.151818  1.956549\n",
       "4 12        1        12              0.9531315 1.222234e-07 -3.941638  1.944559\n",
       "5 12        1        12              0.9492339 1.599164e-07  3.179791  5.670570\n",
       "6 12        1        12              0.9320480 1.708380e-07 -2.018620 -6.632152\n",
       "  e_acf1    e_acf10  seasonal_strength peak trough entropy   x_acf1    x_acf10 \n",
       "1 0.8454210 1.159314 0.12604369        12   5      0.5977804 0.9774598 5.517595\n",
       "2 0.8582569 1.183075 0.09641165         1   5      0.5427694 0.9757847 6.052019\n",
       "3 0.8807846 1.410732 0.10045470         9   4      0.5458390 0.9712250 5.603514\n",
       "4 0.8604031 1.131996 0.24430725         1   5      0.5882649 0.9620671 4.573657\n",
       "5 0.8527939 1.177701 0.39023178         1   6      0.6173344 0.9634733 4.700404\n",
       "6 0.8763513 1.222079 0.25096789        11   5      0.6383962 0.9543605 3.877693\n",
       "  diff1_acf1 diff1_acf10 diff2_acf1 diff2_acf10 seas_acf1\n",
       "1 0.8238031  0.9675078   0.5318010  0.9109732   0.3526531\n",
       "2 0.8190963  0.9426224   0.4867796  0.6482644   0.5042263\n",
       "3 0.8506849  1.2190287   0.4892918  0.5528145   0.4555680\n",
       "4 0.8462332  1.0444014   0.5709416  0.8613847   0.3172945\n",
       "5 0.8277382  1.0134493   0.5072502  0.6229488   0.4188087\n",
       "6 0.8660764  1.1364421   0.6677847  0.9972327   0.1575627"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1ffd85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "long=matrix(0,ll,1)\n",
    "for( i in 1:ll)\n",
    "    {\n",
    "    long[i,1]=length(data_tstrain[[i]])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d68c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features=cbind(data_features,long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53921725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53ca3e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 21</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>frequency</th><th scope=col>nperiods</th><th scope=col>seasonal_period</th><th scope=col>trend</th><th scope=col>spike</th><th scope=col>linearity</th><th scope=col>curvature</th><th scope=col>e_acf1</th><th scope=col>e_acf10</th><th scope=col>seasonal_strength</th><th scope=col>⋯</th><th scope=col>trough</th><th scope=col>entropy</th><th scope=col>x_acf1</th><th scope=col>x_acf10</th><th scope=col>diff1_acf1</th><th scope=col>diff1_acf10</th><th scope=col>diff2_acf1</th><th scope=col>diff2_acf10</th><th scope=col>seas_acf1</th><th scope=col>long</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>12</td><td>1</td><td>12</td><td>0.9414541</td><td>1.469496e-07</td><td>-4.148065</td><td>-3.765981</td><td>0.8454210</td><td>1.159314</td><td>0.12604369</td><td>⋯</td><td>5</td><td>0.5977804</td><td>0.9774598</td><td>5.517595</td><td>0.8238031</td><td>0.9675078</td><td>0.5318010</td><td>0.9109732</td><td>0.3526531</td><td>333</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>12</td><td>1</td><td>12</td><td>0.9630601</td><td>8.844036e-08</td><td>-8.774571</td><td> 2.937463</td><td>0.8582569</td><td>1.183075</td><td>0.09641165</td><td>⋯</td><td>5</td><td>0.5427694</td><td>0.9757847</td><td>6.052019</td><td>0.8190963</td><td>0.9426224</td><td>0.4867796</td><td>0.6482644</td><td>0.5042263</td><td>333</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>12</td><td>1</td><td>12</td><td>0.9656192</td><td>5.579385e-08</td><td>-8.151818</td><td> 1.956549</td><td>0.8807846</td><td>1.410732</td><td>0.10045470</td><td>⋯</td><td>4</td><td>0.5458390</td><td>0.9712250</td><td>5.603514</td><td>0.8506849</td><td>1.2190287</td><td>0.4892918</td><td>0.5528145</td><td>0.4555680</td><td>333</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>12</td><td>1</td><td>12</td><td>0.9531315</td><td>1.222234e-07</td><td>-3.941638</td><td> 1.944559</td><td>0.8604031</td><td>1.131996</td><td>0.24430725</td><td>⋯</td><td>5</td><td>0.5882649</td><td>0.9620671</td><td>4.573657</td><td>0.8462332</td><td>1.0444014</td><td>0.5709416</td><td>0.8613847</td><td>0.3172945</td><td>333</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>12</td><td>1</td><td>12</td><td>0.9492339</td><td>1.599164e-07</td><td> 3.179791</td><td> 5.670570</td><td>0.8527939</td><td>1.177701</td><td>0.39023178</td><td>⋯</td><td>6</td><td>0.6173344</td><td>0.9634733</td><td>4.700404</td><td>0.8277382</td><td>1.0134493</td><td>0.5072502</td><td>0.6229488</td><td>0.4188087</td><td>333</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>12</td><td>1</td><td>12</td><td>0.9320480</td><td>1.708380e-07</td><td>-2.018620</td><td>-6.632152</td><td>0.8763513</td><td>1.222079</td><td>0.25096789</td><td>⋯</td><td>5</td><td>0.6383962</td><td>0.9543605</td><td>3.877693</td><td>0.8660764</td><td>1.1364421</td><td>0.6677847</td><td>0.9972327</td><td>0.1575627</td><td>333</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 21\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & frequency & nperiods & seasonal\\_period & trend & spike & linearity & curvature & e\\_acf1 & e\\_acf10 & seasonal\\_strength & ⋯ & trough & entropy & x\\_acf1 & x\\_acf10 & diff1\\_acf1 & diff1\\_acf10 & diff2\\_acf1 & diff2\\_acf10 & seas\\_acf1 & long\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 12 & 1 & 12 & 0.9414541 & 1.469496e-07 & -4.148065 & -3.765981 & 0.8454210 & 1.159314 & 0.12604369 & ⋯ & 5 & 0.5977804 & 0.9774598 & 5.517595 & 0.8238031 & 0.9675078 & 0.5318010 & 0.9109732 & 0.3526531 & 333\\\\\n",
       "\t2 & 12 & 1 & 12 & 0.9630601 & 8.844036e-08 & -8.774571 &  2.937463 & 0.8582569 & 1.183075 & 0.09641165 & ⋯ & 5 & 0.5427694 & 0.9757847 & 6.052019 & 0.8190963 & 0.9426224 & 0.4867796 & 0.6482644 & 0.5042263 & 333\\\\\n",
       "\t3 & 12 & 1 & 12 & 0.9656192 & 5.579385e-08 & -8.151818 &  1.956549 & 0.8807846 & 1.410732 & 0.10045470 & ⋯ & 4 & 0.5458390 & 0.9712250 & 5.603514 & 0.8506849 & 1.2190287 & 0.4892918 & 0.5528145 & 0.4555680 & 333\\\\\n",
       "\t4 & 12 & 1 & 12 & 0.9531315 & 1.222234e-07 & -3.941638 &  1.944559 & 0.8604031 & 1.131996 & 0.24430725 & ⋯ & 5 & 0.5882649 & 0.9620671 & 4.573657 & 0.8462332 & 1.0444014 & 0.5709416 & 0.8613847 & 0.3172945 & 333\\\\\n",
       "\t5 & 12 & 1 & 12 & 0.9492339 & 1.599164e-07 &  3.179791 &  5.670570 & 0.8527939 & 1.177701 & 0.39023178 & ⋯ & 6 & 0.6173344 & 0.9634733 & 4.700404 & 0.8277382 & 1.0134493 & 0.5072502 & 0.6229488 & 0.4188087 & 333\\\\\n",
       "\t6 & 12 & 1 & 12 & 0.9320480 & 1.708380e-07 & -2.018620 & -6.632152 & 0.8763513 & 1.222079 & 0.25096789 & ⋯ & 5 & 0.6383962 & 0.9543605 & 3.877693 & 0.8660764 & 1.1364421 & 0.6677847 & 0.9972327 & 0.1575627 & 333\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 21\n",
       "\n",
       "| <!--/--> | frequency &lt;dbl&gt; | nperiods &lt;dbl&gt; | seasonal_period &lt;dbl&gt; | trend &lt;dbl&gt; | spike &lt;dbl&gt; | linearity &lt;dbl&gt; | curvature &lt;dbl&gt; | e_acf1 &lt;dbl&gt; | e_acf10 &lt;dbl&gt; | seasonal_strength &lt;dbl&gt; | ⋯ ⋯ | trough &lt;dbl&gt; | entropy &lt;dbl&gt; | x_acf1 &lt;dbl&gt; | x_acf10 &lt;dbl&gt; | diff1_acf1 &lt;dbl&gt; | diff1_acf10 &lt;dbl&gt; | diff2_acf1 &lt;dbl&gt; | diff2_acf10 &lt;dbl&gt; | seas_acf1 &lt;dbl&gt; | long &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 12 | 1 | 12 | 0.9414541 | 1.469496e-07 | -4.148065 | -3.765981 | 0.8454210 | 1.159314 | 0.12604369 | ⋯ | 5 | 0.5977804 | 0.9774598 | 5.517595 | 0.8238031 | 0.9675078 | 0.5318010 | 0.9109732 | 0.3526531 | 333 |\n",
       "| 2 | 12 | 1 | 12 | 0.9630601 | 8.844036e-08 | -8.774571 |  2.937463 | 0.8582569 | 1.183075 | 0.09641165 | ⋯ | 5 | 0.5427694 | 0.9757847 | 6.052019 | 0.8190963 | 0.9426224 | 0.4867796 | 0.6482644 | 0.5042263 | 333 |\n",
       "| 3 | 12 | 1 | 12 | 0.9656192 | 5.579385e-08 | -8.151818 |  1.956549 | 0.8807846 | 1.410732 | 0.10045470 | ⋯ | 4 | 0.5458390 | 0.9712250 | 5.603514 | 0.8506849 | 1.2190287 | 0.4892918 | 0.5528145 | 0.4555680 | 333 |\n",
       "| 4 | 12 | 1 | 12 | 0.9531315 | 1.222234e-07 | -3.941638 |  1.944559 | 0.8604031 | 1.131996 | 0.24430725 | ⋯ | 5 | 0.5882649 | 0.9620671 | 4.573657 | 0.8462332 | 1.0444014 | 0.5709416 | 0.8613847 | 0.3172945 | 333 |\n",
       "| 5 | 12 | 1 | 12 | 0.9492339 | 1.599164e-07 |  3.179791 |  5.670570 | 0.8527939 | 1.177701 | 0.39023178 | ⋯ | 6 | 0.6173344 | 0.9634733 | 4.700404 | 0.8277382 | 1.0134493 | 0.5072502 | 0.6229488 | 0.4188087 | 333 |\n",
       "| 6 | 12 | 1 | 12 | 0.9320480 | 1.708380e-07 | -2.018620 | -6.632152 | 0.8763513 | 1.222079 | 0.25096789 | ⋯ | 5 | 0.6383962 | 0.9543605 | 3.877693 | 0.8660764 | 1.1364421 | 0.6677847 | 0.9972327 | 0.1575627 | 333 |\n",
       "\n"
      ],
      "text/plain": [
       "  frequency nperiods seasonal_period trend     spike        linearity curvature\n",
       "1 12        1        12              0.9414541 1.469496e-07 -4.148065 -3.765981\n",
       "2 12        1        12              0.9630601 8.844036e-08 -8.774571  2.937463\n",
       "3 12        1        12              0.9656192 5.579385e-08 -8.151818  1.956549\n",
       "4 12        1        12              0.9531315 1.222234e-07 -3.941638  1.944559\n",
       "5 12        1        12              0.9492339 1.599164e-07  3.179791  5.670570\n",
       "6 12        1        12              0.9320480 1.708380e-07 -2.018620 -6.632152\n",
       "  e_acf1    e_acf10  seasonal_strength ⋯ trough entropy   x_acf1    x_acf10 \n",
       "1 0.8454210 1.159314 0.12604369        ⋯ 5      0.5977804 0.9774598 5.517595\n",
       "2 0.8582569 1.183075 0.09641165        ⋯ 5      0.5427694 0.9757847 6.052019\n",
       "3 0.8807846 1.410732 0.10045470        ⋯ 4      0.5458390 0.9712250 5.603514\n",
       "4 0.8604031 1.131996 0.24430725        ⋯ 5      0.5882649 0.9620671 4.573657\n",
       "5 0.8527939 1.177701 0.39023178        ⋯ 6      0.6173344 0.9634733 4.700404\n",
       "6 0.8763513 1.222079 0.25096789        ⋯ 5      0.6383962 0.9543605 3.877693\n",
       "  diff1_acf1 diff1_acf10 diff2_acf1 diff2_acf10 seas_acf1 long\n",
       "1 0.8238031  0.9675078   0.5318010  0.9109732   0.3526531 333 \n",
       "2 0.8190963  0.9426224   0.4867796  0.6482644   0.5042263 333 \n",
       "3 0.8506849  1.2190287   0.4892918  0.5528145   0.4555680 333 \n",
       "4 0.8462332  1.0444014   0.5709416  0.8613847   0.3172945 333 \n",
       "5 0.8277382  1.0134493   0.5072502  0.6229488   0.4188087 333 \n",
       "6 0.8660764  1.1364421   0.6677847  0.9972327   0.1575627 333 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844bdb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f87372e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802af79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6fabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf60ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef92371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=function(x){\n",
    "    if( x%%1>=0.5)\n",
    "        {\n",
    "        return(as.integer(x)+1)\n",
    "    }\n",
    "    else{return(as.integer(x))}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ccdaa415",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_and_evaluate <- function(data_ts, data_tstrain, m,n,hh, ll) {\n",
    "  predets <- array(0, dim = c(ll, m, n, 6))\n",
    "  predhets <- array(0, dim = c(ll, m, n, hh))\n",
    "  predthetaf <- array(0, dim = c(ll, m, n, 6))\n",
    "  predhthetaf <- array(0, dim = c(ll, m, n, hh))\n",
    "  predarima <- array(0, dim = c(ll, m, n, 6))\n",
    "  predharima <- array(0, dim = c(ll, m, n, hh))\n",
    "  prednnetar <- array(0, dim = c(ll, m, n, 6))\n",
    "  predhnnetar <- array(0, dim = c(ll, m, n, hh))\n",
    "  yreal <- list()\n",
    "  \n",
    "  for (k in 1:ll) {\n",
    "    y <- data_tstrain[[k]]\n",
    "    yall <- data_ts[[k]]\n",
    "    y_pred <- ts(yall[(length(yall) - hh + 1):length(yall)], end = end(yall), frequency = frequency(yall))\n",
    "    y_l=length(y)\n",
    "    loc = 1:length(y)\n",
    "    loc_m = as.integer(loc*m/length(y))\n",
    "    filt_d = data.frame(y,loc_m)\n",
    "    filt_0=filter(filt_d ,loc_m==0)\n",
    "    m_l=count(filt_0)\n",
    "    n_l=m_l/n\n",
    "    m_l=as.integer(m_l)\n",
    "    n_l=as.numeric(n_l)\n",
    "    \n",
    "    yreal[[k]] <- y_pred\n",
    "    \n",
    "    for (i in 0:(m - 1)) {\n",
    "      for (j in 0:(n-1)) {\n",
    "        Y <- ts(y[round((i*m_l+j*n_l)+1):y_l], end = end(y), frequency = frequency(yall))\n",
    "#         M <- ets(Y)\n",
    "#         pd <- forecast(M, h = hh)\n",
    "#         predhets[k, (i + 1), (j + 1), ] <- pd$mean\n",
    "#         predets[k, (i + 1), (j + 1), ] <- accuracy(pd, y_pred)[2, 1:6]\n",
    "        \n",
    "#         M <- thetaf(Y, h = hh)\n",
    "#         pd <- forecast(M, h = hh)\n",
    "#         predhthetaf[k, (i + 1), (j + 1), ] <- pd$mean\n",
    "#         predthetaf[k, (i + 1), (j + 1), ] <- accuracy(pd, y_pred)[2, 1:6]\n",
    "          \n",
    "        M <- auto.arima(Y)\n",
    "        pd <- forecast(M, h = hh)\n",
    "        predharima[k, (i + 1), (j + 1), ] <- pd$mean\n",
    "        predarima[k, (i + 1), (j + 1), ] <- accuracy(pd, y_pred)[2, 1:6]\n",
    "          \n",
    "#         M <- nnetar(Y, h = hh)\n",
    "#         pd <- forecast(M, h = hh)\n",
    "#         predhnnetar[k, (i + 1), (j + 1), ] <- pd$mean\n",
    "#         prednnetar[k, (i + 1), (j + 1), ] <- accuracy(pd, y_pred)[2, 1:6]\n",
    "        \n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  list(\n",
    "    pred_ets = list(predhets = predhets, predets = predets),\n",
    "    pred_thetaf = list(predhthetaf = predhthetaf, predthetaf = predthetaf),\n",
    "    pred_arima = list(predharima = predharima, predarima = predarima),\n",
    "    pred_nnetar = list(predhnnetar = predhnnetar, prednnetar = prednnetar),\n",
    "    y_real = yreal\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eeb332c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in auto.arima(Y):\n",
      "“Having 3 or more differencing operations is not recommended. Please consider reducing the total number of differences.”\n"
     ]
    }
   ],
   "source": [
    "forecast_list=forecast_and_evaluate(data_ts, data_tstrain, m,n,hh, ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2dbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2f97521",
   "metadata": {},
   "outputs": [],
   "source": [
    "predhets=forecast_list$pred_ets$predhets\n",
    "predets=forecast_list$pred_ets$predets\n",
    "predhthetaf=forecast_list$pred_thetaf$predhthetaf\n",
    "predthetaf=forecast_list$pred_thetaf$predthetaf\n",
    "\n",
    "predharima=forecast_list$pred_arima$predharima\n",
    "predarima=forecast_list$pred_arima$predarima\n",
    "predhnnetar=forecast_list$pred_nnetar$predhnnetar\n",
    "prednnetar=forecast_list$pred_nnetar$prednnetar\n",
    "\n",
    "y_real=forecast_list$y_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6693a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "length5=matrix(0,ll,m)\n",
    "for(k in 1:ll)\n",
    "{\n",
    "y = data_tstrain[[k]]\n",
    "y_l=length(y)\n",
    "loc = 1:length(y)\n",
    "loc_m = as.integer(loc*m/length(y))\n",
    "filt_d = data.frame(y,loc_m)\n",
    "filt_0=filter(filt_d ,loc_m==0)\n",
    "m_l=count(filt_0)\n",
    "m_l=as.integer(m_l)\n",
    "length5[k,]=c(0,1*m_l,2*m_l,3*m_l,4*m_l)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae36a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2932818b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘xgboost’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    slice\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘lightgbm’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:xgboost’:\n",
      "\n",
      "    slice\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    slice\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(\"xgboost\")\n",
    "library(\"Matrix\")\n",
    "library('Ckmeans.1d.dp')\n",
    "library(lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2f70c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47699d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanunique=function(x)\n",
    "    {\n",
    "    mean(unique(x))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50237fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "whichmin<-function(x){\n",
    "    minx=min(x[x>0])\n",
    "    loc=which(x==minx)[1]-1\n",
    "    loc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d0c5902",
   "metadata": {},
   "outputs": [],
   "source": [
    "realbest_construct<-function(MASE)\n",
    "    {\n",
    "realbestmean=matrix(0,dim(MASE)[1],1)\n",
    "for(i in seq(1,dim(MASE)[1]))\n",
    "    {\n",
    "    count=MASE[i,,]\n",
    "    line=apply(count,1,meanunique)\n",
    "    if (max(line,na.rm = TRUE)==0){\n",
    "        realbestmean[i,]=0\n",
    "        }\n",
    "    else\n",
    "        {\n",
    "        line[is.na(line)]=100 \n",
    "        realbestmean[i,]= whichmin(line)\n",
    "    }\n",
    "    }\n",
    "    return(realbestmean)\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe49228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ef2f704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASEets=predets[,,,6]\n",
    "MASEthetaf=predthetaf[,,,6]\n",
    "MASEarima=predarima[,,,6]\n",
    "MASEnnetar=prednnetar[,,,6]\n",
    "\n",
    "realbestmeanets=realbest_construct(MASEets)\n",
    "realbestmeanthetaf=realbest_construct(MASEthetaf)\n",
    "realbestmeanarima=realbest_construct(MASEarima)\n",
    "realbestmeannnetar=realbest_construct(MASEnnetar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d6b0bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(50)\n",
    "index = sample(2,nrow(data_features),replace = TRUE,prob=c(0.7,0.3))\n",
    "train_data=data_features[index==1,]\n",
    "test_data=data_features[index==2,]\n",
    "train_label_ets=realbestmeanets[index==1,]\n",
    "test_label_ets=realbestmeanets[index==2,]\n",
    "train_label_thetaf=realbestmeanthetaf[index==1,]\n",
    "test_label_thetaf=realbestmeanthetaf[index==2,]\n",
    "               \n",
    "train_label_arima=realbestmeanarima[index==1,]\n",
    "test_label_arima=realbestmeanarima[index==2,]\n",
    "train_label_nnetar=realbestmeannnetar[index==1,]\n",
    "test_label_nnetar=realbestmeannnetar[index==2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e08a154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3969ef50",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "526b9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_models<-function(train_data,train_label)\n",
    "{\n",
    "    dtrain_reg <- xgb.DMatrix(data = as.matrix(train_data),label = as.matrix(train_label)) \n",
    "    dtrain_cl<- xgb.DMatrix(data = as.matrix(train_data),label = as.matrix(as.factor(train_label)))\n",
    "    xgbreg  <- xgboost(data = dtrain_reg, nround=100)\n",
    "    xgbcls  <- xgboost(data = dtrain_cl, nround=100, objective='multi:softmax',num_class=5)\n",
    "    dtrain_reg <- lgb.Dataset(data = as.matrix(train_data),label = as.matrix(train_label))\n",
    "    dtrain_cl <- lgb.Dataset(data = as.matrix(train_data),label = as.matrix(as.factor(train_label)))\n",
    "    # 定义参数列表\n",
    "    params_reg <- list(\n",
    "      objective = \"regression\",\n",
    "      metric = \"rmse\"\n",
    "    )\n",
    "    lgbreg  <- lgb.train(data = dtrain_reg,nrounds = 100,params = params_reg)\n",
    "    # 定义参数列表\n",
    "    params_cl <- list(\n",
    "      objective = 'multiclass',\n",
    "      num_class = 5,\n",
    "      num_iterations = 100  # 使用 num_iterations 代替 nrounds\n",
    "    )\n",
    "    # 使用参数列表进行训练\n",
    "    lgbcls <- lgb.train(data = dtrain_cl,params = params_cl)\n",
    "    return(list(xgbreg =xgbreg, xgbcls = xgbcls,lgbreg=lgbreg,lgbcls=lgbcls))\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33fd45f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:2.296028 \n",
      "[2]\ttrain-rmse:1.664914 \n",
      "[3]\ttrain-rmse:1.220185 \n",
      "[4]\ttrain-rmse:0.913355 \n",
      "[5]\ttrain-rmse:0.671086 \n",
      "[6]\ttrain-rmse:0.501464 \n",
      "[7]\ttrain-rmse:0.380681 \n",
      "[8]\ttrain-rmse:0.294589 \n",
      "[9]\ttrain-rmse:0.230904 \n",
      "[10]\ttrain-rmse:0.186042 \n",
      "[11]\ttrain-rmse:0.151898 \n",
      "[12]\ttrain-rmse:0.125151 \n",
      "[13]\ttrain-rmse:0.104605 \n",
      "[14]\ttrain-rmse:0.087224 \n",
      "[15]\ttrain-rmse:0.073788 \n",
      "[16]\ttrain-rmse:0.062506 \n",
      "[17]\ttrain-rmse:0.053306 \n",
      "[18]\ttrain-rmse:0.044030 \n",
      "[19]\ttrain-rmse:0.037552 \n",
      "[20]\ttrain-rmse:0.031624 \n",
      "[21]\ttrain-rmse:0.027054 \n",
      "[22]\ttrain-rmse:0.023191 \n",
      "[23]\ttrain-rmse:0.019664 \n",
      "[24]\ttrain-rmse:0.016900 \n",
      "[25]\ttrain-rmse:0.014265 \n",
      "[26]\ttrain-rmse:0.012003 \n",
      "[27]\ttrain-rmse:0.010150 \n",
      "[28]\ttrain-rmse:0.008602 \n",
      "[29]\ttrain-rmse:0.007334 \n",
      "[30]\ttrain-rmse:0.006248 \n",
      "[31]\ttrain-rmse:0.005320 \n",
      "[32]\ttrain-rmse:0.004544 \n",
      "[33]\ttrain-rmse:0.003846 \n",
      "[34]\ttrain-rmse:0.003283 \n",
      "[35]\ttrain-rmse:0.002820 \n",
      "[36]\ttrain-rmse:0.002403 \n",
      "[37]\ttrain-rmse:0.002058 \n",
      "[38]\ttrain-rmse:0.001760 \n",
      "[39]\ttrain-rmse:0.001499 \n",
      "[40]\ttrain-rmse:0.001280 \n",
      "[41]\ttrain-rmse:0.001101 \n",
      "[42]\ttrain-rmse:0.000964 \n",
      "[43]\ttrain-rmse:0.000847 \n",
      "[44]\ttrain-rmse:0.000736 \n",
      "[45]\ttrain-rmse:0.000665 \n",
      "[46]\ttrain-rmse:0.000585 \n",
      "[47]\ttrain-rmse:0.000560 \n",
      "[48]\ttrain-rmse:0.000527 \n",
      "[49]\ttrain-rmse:0.000511 \n",
      "[50]\ttrain-rmse:0.000510 \n",
      "[51]\ttrain-rmse:0.000510 \n",
      "[52]\ttrain-rmse:0.000510 \n",
      "[53]\ttrain-rmse:0.000510 \n",
      "[54]\ttrain-rmse:0.000510 \n",
      "[55]\ttrain-rmse:0.000510 \n",
      "[56]\ttrain-rmse:0.000510 \n",
      "[57]\ttrain-rmse:0.000510 \n",
      "[58]\ttrain-rmse:0.000510 \n",
      "[59]\ttrain-rmse:0.000510 \n",
      "[60]\ttrain-rmse:0.000510 \n",
      "[61]\ttrain-rmse:0.000510 \n",
      "[62]\ttrain-rmse:0.000510 \n",
      "[63]\ttrain-rmse:0.000510 \n",
      "[64]\ttrain-rmse:0.000510 \n",
      "[65]\ttrain-rmse:0.000510 \n",
      "[66]\ttrain-rmse:0.000510 \n",
      "[67]\ttrain-rmse:0.000510 \n",
      "[68]\ttrain-rmse:0.000510 \n",
      "[69]\ttrain-rmse:0.000510 \n",
      "[70]\ttrain-rmse:0.000510 \n",
      "[71]\ttrain-rmse:0.000510 \n",
      "[72]\ttrain-rmse:0.000510 \n",
      "[73]\ttrain-rmse:0.000510 \n",
      "[74]\ttrain-rmse:0.000510 \n",
      "[75]\ttrain-rmse:0.000510 \n",
      "[76]\ttrain-rmse:0.000510 \n",
      "[77]\ttrain-rmse:0.000510 \n",
      "[78]\ttrain-rmse:0.000510 \n",
      "[79]\ttrain-rmse:0.000510 \n",
      "[80]\ttrain-rmse:0.000510 \n",
      "[81]\ttrain-rmse:0.000510 \n",
      "[82]\ttrain-rmse:0.000510 \n",
      "[83]\ttrain-rmse:0.000510 \n",
      "[84]\ttrain-rmse:0.000510 \n",
      "[85]\ttrain-rmse:0.000510 \n",
      "[86]\ttrain-rmse:0.000510 \n",
      "[87]\ttrain-rmse:0.000510 \n",
      "[88]\ttrain-rmse:0.000510 \n",
      "[89]\ttrain-rmse:0.000510 \n",
      "[90]\ttrain-rmse:0.000510 \n",
      "[91]\ttrain-rmse:0.000510 \n",
      "[92]\ttrain-rmse:0.000510 \n",
      "[93]\ttrain-rmse:0.000510 \n",
      "[94]\ttrain-rmse:0.000510 \n",
      "[95]\ttrain-rmse:0.000510 \n",
      "[96]\ttrain-rmse:0.000510 \n",
      "[97]\ttrain-rmse:0.000510 \n",
      "[98]\ttrain-rmse:0.000510 \n",
      "[99]\ttrain-rmse:0.000510 \n",
      "[100]\ttrain-rmse:0.000510 \n",
      "[1]\ttrain-mlogloss:1.166187 \n",
      "[2]\ttrain-mlogloss:0.912254 \n",
      "[3]\ttrain-mlogloss:0.729929 \n",
      "[4]\ttrain-mlogloss:0.597300 \n",
      "[5]\ttrain-mlogloss:0.493407 \n",
      "[6]\ttrain-mlogloss:0.417033 \n",
      "[7]\ttrain-mlogloss:0.356258 \n",
      "[8]\ttrain-mlogloss:0.306037 \n",
      "[9]\ttrain-mlogloss:0.270609 \n",
      "[10]\ttrain-mlogloss:0.230594 \n",
      "[11]\ttrain-mlogloss:0.206082 \n",
      "[12]\ttrain-mlogloss:0.184576 \n",
      "[13]\ttrain-mlogloss:0.164794 \n",
      "[14]\ttrain-mlogloss:0.150829 \n",
      "[15]\ttrain-mlogloss:0.138110 \n",
      "[16]\ttrain-mlogloss:0.129510 \n",
      "[17]\ttrain-mlogloss:0.123206 \n",
      "[18]\ttrain-mlogloss:0.117466 \n",
      "[19]\ttrain-mlogloss:0.113242 \n",
      "[20]\ttrain-mlogloss:0.109169 \n",
      "[21]\ttrain-mlogloss:0.105095 \n",
      "[22]\ttrain-mlogloss:0.100540 \n",
      "[23]\ttrain-mlogloss:0.097046 \n",
      "[24]\ttrain-mlogloss:0.094289 \n",
      "[25]\ttrain-mlogloss:0.091707 \n",
      "[26]\ttrain-mlogloss:0.089590 \n",
      "[27]\ttrain-mlogloss:0.086763 \n",
      "[28]\ttrain-mlogloss:0.083830 \n",
      "[29]\ttrain-mlogloss:0.082989 \n",
      "[30]\ttrain-mlogloss:0.081525 \n",
      "[31]\ttrain-mlogloss:0.080835 \n",
      "[32]\ttrain-mlogloss:0.080172 \n",
      "[33]\ttrain-mlogloss:0.079558 \n",
      "[34]\ttrain-mlogloss:0.078990 \n",
      "[35]\ttrain-mlogloss:0.078374 \n",
      "[36]\ttrain-mlogloss:0.077832 \n",
      "[37]\ttrain-mlogloss:0.077343 \n",
      "[38]\ttrain-mlogloss:0.076840 \n",
      "[39]\ttrain-mlogloss:0.076337 \n",
      "[40]\ttrain-mlogloss:0.075867 \n",
      "[41]\ttrain-mlogloss:0.075416 \n",
      "[42]\ttrain-mlogloss:0.074973 \n",
      "[43]\ttrain-mlogloss:0.074536 \n",
      "[44]\ttrain-mlogloss:0.074131 \n",
      "[45]\ttrain-mlogloss:0.073747 \n",
      "[46]\ttrain-mlogloss:0.073361 \n",
      "[47]\ttrain-mlogloss:0.072967 \n",
      "[48]\ttrain-mlogloss:0.072618 \n",
      "[49]\ttrain-mlogloss:0.072266 \n",
      "[50]\ttrain-mlogloss:0.071932 \n",
      "[51]\ttrain-mlogloss:0.071605 \n",
      "[52]\ttrain-mlogloss:0.071295 \n",
      "[53]\ttrain-mlogloss:0.070983 \n",
      "[54]\ttrain-mlogloss:0.070671 \n",
      "[55]\ttrain-mlogloss:0.070383 \n",
      "[56]\ttrain-mlogloss:0.070096 \n",
      "[57]\ttrain-mlogloss:0.069820 \n",
      "[58]\ttrain-mlogloss:0.069533 \n",
      "[59]\ttrain-mlogloss:0.069260 \n",
      "[60]\ttrain-mlogloss:0.069000 \n",
      "[61]\ttrain-mlogloss:0.068735 \n",
      "[62]\ttrain-mlogloss:0.068479 \n",
      "[63]\ttrain-mlogloss:0.068219 \n",
      "[64]\ttrain-mlogloss:0.067972 \n",
      "[65]\ttrain-mlogloss:0.067736 \n",
      "[66]\ttrain-mlogloss:0.067494 \n",
      "[67]\ttrain-mlogloss:0.067254 \n",
      "[68]\ttrain-mlogloss:0.067032 \n",
      "[69]\ttrain-mlogloss:0.066813 \n",
      "[70]\ttrain-mlogloss:0.066583 \n",
      "[71]\ttrain-mlogloss:0.066371 \n",
      "[72]\ttrain-mlogloss:0.066156 \n",
      "[73]\ttrain-mlogloss:0.065940 \n",
      "[74]\ttrain-mlogloss:0.065740 \n",
      "[75]\ttrain-mlogloss:0.065536 \n",
      "[76]\ttrain-mlogloss:0.065338 \n",
      "[77]\ttrain-mlogloss:0.065145 \n",
      "[78]\ttrain-mlogloss:0.064953 \n",
      "[79]\ttrain-mlogloss:0.064762 \n",
      "[80]\ttrain-mlogloss:0.064577 \n",
      "[81]\ttrain-mlogloss:0.064401 \n",
      "[82]\ttrain-mlogloss:0.064223 \n",
      "[83]\ttrain-mlogloss:0.064041 \n",
      "[84]\ttrain-mlogloss:0.063873 \n",
      "[85]\ttrain-mlogloss:0.063703 \n",
      "[86]\ttrain-mlogloss:0.063538 \n",
      "[87]\ttrain-mlogloss:0.063374 \n",
      "[88]\ttrain-mlogloss:0.063213 \n",
      "[89]\ttrain-mlogloss:0.063054 \n",
      "[90]\ttrain-mlogloss:0.062902 \n",
      "[91]\ttrain-mlogloss:0.062754 \n",
      "[92]\ttrain-mlogloss:0.062597 \n",
      "[93]\ttrain-mlogloss:0.062450 \n",
      "[94]\ttrain-mlogloss:0.062312 \n",
      "[95]\ttrain-mlogloss:0.062164 \n",
      "[96]\ttrain-mlogloss:0.062035 \n",
      "[97]\ttrain-mlogloss:0.061898 \n",
      "[98]\ttrain-mlogloss:0.061777 \n",
      "[99]\ttrain-mlogloss:0.061650 \n",
      "[100]\ttrain-mlogloss:0.061536 \n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 37, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 3.405405\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 37, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score -2.224624\n",
      "[LightGBM] [Info] Start training from score -3.610918\n",
      "[LightGBM] [Info] Start training from score -3.610918\n",
      "[LightGBM] [Info] Start training from score -3.610918\n",
      "[LightGBM] [Info] Start training from score -0.209721\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    }
   ],
   "source": [
    "models_ets=train_models(train_data,train_label_ets)\n",
    "etsxgbreg=models_ets$xgbreg\n",
    "etsxgbcls=models_ets$xgbcls\n",
    "etslgbreg=models_ets$lgbreg\n",
    "etslgbcls=models_ets$lgbcls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b1f5344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:1.908672 \n",
      "[2]\ttrain-rmse:1.449071 \n",
      "[3]\ttrain-rmse:1.089677 \n",
      "[4]\ttrain-rmse:0.822813 \n",
      "[5]\ttrain-rmse:0.634579 \n",
      "[6]\ttrain-rmse:0.482956 \n",
      "[7]\ttrain-rmse:0.376258 \n",
      "[8]\ttrain-rmse:0.295355 \n",
      "[9]\ttrain-rmse:0.234167 \n",
      "[10]\ttrain-rmse:0.188490 \n",
      "[11]\ttrain-rmse:0.154603 \n",
      "[12]\ttrain-rmse:0.126664 \n",
      "[13]\ttrain-rmse:0.105743 \n",
      "[14]\ttrain-rmse:0.087517 \n",
      "[15]\ttrain-rmse:0.073646 \n",
      "[16]\ttrain-rmse:0.062455 \n",
      "[17]\ttrain-rmse:0.052115 \n",
      "[18]\ttrain-rmse:0.043870 \n",
      "[19]\ttrain-rmse:0.037136 \n",
      "[20]\ttrain-rmse:0.031414 \n",
      "[21]\ttrain-rmse:0.027042 \n",
      "[22]\ttrain-rmse:0.022676 \n",
      "[23]\ttrain-rmse:0.019458 \n",
      "[24]\ttrain-rmse:0.016709 \n",
      "[25]\ttrain-rmse:0.014229 \n",
      "[26]\ttrain-rmse:0.012308 \n",
      "[27]\ttrain-rmse:0.010388 \n",
      "[28]\ttrain-rmse:0.008857 \n",
      "[29]\ttrain-rmse:0.007589 \n",
      "[30]\ttrain-rmse:0.006573 \n",
      "[31]\ttrain-rmse:0.005641 \n",
      "[32]\ttrain-rmse:0.004836 \n",
      "[33]\ttrain-rmse:0.004214 \n",
      "[34]\ttrain-rmse:0.003642 \n",
      "[35]\ttrain-rmse:0.003179 \n",
      "[36]\ttrain-rmse:0.002651 \n",
      "[37]\ttrain-rmse:0.002169 \n",
      "[38]\ttrain-rmse:0.001871 \n",
      "[39]\ttrain-rmse:0.001619 \n",
      "[40]\ttrain-rmse:0.001372 \n",
      "[41]\ttrain-rmse:0.001146 \n",
      "[42]\ttrain-rmse:0.000981 \n",
      "[43]\ttrain-rmse:0.000828 \n",
      "[44]\ttrain-rmse:0.000776 \n",
      "[45]\ttrain-rmse:0.000746 \n",
      "[46]\ttrain-rmse:0.000714 \n",
      "[47]\ttrain-rmse:0.000644 \n",
      "[48]\ttrain-rmse:0.000594 \n",
      "[49]\ttrain-rmse:0.000593 \n",
      "[50]\ttrain-rmse:0.000592 \n",
      "[51]\ttrain-rmse:0.000592 \n",
      "[52]\ttrain-rmse:0.000592 \n",
      "[53]\ttrain-rmse:0.000591 \n",
      "[54]\ttrain-rmse:0.000591 \n",
      "[55]\ttrain-rmse:0.000591 \n",
      "[56]\ttrain-rmse:0.000591 \n",
      "[57]\ttrain-rmse:0.000591 \n",
      "[58]\ttrain-rmse:0.000591 \n",
      "[59]\ttrain-rmse:0.000591 \n",
      "[60]\ttrain-rmse:0.000591 \n",
      "[61]\ttrain-rmse:0.000591 \n",
      "[62]\ttrain-rmse:0.000591 \n",
      "[63]\ttrain-rmse:0.000591 \n",
      "[64]\ttrain-rmse:0.000591 \n",
      "[65]\ttrain-rmse:0.000591 \n",
      "[66]\ttrain-rmse:0.000591 \n",
      "[67]\ttrain-rmse:0.000591 \n",
      "[68]\ttrain-rmse:0.000591 \n",
      "[69]\ttrain-rmse:0.000591 \n",
      "[70]\ttrain-rmse:0.000591 \n",
      "[71]\ttrain-rmse:0.000591 \n",
      "[72]\ttrain-rmse:0.000591 \n",
      "[73]\ttrain-rmse:0.000592 \n",
      "[74]\ttrain-rmse:0.000592 \n",
      "[75]\ttrain-rmse:0.000592 \n",
      "[76]\ttrain-rmse:0.000592 \n",
      "[77]\ttrain-rmse:0.000592 \n",
      "[78]\ttrain-rmse:0.000592 \n",
      "[79]\ttrain-rmse:0.000592 \n",
      "[80]\ttrain-rmse:0.000592 \n",
      "[81]\ttrain-rmse:0.000592 \n",
      "[82]\ttrain-rmse:0.000592 \n",
      "[83]\ttrain-rmse:0.000592 \n",
      "[84]\ttrain-rmse:0.000592 \n",
      "[85]\ttrain-rmse:0.000592 \n",
      "[86]\ttrain-rmse:0.000592 \n",
      "[87]\ttrain-rmse:0.000592 \n",
      "[88]\ttrain-rmse:0.000592 \n",
      "[89]\ttrain-rmse:0.000592 \n",
      "[90]\ttrain-rmse:0.000592 \n",
      "[91]\ttrain-rmse:0.000592 \n",
      "[92]\ttrain-rmse:0.000592 \n",
      "[93]\ttrain-rmse:0.000592 \n",
      "[94]\ttrain-rmse:0.000592 \n",
      "[95]\ttrain-rmse:0.000592 \n",
      "[96]\ttrain-rmse:0.000592 \n",
      "[97]\ttrain-rmse:0.000592 \n",
      "[98]\ttrain-rmse:0.000592 \n",
      "[99]\ttrain-rmse:0.000592 \n",
      "[100]\ttrain-rmse:0.000592 \n",
      "[1]\ttrain-mlogloss:1.319636 \n",
      "[2]\ttrain-mlogloss:1.060898 \n",
      "[3]\ttrain-mlogloss:0.862051 \n",
      "[4]\ttrain-mlogloss:0.707046 \n",
      "[5]\ttrain-mlogloss:0.595144 \n",
      "[6]\ttrain-mlogloss:0.507133 \n",
      "[7]\ttrain-mlogloss:0.444214 \n",
      "[8]\ttrain-mlogloss:0.382800 \n",
      "[9]\ttrain-mlogloss:0.339984 \n",
      "[10]\ttrain-mlogloss:0.303976 \n",
      "[11]\ttrain-mlogloss:0.269970 \n",
      "[12]\ttrain-mlogloss:0.242883 \n",
      "[13]\ttrain-mlogloss:0.221088 \n",
      "[14]\ttrain-mlogloss:0.201283 \n",
      "[15]\ttrain-mlogloss:0.184531 \n",
      "[16]\ttrain-mlogloss:0.171583 \n",
      "[17]\ttrain-mlogloss:0.159521 \n",
      "[18]\ttrain-mlogloss:0.148436 \n",
      "[19]\ttrain-mlogloss:0.140346 \n",
      "[20]\ttrain-mlogloss:0.133028 \n",
      "[21]\ttrain-mlogloss:0.128814 \n",
      "[22]\ttrain-mlogloss:0.125455 \n",
      "[23]\ttrain-mlogloss:0.121661 \n",
      "[24]\ttrain-mlogloss:0.118858 \n",
      "[25]\ttrain-mlogloss:0.115821 \n",
      "[26]\ttrain-mlogloss:0.113413 \n",
      "[27]\ttrain-mlogloss:0.111029 \n",
      "[28]\ttrain-mlogloss:0.108499 \n",
      "[29]\ttrain-mlogloss:0.106361 \n",
      "[30]\ttrain-mlogloss:0.104300 \n",
      "[31]\ttrain-mlogloss:0.102506 \n",
      "[32]\ttrain-mlogloss:0.101014 \n",
      "[33]\ttrain-mlogloss:0.099453 \n",
      "[34]\ttrain-mlogloss:0.098162 \n",
      "[35]\ttrain-mlogloss:0.096632 \n",
      "[36]\ttrain-mlogloss:0.095577 \n",
      "[37]\ttrain-mlogloss:0.094270 \n",
      "[38]\ttrain-mlogloss:0.093290 \n",
      "[39]\ttrain-mlogloss:0.092112 \n",
      "[40]\ttrain-mlogloss:0.091207 \n",
      "[41]\ttrain-mlogloss:0.089830 \n",
      "[42]\ttrain-mlogloss:0.088505 \n",
      "[43]\ttrain-mlogloss:0.087575 \n",
      "[44]\ttrain-mlogloss:0.086784 \n",
      "[45]\ttrain-mlogloss:0.085982 \n",
      "[46]\ttrain-mlogloss:0.085169 \n",
      "[47]\ttrain-mlogloss:0.084415 \n",
      "[48]\ttrain-mlogloss:0.083672 \n",
      "[49]\ttrain-mlogloss:0.082963 \n",
      "[50]\ttrain-mlogloss:0.082272 \n",
      "[51]\ttrain-mlogloss:0.081594 \n",
      "[52]\ttrain-mlogloss:0.080620 \n",
      "[53]\ttrain-mlogloss:0.080019 \n",
      "[54]\ttrain-mlogloss:0.079434 \n",
      "[55]\ttrain-mlogloss:0.078856 \n",
      "[56]\ttrain-mlogloss:0.078332 \n",
      "[57]\ttrain-mlogloss:0.078026 \n",
      "[58]\ttrain-mlogloss:0.077758 \n",
      "[59]\ttrain-mlogloss:0.077543 \n",
      "[60]\ttrain-mlogloss:0.077332 \n",
      "[61]\ttrain-mlogloss:0.077138 \n",
      "[62]\ttrain-mlogloss:0.076938 \n",
      "[63]\ttrain-mlogloss:0.076746 \n",
      "[64]\ttrain-mlogloss:0.076562 \n",
      "[65]\ttrain-mlogloss:0.076379 \n",
      "[66]\ttrain-mlogloss:0.076185 \n",
      "[67]\ttrain-mlogloss:0.076000 \n",
      "[68]\ttrain-mlogloss:0.075824 \n",
      "[69]\ttrain-mlogloss:0.075642 \n",
      "[70]\ttrain-mlogloss:0.075469 \n",
      "[71]\ttrain-mlogloss:0.075301 \n",
      "[72]\ttrain-mlogloss:0.075127 \n",
      "[73]\ttrain-mlogloss:0.074962 \n",
      "[74]\ttrain-mlogloss:0.074792 \n",
      "[75]\ttrain-mlogloss:0.074633 \n",
      "[76]\ttrain-mlogloss:0.074466 \n",
      "[77]\ttrain-mlogloss:0.074314 \n",
      "[78]\ttrain-mlogloss:0.074163 \n",
      "[79]\ttrain-mlogloss:0.074005 \n",
      "[80]\ttrain-mlogloss:0.073852 \n",
      "[81]\ttrain-mlogloss:0.073705 \n",
      "[82]\ttrain-mlogloss:0.073551 \n",
      "[83]\ttrain-mlogloss:0.073404 \n",
      "[84]\ttrain-mlogloss:0.073256 \n",
      "[85]\ttrain-mlogloss:0.073120 \n",
      "[86]\ttrain-mlogloss:0.072975 \n",
      "[87]\ttrain-mlogloss:0.072840 \n",
      "[88]\ttrain-mlogloss:0.072705 \n",
      "[89]\ttrain-mlogloss:0.072570 \n",
      "[90]\ttrain-mlogloss:0.072435 \n",
      "[91]\ttrain-mlogloss:0.072297 \n",
      "[92]\ttrain-mlogloss:0.072169 \n",
      "[93]\ttrain-mlogloss:0.072045 \n",
      "[94]\ttrain-mlogloss:0.071915 \n",
      "[95]\ttrain-mlogloss:0.071787 \n",
      "[96]\ttrain-mlogloss:0.071664 \n",
      "[97]\ttrain-mlogloss:0.071544 \n",
      "[98]\ttrain-mlogloss:0.071423 \n",
      "[99]\ttrain-mlogloss:0.071297 \n",
      "[100]\ttrain-mlogloss:0.071182 \n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 37, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 2.513514\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 37, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score -1.819158\n",
      "[LightGBM] [Info] Start training from score -1.665008\n",
      "[LightGBM] [Info] Start training from score -2.224624\n",
      "[LightGBM] [Info] Start training from score -2.917771\n",
      "[LightGBM] [Info] Start training from score -0.720546\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    }
   ],
   "source": [
    "models_thetaf=train_models(train_data,train_label_thetaf)\n",
    "thetafxgbreg=models_thetaf$xgbreg\n",
    "thetafxgbcls=models_thetaf$xgbcls\n",
    "thetaflgbreg=models_thetaf$lgbreg\n",
    "thetaflgbcls=models_thetaf$lgbcls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "83b4f6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:1.908672 \n",
      "[2]\ttrain-rmse:1.449071 \n",
      "[3]\ttrain-rmse:1.089677 \n",
      "[4]\ttrain-rmse:0.822813 \n",
      "[5]\ttrain-rmse:0.634579 \n",
      "[6]\ttrain-rmse:0.482956 \n",
      "[7]\ttrain-rmse:0.376258 \n",
      "[8]\ttrain-rmse:0.295355 \n",
      "[9]\ttrain-rmse:0.234167 \n",
      "[10]\ttrain-rmse:0.188490 \n",
      "[11]\ttrain-rmse:0.154603 \n",
      "[12]\ttrain-rmse:0.126664 \n",
      "[13]\ttrain-rmse:0.105743 \n",
      "[14]\ttrain-rmse:0.087517 \n",
      "[15]\ttrain-rmse:0.073646 \n",
      "[16]\ttrain-rmse:0.062455 \n",
      "[17]\ttrain-rmse:0.052115 \n",
      "[18]\ttrain-rmse:0.043870 \n",
      "[19]\ttrain-rmse:0.037136 \n",
      "[20]\ttrain-rmse:0.031414 \n",
      "[21]\ttrain-rmse:0.027042 \n",
      "[22]\ttrain-rmse:0.022676 \n",
      "[23]\ttrain-rmse:0.019458 \n",
      "[24]\ttrain-rmse:0.016709 \n",
      "[25]\ttrain-rmse:0.014229 \n",
      "[26]\ttrain-rmse:0.012308 \n",
      "[27]\ttrain-rmse:0.010388 \n",
      "[28]\ttrain-rmse:0.008857 \n",
      "[29]\ttrain-rmse:0.007589 \n",
      "[30]\ttrain-rmse:0.006573 \n",
      "[31]\ttrain-rmse:0.005641 \n",
      "[32]\ttrain-rmse:0.004836 \n",
      "[33]\ttrain-rmse:0.004214 \n",
      "[34]\ttrain-rmse:0.003642 \n",
      "[35]\ttrain-rmse:0.003179 \n",
      "[36]\ttrain-rmse:0.002651 \n",
      "[37]\ttrain-rmse:0.002169 \n",
      "[38]\ttrain-rmse:0.001871 \n",
      "[39]\ttrain-rmse:0.001619 \n",
      "[40]\ttrain-rmse:0.001372 \n",
      "[41]\ttrain-rmse:0.001146 \n",
      "[42]\ttrain-rmse:0.000981 \n",
      "[43]\ttrain-rmse:0.000828 \n",
      "[44]\ttrain-rmse:0.000776 \n",
      "[45]\ttrain-rmse:0.000746 \n",
      "[46]\ttrain-rmse:0.000714 \n",
      "[47]\ttrain-rmse:0.000644 \n",
      "[48]\ttrain-rmse:0.000594 \n",
      "[49]\ttrain-rmse:0.000593 \n",
      "[50]\ttrain-rmse:0.000592 \n",
      "[51]\ttrain-rmse:0.000592 \n",
      "[52]\ttrain-rmse:0.000592 \n",
      "[53]\ttrain-rmse:0.000591 \n",
      "[54]\ttrain-rmse:0.000591 \n",
      "[55]\ttrain-rmse:0.000591 \n",
      "[56]\ttrain-rmse:0.000591 \n",
      "[57]\ttrain-rmse:0.000591 \n",
      "[58]\ttrain-rmse:0.000591 \n",
      "[59]\ttrain-rmse:0.000591 \n",
      "[60]\ttrain-rmse:0.000591 \n",
      "[61]\ttrain-rmse:0.000591 \n",
      "[62]\ttrain-rmse:0.000591 \n",
      "[63]\ttrain-rmse:0.000591 \n",
      "[64]\ttrain-rmse:0.000591 \n",
      "[65]\ttrain-rmse:0.000591 \n",
      "[66]\ttrain-rmse:0.000591 \n",
      "[67]\ttrain-rmse:0.000591 \n",
      "[68]\ttrain-rmse:0.000591 \n",
      "[69]\ttrain-rmse:0.000591 \n",
      "[70]\ttrain-rmse:0.000591 \n",
      "[71]\ttrain-rmse:0.000591 \n",
      "[72]\ttrain-rmse:0.000591 \n",
      "[73]\ttrain-rmse:0.000592 \n",
      "[74]\ttrain-rmse:0.000592 \n",
      "[75]\ttrain-rmse:0.000592 \n",
      "[76]\ttrain-rmse:0.000592 \n",
      "[77]\ttrain-rmse:0.000592 \n",
      "[78]\ttrain-rmse:0.000592 \n",
      "[79]\ttrain-rmse:0.000592 \n",
      "[80]\ttrain-rmse:0.000592 \n",
      "[81]\ttrain-rmse:0.000592 \n",
      "[82]\ttrain-rmse:0.000592 \n",
      "[83]\ttrain-rmse:0.000592 \n",
      "[84]\ttrain-rmse:0.000592 \n",
      "[85]\ttrain-rmse:0.000592 \n",
      "[86]\ttrain-rmse:0.000592 \n",
      "[87]\ttrain-rmse:0.000592 \n",
      "[88]\ttrain-rmse:0.000592 \n",
      "[89]\ttrain-rmse:0.000592 \n",
      "[90]\ttrain-rmse:0.000592 \n",
      "[91]\ttrain-rmse:0.000592 \n",
      "[92]\ttrain-rmse:0.000592 \n",
      "[93]\ttrain-rmse:0.000592 \n",
      "[94]\ttrain-rmse:0.000592 \n",
      "[95]\ttrain-rmse:0.000592 \n",
      "[96]\ttrain-rmse:0.000592 \n",
      "[97]\ttrain-rmse:0.000592 \n",
      "[98]\ttrain-rmse:0.000592 \n",
      "[99]\ttrain-rmse:0.000592 \n",
      "[100]\ttrain-rmse:0.000592 \n",
      "[1]\ttrain-mlogloss:1.319636 \n",
      "[2]\ttrain-mlogloss:1.060898 \n",
      "[3]\ttrain-mlogloss:0.862051 \n",
      "[4]\ttrain-mlogloss:0.707046 \n",
      "[5]\ttrain-mlogloss:0.595144 \n",
      "[6]\ttrain-mlogloss:0.507133 \n",
      "[7]\ttrain-mlogloss:0.444214 \n",
      "[8]\ttrain-mlogloss:0.382800 \n",
      "[9]\ttrain-mlogloss:0.339984 \n",
      "[10]\ttrain-mlogloss:0.303976 \n",
      "[11]\ttrain-mlogloss:0.269970 \n",
      "[12]\ttrain-mlogloss:0.242883 \n",
      "[13]\ttrain-mlogloss:0.221088 \n",
      "[14]\ttrain-mlogloss:0.201283 \n",
      "[15]\ttrain-mlogloss:0.184531 \n",
      "[16]\ttrain-mlogloss:0.171583 \n",
      "[17]\ttrain-mlogloss:0.159521 \n",
      "[18]\ttrain-mlogloss:0.148436 \n",
      "[19]\ttrain-mlogloss:0.140346 \n",
      "[20]\ttrain-mlogloss:0.133028 \n",
      "[21]\ttrain-mlogloss:0.128814 \n",
      "[22]\ttrain-mlogloss:0.125455 \n",
      "[23]\ttrain-mlogloss:0.121661 \n",
      "[24]\ttrain-mlogloss:0.118858 \n",
      "[25]\ttrain-mlogloss:0.115821 \n",
      "[26]\ttrain-mlogloss:0.113413 \n",
      "[27]\ttrain-mlogloss:0.111029 \n",
      "[28]\ttrain-mlogloss:0.108499 \n",
      "[29]\ttrain-mlogloss:0.106361 \n",
      "[30]\ttrain-mlogloss:0.104300 \n",
      "[31]\ttrain-mlogloss:0.102506 \n",
      "[32]\ttrain-mlogloss:0.101014 \n",
      "[33]\ttrain-mlogloss:0.099453 \n",
      "[34]\ttrain-mlogloss:0.098162 \n",
      "[35]\ttrain-mlogloss:0.096632 \n",
      "[36]\ttrain-mlogloss:0.095577 \n",
      "[37]\ttrain-mlogloss:0.094270 \n",
      "[38]\ttrain-mlogloss:0.093290 \n",
      "[39]\ttrain-mlogloss:0.092112 \n",
      "[40]\ttrain-mlogloss:0.091207 \n",
      "[41]\ttrain-mlogloss:0.089830 \n",
      "[42]\ttrain-mlogloss:0.088505 \n",
      "[43]\ttrain-mlogloss:0.087575 \n",
      "[44]\ttrain-mlogloss:0.086784 \n",
      "[45]\ttrain-mlogloss:0.085982 \n",
      "[46]\ttrain-mlogloss:0.085169 \n",
      "[47]\ttrain-mlogloss:0.084415 \n",
      "[48]\ttrain-mlogloss:0.083672 \n",
      "[49]\ttrain-mlogloss:0.082963 \n",
      "[50]\ttrain-mlogloss:0.082272 \n",
      "[51]\ttrain-mlogloss:0.081594 \n",
      "[52]\ttrain-mlogloss:0.080620 \n",
      "[53]\ttrain-mlogloss:0.080019 \n",
      "[54]\ttrain-mlogloss:0.079434 \n",
      "[55]\ttrain-mlogloss:0.078856 \n",
      "[56]\ttrain-mlogloss:0.078332 \n",
      "[57]\ttrain-mlogloss:0.078026 \n",
      "[58]\ttrain-mlogloss:0.077758 \n",
      "[59]\ttrain-mlogloss:0.077543 \n",
      "[60]\ttrain-mlogloss:0.077332 \n",
      "[61]\ttrain-mlogloss:0.077138 \n",
      "[62]\ttrain-mlogloss:0.076938 \n",
      "[63]\ttrain-mlogloss:0.076746 \n",
      "[64]\ttrain-mlogloss:0.076562 \n",
      "[65]\ttrain-mlogloss:0.076379 \n",
      "[66]\ttrain-mlogloss:0.076185 \n",
      "[67]\ttrain-mlogloss:0.076000 \n",
      "[68]\ttrain-mlogloss:0.075824 \n",
      "[69]\ttrain-mlogloss:0.075642 \n",
      "[70]\ttrain-mlogloss:0.075469 \n",
      "[71]\ttrain-mlogloss:0.075301 \n",
      "[72]\ttrain-mlogloss:0.075127 \n",
      "[73]\ttrain-mlogloss:0.074962 \n",
      "[74]\ttrain-mlogloss:0.074792 \n",
      "[75]\ttrain-mlogloss:0.074633 \n",
      "[76]\ttrain-mlogloss:0.074466 \n",
      "[77]\ttrain-mlogloss:0.074314 \n",
      "[78]\ttrain-mlogloss:0.074163 \n",
      "[79]\ttrain-mlogloss:0.074005 \n",
      "[80]\ttrain-mlogloss:0.073852 \n",
      "[81]\ttrain-mlogloss:0.073705 \n",
      "[82]\ttrain-mlogloss:0.073551 \n",
      "[83]\ttrain-mlogloss:0.073404 \n",
      "[84]\ttrain-mlogloss:0.073256 \n",
      "[85]\ttrain-mlogloss:0.073120 \n",
      "[86]\ttrain-mlogloss:0.072975 \n",
      "[87]\ttrain-mlogloss:0.072840 \n",
      "[88]\ttrain-mlogloss:0.072705 \n",
      "[89]\ttrain-mlogloss:0.072570 \n",
      "[90]\ttrain-mlogloss:0.072435 \n",
      "[91]\ttrain-mlogloss:0.072297 \n",
      "[92]\ttrain-mlogloss:0.072169 \n",
      "[93]\ttrain-mlogloss:0.072045 \n",
      "[94]\ttrain-mlogloss:0.071915 \n",
      "[95]\ttrain-mlogloss:0.071787 \n",
      "[96]\ttrain-mlogloss:0.071664 \n",
      "[97]\ttrain-mlogloss:0.071544 \n",
      "[98]\ttrain-mlogloss:0.071423 \n",
      "[99]\ttrain-mlogloss:0.071297 \n",
      "[100]\ttrain-mlogloss:0.071182 \n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 37, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 2.513514\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 37, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score -1.819158\n",
      "[LightGBM] [Info] Start training from score -1.665008\n",
      "[LightGBM] [Info] Start training from score -2.224624\n",
      "[LightGBM] [Info] Start training from score -2.917771\n",
      "[LightGBM] [Info] Start training from score -0.720546\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    }
   ],
   "source": [
    "models_arima=train_models(train_data,train_label_arima)\n",
    "arimaxgbreg=models_arima$xgbreg\n",
    "arimaxgbcls=models_arima$xgbcls\n",
    "arimalgbreg=models_arima$lgbreg\n",
    "arimalgbcls=models_arima$lgbcls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c73757b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:1.904984 \n",
      "[2]\ttrain-rmse:1.447677 \n",
      "[3]\ttrain-rmse:1.091934 \n",
      "[4]\ttrain-rmse:0.826908 \n",
      "[5]\ttrain-rmse:0.622107 \n",
      "[6]\ttrain-rmse:0.471307 \n",
      "[7]\ttrain-rmse:0.361888 \n",
      "[8]\ttrain-rmse:0.283072 \n",
      "[9]\ttrain-rmse:0.224024 \n",
      "[10]\ttrain-rmse:0.175102 \n",
      "[11]\ttrain-rmse:0.138701 \n",
      "[12]\ttrain-rmse:0.112835 \n",
      "[13]\ttrain-rmse:0.090631 \n",
      "[14]\ttrain-rmse:0.073517 \n",
      "[15]\ttrain-rmse:0.059671 \n",
      "[16]\ttrain-rmse:0.048597 \n",
      "[17]\ttrain-rmse:0.040591 \n",
      "[18]\ttrain-rmse:0.033791 \n",
      "[19]\ttrain-rmse:0.028092 \n",
      "[20]\ttrain-rmse:0.023513 \n",
      "[21]\ttrain-rmse:0.019793 \n",
      "[22]\ttrain-rmse:0.016750 \n",
      "[23]\ttrain-rmse:0.013981 \n",
      "[24]\ttrain-rmse:0.011947 \n",
      "[25]\ttrain-rmse:0.009977 \n",
      "[26]\ttrain-rmse:0.008475 \n",
      "[27]\ttrain-rmse:0.007115 \n",
      "[28]\ttrain-rmse:0.006003 \n",
      "[29]\ttrain-rmse:0.005091 \n",
      "[30]\ttrain-rmse:0.004287 \n",
      "[31]\ttrain-rmse:0.003650 \n",
      "[32]\ttrain-rmse:0.003114 \n",
      "[33]\ttrain-rmse:0.002651 \n",
      "[34]\ttrain-rmse:0.002274 \n",
      "[35]\ttrain-rmse:0.001945 \n",
      "[36]\ttrain-rmse:0.001639 \n",
      "[37]\ttrain-rmse:0.001392 \n",
      "[38]\ttrain-rmse:0.001201 \n",
      "[39]\ttrain-rmse:0.001045 \n",
      "[40]\ttrain-rmse:0.000958 \n",
      "[41]\ttrain-rmse:0.000880 \n",
      "[42]\ttrain-rmse:0.000819 \n",
      "[43]\ttrain-rmse:0.000736 \n",
      "[44]\ttrain-rmse:0.000650 \n",
      "[45]\ttrain-rmse:0.000572 \n",
      "[46]\ttrain-rmse:0.000570 \n",
      "[47]\ttrain-rmse:0.000569 \n",
      "[48]\ttrain-rmse:0.000568 \n",
      "[49]\ttrain-rmse:0.000568 \n",
      "[50]\ttrain-rmse:0.000568 \n",
      "[51]\ttrain-rmse:0.000568 \n",
      "[52]\ttrain-rmse:0.000568 \n",
      "[53]\ttrain-rmse:0.000568 \n",
      "[54]\ttrain-rmse:0.000568 \n",
      "[55]\ttrain-rmse:0.000568 \n",
      "[56]\ttrain-rmse:0.000568 \n",
      "[57]\ttrain-rmse:0.000568 \n",
      "[58]\ttrain-rmse:0.000568 \n",
      "[59]\ttrain-rmse:0.000568 \n",
      "[60]\ttrain-rmse:0.000568 \n",
      "[61]\ttrain-rmse:0.000568 \n",
      "[62]\ttrain-rmse:0.000568 \n",
      "[63]\ttrain-rmse:0.000568 \n",
      "[64]\ttrain-rmse:0.000568 \n",
      "[65]\ttrain-rmse:0.000568 \n",
      "[66]\ttrain-rmse:0.000568 \n",
      "[67]\ttrain-rmse:0.000568 \n",
      "[68]\ttrain-rmse:0.000568 \n",
      "[69]\ttrain-rmse:0.000568 \n",
      "[70]\ttrain-rmse:0.000568 \n",
      "[71]\ttrain-rmse:0.000568 \n",
      "[72]\ttrain-rmse:0.000568 \n",
      "[73]\ttrain-rmse:0.000568 \n",
      "[74]\ttrain-rmse:0.000568 \n",
      "[75]\ttrain-rmse:0.000568 \n",
      "[76]\ttrain-rmse:0.000568 \n",
      "[77]\ttrain-rmse:0.000568 \n",
      "[78]\ttrain-rmse:0.000568 \n",
      "[79]\ttrain-rmse:0.000568 \n",
      "[80]\ttrain-rmse:0.000568 \n",
      "[81]\ttrain-rmse:0.000568 \n",
      "[82]\ttrain-rmse:0.000568 \n",
      "[83]\ttrain-rmse:0.000568 \n",
      "[84]\ttrain-rmse:0.000568 \n",
      "[85]\ttrain-rmse:0.000568 \n",
      "[86]\ttrain-rmse:0.000568 \n",
      "[87]\ttrain-rmse:0.000568 \n",
      "[88]\ttrain-rmse:0.000568 \n",
      "[89]\ttrain-rmse:0.000568 \n",
      "[90]\ttrain-rmse:0.000568 \n",
      "[91]\ttrain-rmse:0.000568 \n",
      "[92]\ttrain-rmse:0.000568 \n",
      "[93]\ttrain-rmse:0.000568 \n",
      "[94]\ttrain-rmse:0.000568 \n",
      "[95]\ttrain-rmse:0.000568 \n",
      "[96]\ttrain-rmse:0.000568 \n",
      "[97]\ttrain-rmse:0.000568 \n",
      "[98]\ttrain-rmse:0.000568 \n",
      "[99]\ttrain-rmse:0.000568 \n",
      "[100]\ttrain-rmse:0.000568 \n",
      "[1]\ttrain-mlogloss:1.318528 \n",
      "[2]\ttrain-mlogloss:1.085308 \n",
      "[3]\ttrain-mlogloss:0.887063 \n",
      "[4]\ttrain-mlogloss:0.735778 \n",
      "[5]\ttrain-mlogloss:0.619119 \n",
      "[6]\ttrain-mlogloss:0.521203 \n",
      "[7]\ttrain-mlogloss:0.443025 \n",
      "[8]\ttrain-mlogloss:0.387568 \n",
      "[9]\ttrain-mlogloss:0.340955 \n",
      "[10]\ttrain-mlogloss:0.298713 \n",
      "[11]\ttrain-mlogloss:0.266153 \n",
      "[12]\ttrain-mlogloss:0.238820 \n",
      "[13]\ttrain-mlogloss:0.216358 \n",
      "[14]\ttrain-mlogloss:0.196097 \n",
      "[15]\ttrain-mlogloss:0.182389 \n",
      "[16]\ttrain-mlogloss:0.170108 \n",
      "[17]\ttrain-mlogloss:0.157527 \n",
      "[18]\ttrain-mlogloss:0.150663 \n",
      "[19]\ttrain-mlogloss:0.142413 \n",
      "[20]\ttrain-mlogloss:0.135384 \n",
      "[21]\ttrain-mlogloss:0.128403 \n",
      "[22]\ttrain-mlogloss:0.123955 \n",
      "[23]\ttrain-mlogloss:0.118865 \n",
      "[24]\ttrain-mlogloss:0.114300 \n",
      "[25]\ttrain-mlogloss:0.111208 \n",
      "[26]\ttrain-mlogloss:0.109072 \n",
      "[27]\ttrain-mlogloss:0.106336 \n",
      "[28]\ttrain-mlogloss:0.104474 \n",
      "[29]\ttrain-mlogloss:0.102329 \n",
      "[30]\ttrain-mlogloss:0.100985 \n",
      "[31]\ttrain-mlogloss:0.099653 \n",
      "[32]\ttrain-mlogloss:0.098432 \n",
      "[33]\ttrain-mlogloss:0.097311 \n",
      "[34]\ttrain-mlogloss:0.096215 \n",
      "[35]\ttrain-mlogloss:0.095278 \n",
      "[36]\ttrain-mlogloss:0.094386 \n",
      "[37]\ttrain-mlogloss:0.093566 \n",
      "[38]\ttrain-mlogloss:0.092797 \n",
      "[39]\ttrain-mlogloss:0.092051 \n",
      "[40]\ttrain-mlogloss:0.091353 \n",
      "[41]\ttrain-mlogloss:0.090663 \n",
      "[42]\ttrain-mlogloss:0.090057 \n",
      "[43]\ttrain-mlogloss:0.089586 \n",
      "[44]\ttrain-mlogloss:0.089122 \n",
      "[45]\ttrain-mlogloss:0.088701 \n",
      "[46]\ttrain-mlogloss:0.088283 \n",
      "[47]\ttrain-mlogloss:0.087871 \n",
      "[48]\ttrain-mlogloss:0.087471 \n",
      "[49]\ttrain-mlogloss:0.087077 \n",
      "[50]\ttrain-mlogloss:0.086725 \n",
      "[51]\ttrain-mlogloss:0.086396 \n",
      "[52]\ttrain-mlogloss:0.086062 \n",
      "[53]\ttrain-mlogloss:0.085709 \n",
      "[54]\ttrain-mlogloss:0.085398 \n",
      "[55]\ttrain-mlogloss:0.085065 \n",
      "[56]\ttrain-mlogloss:0.084760 \n",
      "[57]\ttrain-mlogloss:0.084456 \n",
      "[58]\ttrain-mlogloss:0.084148 \n",
      "[59]\ttrain-mlogloss:0.083848 \n",
      "[60]\ttrain-mlogloss:0.083547 \n",
      "[61]\ttrain-mlogloss:0.083259 \n",
      "[62]\ttrain-mlogloss:0.082981 \n",
      "[63]\ttrain-mlogloss:0.082698 \n",
      "[64]\ttrain-mlogloss:0.082421 \n",
      "[65]\ttrain-mlogloss:0.082150 \n",
      "[66]\ttrain-mlogloss:0.081885 \n",
      "[67]\ttrain-mlogloss:0.081620 \n",
      "[68]\ttrain-mlogloss:0.081376 \n",
      "[69]\ttrain-mlogloss:0.081121 \n",
      "[70]\ttrain-mlogloss:0.080868 \n",
      "[71]\ttrain-mlogloss:0.080633 \n",
      "[72]\ttrain-mlogloss:0.080381 \n",
      "[73]\ttrain-mlogloss:0.080150 \n",
      "[74]\ttrain-mlogloss:0.079914 \n",
      "[75]\ttrain-mlogloss:0.079679 \n",
      "[76]\ttrain-mlogloss:0.079458 \n",
      "[77]\ttrain-mlogloss:0.079229 \n",
      "[78]\ttrain-mlogloss:0.079018 \n",
      "[79]\ttrain-mlogloss:0.078808 \n",
      "[80]\ttrain-mlogloss:0.078588 \n",
      "[81]\ttrain-mlogloss:0.078371 \n",
      "[82]\ttrain-mlogloss:0.078155 \n",
      "[83]\ttrain-mlogloss:0.077961 \n",
      "[84]\ttrain-mlogloss:0.077760 \n",
      "[85]\ttrain-mlogloss:0.077568 \n",
      "[86]\ttrain-mlogloss:0.077382 \n",
      "[87]\ttrain-mlogloss:0.077191 \n",
      "[88]\ttrain-mlogloss:0.077013 \n",
      "[89]\ttrain-mlogloss:0.076827 \n",
      "[90]\ttrain-mlogloss:0.076654 \n",
      "[91]\ttrain-mlogloss:0.076483 \n",
      "[92]\ttrain-mlogloss:0.076303 \n",
      "[93]\ttrain-mlogloss:0.076139 \n",
      "[94]\ttrain-mlogloss:0.075966 \n",
      "[95]\ttrain-mlogloss:0.075806 \n",
      "[96]\ttrain-mlogloss:0.075647 \n",
      "[97]\ttrain-mlogloss:0.075484 \n",
      "[98]\ttrain-mlogloss:0.075331 \n",
      "[99]\ttrain-mlogloss:0.075171 \n",
      "[100]\ttrain-mlogloss:0.075022 \n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 37, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 2.432432\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 37, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score -1.665008\n",
      "[LightGBM] [Info] Start training from score -1.819158\n",
      "[LightGBM] [Info] Start training from score -2.224624\n",
      "[LightGBM] [Info] Start training from score -2.224624\n",
      "[LightGBM] [Info] Start training from score -0.838329\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    }
   ],
   "source": [
    "models_nnetar=train_models(train_data,train_label_nnetar)\n",
    "nnetarxgbreg=models_nnetar$xgbreg\n",
    "nnetarxgbcls=models_nnetar$xgbcls\n",
    "nnetarlgbreg=models_nnetar$lgbreg\n",
    "nnetarlgbcls=models_nnetar$lgbcls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489cbecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76218c34",
   "metadata": {},
   "source": [
    "## 预测与输出误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7a8f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldatalgb <- lgb.Dataset(data = as.matrix(data_features))\n",
    "alldataxgb <- xgb.DMatrix(data = as.matrix(data_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66aa6432",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbcls_change<-function(lgbcls,ll)\n",
    "    {\n",
    "    lgbclsm=matrix(lgbcls,5,ll)\n",
    "    lgbclsr=matrix(0,ll,1)\n",
    "    for(i in 1:ll)\n",
    "        {\n",
    "        lgbclsr[i,]=which.max(lgbclsm[,i])\n",
    "\n",
    "    }\n",
    "    return(lgbclsr)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7409a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbregets=predict(etsxgbreg,alldataxgb)\n",
    "xgbclsets=predict(etsxgbcls,alldataxgb)\n",
    "lgbregets=predict(etslgbreg,as.matrix(data_features))\n",
    "lgbclsets=predict(etslgbcls,as.matrix(data_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c6aca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbregthetaf=predict(thetafxgbreg,alldataxgb)\n",
    "xgbclsthetaf=predict(thetafxgbcls,alldataxgb)\n",
    "lgbregthetaf=predict(thetaflgbreg,as.matrix(data_features))\n",
    "lgbclsthetaf=predict(thetaflgbcls,as.matrix(data_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6f8fa483",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbregarima=predict(arimaxgbreg,alldataxgb)\n",
    "xgbclsarima=predict(arimaxgbcls,alldataxgb)\n",
    "lgbregarima=predict(arimalgbreg,as.matrix(data_features))\n",
    "lgbclsarima=predict(arimalgbcls,as.matrix(data_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f11c8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbregnnetar=predict(nnetarxgbreg,alldataxgb)\n",
    "xgbclsnnetar=predict(nnetarxgbcls,alldataxgb)\n",
    "lgbregnnetar=predict(nnetarlgbreg,as.matrix(data_features))\n",
    "lgbclsnnetar=predict(nnetarlgbcls,as.matrix(data_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef4d9884",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbclsetsr=lgbcls_change(lgbclsets,ll)\n",
    "lgbclsthetafr=lgbcls_change(lgbclsthetaf,ll)\n",
    "lgbclsarimar=lgbcls_change(lgbclsarima,ll)\n",
    "lgbclsnnetarr=lgbcls_change(lgbclsnnetar,ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8c6dbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "round5=function(x)\n",
    "    {\n",
    "    l=round(x)\n",
    "    for(i in 1:length(l))\n",
    "    {\n",
    "    if(l[i]>5)\n",
    "        {\n",
    "        l[i]=5\n",
    "    }\n",
    "    if(l[i]<1)\n",
    "    {\n",
    "        l[i]=1\n",
    "    }\n",
    "}\n",
    "    l\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb0b589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ets_pr=matrix(0,ll,4)\n",
    "ets_pr[,1]=round5(xgbregets+1)\n",
    "ets_pr[,2]=xgbclsets+1\n",
    "ets_pr[,3]=round5(lgbregets+1)\n",
    "ets_pr[,4]=lgbclsetsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a348e5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1e2fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetaf_pr=matrix(0,ll,4)\n",
    "thetaf_pr[,1]=round5(xgbregthetaf+1)\n",
    "thetaf_pr[,2]=xgbclsthetaf+1\n",
    "thetaf_pr[,3]=round5(lgbregthetaf+1)\n",
    "thetaf_pr[,4]=lgbclsthetafr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3ae1e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_pr=matrix(0,ll,4)\n",
    "arima_pr[,1]=round5(xgbregarima+1)\n",
    "arima_pr[,2]=xgbclsarima+1\n",
    "arima_pr[,3]=round5(lgbregarima+1)\n",
    "arima_pr[,4]=lgbclsarimar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "330991c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnetar_pr=matrix(0,ll,4)\n",
    "nnetar_pr[,1]=round5(xgbregnnetar+1)\n",
    "nnetar_pr[,2]=xgbclsthetaf+1\n",
    "nnetar_pr[,3]=round5(lgbregnnetar+1)\n",
    "nnetar_pr[,4]=lgbclsnnetarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2082231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanpre=function(pred_array,opt_pr,h,testindex)\n",
    "    {\n",
    "    data_length=length(testindex)\n",
    "    meanpreh=matrix(0,data_length,h)\n",
    "    for (i in 1:data_length){\n",
    "    index=testindex[i]\n",
    "    loc=opt_pr[index]\n",
    "    predh=pred_array[index,loc,,]\n",
    "    predh=unique(predh)\n",
    "    meanpreh[i,]=apply(predh,2,mean)\n",
    "}\n",
    "    return(meanpreh)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce4a535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predres=function(pred_matrix,data,real_data,opt_pr,lengthmatrix,h,testindex)\n",
    "    {\n",
    "    data_length=length(testindex)\n",
    "    pred_res=matrix(0,data_length,6)\n",
    "    model=ets(data[[1]])\n",
    "    fore_l=forecast(model,h=h)\n",
    "    freq=frequency(data[[1]])\n",
    "    for (i in 1:data_length){\n",
    "    index=testindex[i]\n",
    "    loc=opt_pr[index]\n",
    "    start=lengthmatrix[i,loc]\n",
    "    y_all=data[[index]]\n",
    "    y=y_all[start:length(y_all)]\n",
    "    fore_l$x=ts(y,frequency=freq,end=end(y_all))\n",
    "    real=real_data[[index]]\n",
    "    fore_l$mean=ts(pred_matrix[i,],start=start(real),frequency=freq)\n",
    "    res=accuracy(fore_l,real)\n",
    "    pred_res[i,]=res[2,1:6]\n",
    "    }\n",
    "    return(pred_res)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69aa85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "testindex=c(1:ll)[index==2]\n",
    "lengthtest=length5[testindex,]\n",
    "etsxgbcls=meanpre(predhets,ets_pr[,1],hh,testindex)\n",
    "etsxgbreg=meanpre(predhets,ets_pr[,2],hh,testindex)\n",
    "etslgbcls=meanpre(predhets,ets_pr[,3],hh,testindex)\n",
    "etslgbreg=meanpre(predhets,ets_pr[,4],hh,testindex)\n",
    "etsxgbclsres=predres(etsxgbcls,data_tstrain,y_real,ets_pr[,1],lengthtest,hh,testindex)\n",
    "etsxgbregres=predres(etsxgbreg,data_tstrain,y_real,ets_pr[,2],lengthtest,hh,testindex)\n",
    "etslgbclsres=predres(etslgbcls,data_tstrain,y_real,ets_pr[,3],lengthtest,hh,testindex)\n",
    "etslgbregres=predres(etslgbreg,data_tstrain,y_real,ets_pr[,4],lengthtest,hh,testindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8a741bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetafxgbcls=meanpre(predhthetaf,thetaf_pr[,1],hh,testindex)\n",
    "thetafxgbreg=meanpre(predhthetaf,thetaf_pr[,2],hh,testindex)\n",
    "thetaflgbcls=meanpre(predhthetaf,thetaf_pr[,3],hh,testindex)\n",
    "thetaflgbreg=meanpre(predhthetaf,thetaf_pr[,4],hh,testindex)\n",
    "thetafxgbclsres=predres(thetafxgbcls,data_tstrain,y_real,thetaf_pr[,1],lengthtest,hh,testindex)\n",
    "thetafxgbregres=predres(thetafxgbreg,data_tstrain,y_real,thetaf_pr[,2],lengthtest,hh,testindex)\n",
    "thetaflgbclsres=predres(thetaflgbcls,data_tstrain,y_real,thetaf_pr[,3],lengthtest,hh,testindex)\n",
    "thetaflgbregres=predres(thetaflgbreg,data_tstrain,y_real,thetaf_pr[,4],lengthtest,hh,testindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7c38fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arimaxgbcls=meanpre(predharima,arima_pr[,1],hh,testindex)\n",
    "arimaxgbreg=meanpre(predharima,arima_pr[,2],hh,testindex)\n",
    "arimalgbcls=meanpre(predharima,arima_pr[,3],hh,testindex)\n",
    "arimalgbreg=meanpre(predharima,arima_pr[,4],hh,testindex)\n",
    "arimaxgbclsres=predres(arimaxgbcls,data_tstrain,y_real,ets_pr[,1],lengthtest,hh,testindex)\n",
    "arimaxgbregres=predres(arimaxgbreg,data_tstrain,y_real,ets_pr[,2],lengthtest,hh,testindex)\n",
    "arimalgbclsres=predres(arimalgbcls,data_tstrain,y_real,ets_pr[,3],lengthtest,hh,testindex)\n",
    "arimalgbregres=predres(arimalgbreg,data_tstrain,y_real,ets_pr[,4],lengthtest,hh,testindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5039104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnetarxgbcls=meanpre(predhnnetar,nnetar_pr[,1],hh,testindex)\n",
    "nnetarxgbreg=meanpre(predhnnetar,nnetar_pr[,2],hh,testindex)\n",
    "nnetarlgbcls=meanpre(predhnnetar,nnetar_pr[,3],hh,testindex)\n",
    "nnetarlgbreg=meanpre(predhnnetar,nnetar_pr[,4],hh,testindex)\n",
    "nnetarxgbclsres=predres(nnetarxgbcls,data_tstrain,y_real,nnetar_pr[,1],lengthtest,hh,testindex)\n",
    "nnetarxgbregres=predres(nnetarxgbreg,data_tstrain,y_real,nnetar_pr[,2],lengthtest,hh,testindex)\n",
    "nnetarlgbclsres=predres(nnetarlgbcls,data_tstrain,y_real,nnetar_pr[,3],lengthtest,hh,testindex)\n",
    "nnetarlgbregres=predres(nnetarlgbreg,data_tstrain,y_real,nnetar_pr[,4],lengthtest,hh,testindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01191a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1.72462664848902</li><li>2.21238152789548</li><li>1.95747263880141</li><li>1.75836360292446</li><li>1.99853623847232</li><li>1.56542355169424</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.72462664848902\n",
       "\\item 2.21238152789548\n",
       "\\item 1.95747263880141\n",
       "\\item 1.75836360292446\n",
       "\\item 1.99853623847232\n",
       "\\item 1.56542355169424\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.72462664848902\n",
       "2. 2.21238152789548\n",
       "3. 1.95747263880141\n",
       "4. 1.75836360292446\n",
       "5. 1.99853623847232\n",
       "6. 1.56542355169424\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.724627 2.212382 1.957473 1.758364 1.998536 1.565424"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1.35852655152662</li><li>2.43280986207057</li><li>2.09161490806065</li><li>1.39527196431892</li><li>2.15026688562213</li><li>1.35942982686322</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.35852655152662\n",
       "\\item 2.43280986207057\n",
       "\\item 2.09161490806065\n",
       "\\item 1.39527196431892\n",
       "\\item 2.15026688562213\n",
       "\\item 1.35942982686322\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.35852655152662\n",
       "2. 2.43280986207057\n",
       "3. 2.09161490806065\n",
       "4. 1.39527196431892\n",
       "5. 2.15026688562213\n",
       "6. 1.35942982686322\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.358527 2.432810 2.091615 1.395272 2.150267 1.359430"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1.47878535232052</li><li>2.48408019106734</li><li>2.12743512401249</li><li>1.52009846739165</li><li>2.18872555977279</li><li>1.18671592003394</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.47878535232052\n",
       "\\item 2.48408019106734\n",
       "\\item 2.12743512401249\n",
       "\\item 1.52009846739165\n",
       "\\item 2.18872555977279\n",
       "\\item 1.18671592003394\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.47878535232052\n",
       "2. 2.48408019106734\n",
       "3. 2.12743512401249\n",
       "4. 1.52009846739165\n",
       "5. 2.18872555977279\n",
       "6. 1.18671592003394\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.478785 2.484080 2.127435 1.520098 2.188726 1.186716"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1.29902893099459</li><li>2.41476857778373</li><li>2.07523355553806</li><li>1.33585618285531</li><li>2.13457677784127</li><li>1.71024392000466</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.29902893099459\n",
       "\\item 2.41476857778373\n",
       "\\item 2.07523355553806\n",
       "\\item 1.33585618285531\n",
       "\\item 2.13457677784127\n",
       "\\item 1.71024392000466\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.29902893099459\n",
       "2. 2.41476857778373\n",
       "3. 2.07523355553806\n",
       "4. 1.33585618285531\n",
       "5. 2.13457677784127\n",
       "6. 1.71024392000466\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.299029 2.414769 2.075234 1.335856 2.134577 1.710244"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1.24290345795419</li><li>2.12097258630365</li><li>1.83701893406068</li><li>1.27505807880498</li><li>1.88690559293073</li><li>1.61005293517732</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.24290345795419\n",
       "\\item 2.12097258630365\n",
       "\\item 1.83701893406068\n",
       "\\item 1.27505807880498\n",
       "\\item 1.88690559293073\n",
       "\\item 1.61005293517732\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.24290345795419\n",
       "2. 2.12097258630365\n",
       "3. 1.83701893406068\n",
       "4. 1.27505807880498\n",
       "5. 1.88690559293073\n",
       "6. 1.61005293517732\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.242903 2.120973 1.837019 1.275058 1.886906 1.610053"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apply(predets[,1,1,],2,mean)\n",
    "apply(etsxgbclsres,2,mean)\n",
    "apply(etsxgbregres,2,mean)\n",
    "apply(etslgbclsres,2,mean)\n",
    "apply(etslgbregres,2,mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6116d097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1.25557823136432</li><li>1.60558588043718</li><li>1.40749121698375</li><li>1.27599020350534</li><li>1.43354256593085</li><li>1.11113688892303</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.25557823136432\n",
       "\\item 1.60558588043718\n",
       "\\item 1.40749121698375\n",
       "\\item 1.27599020350534\n",
       "\\item 1.43354256593085\n",
       "\\item 1.11113688892303\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.25557823136432\n",
       "2. 1.60558588043718\n",
       "3. 1.40749121698375\n",
       "4. 1.27599020350534\n",
       "5. 1.43354256593085\n",
       "6. 1.11113688892303\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.255578 1.605586 1.407491 1.275990 1.433543 1.111137"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1.14584998210976</li><li>1.74796751461765</li><li>1.5174141637225</li><li>1.17386429434176</li><li>1.55653938421751</li><li>1.15429025471657</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.14584998210976\n",
       "\\item 1.74796751461765\n",
       "\\item 1.5174141637225\n",
       "\\item 1.17386429434176\n",
       "\\item 1.55653938421751\n",
       "\\item 1.15429025471657\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.14584998210976\n",
       "2. 1.74796751461765\n",
       "3. 1.5174141637225\n",
       "4. 1.17386429434176\n",
       "5. 1.55653938421751\n",
       "6. 1.15429025471657\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.145850 1.747968 1.517414 1.173864 1.556539 1.154290"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1.27195180749645</li><li>1.88439828403992</li><li>1.64599648852222</li><li>1.30048998992657</li><li>1.68508918393936</li><li>1.07857535072009</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.27195180749645\n",
       "\\item 1.88439828403992\n",
       "\\item 1.64599648852222\n",
       "\\item 1.30048998992657\n",
       "\\item 1.68508918393936\n",
       "\\item 1.07857535072009\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.27195180749645\n",
       "2. 1.88439828403992\n",
       "3. 1.64599648852222\n",
       "4. 1.30048998992657\n",
       "5. 1.68508918393936\n",
       "6. 1.07857535072009\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.271952 1.884398 1.645996 1.300490 1.685089 1.078575"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-0.177731870770126</li><li>2.03243418719885</li><li>1.85151396463414</li><li>-0.21711100127682</li><li>1.91167037337928</li><li>1.57233166390236</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.177731870770126\n",
       "\\item 2.03243418719885\n",
       "\\item 1.85151396463414\n",
       "\\item -0.21711100127682\n",
       "\\item 1.91167037337928\n",
       "\\item 1.57233166390236\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.177731870770126\n",
       "2. 2.03243418719885\n",
       "3. 1.85151396463414\n",
       "4. -0.21711100127682\n",
       "5. 1.91167037337928\n",
       "6. 1.57233166390236\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.1777319  2.0324342  1.8515140 -0.2171110  1.9116704  1.5723317"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.883444489222395</li><li>1.41338956902878</li><li>1.22263642604589</li><li>0.900733236845268</li><li>1.25007596049332</li><li>1.10178571604602</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.883444489222395\n",
       "\\item 1.41338956902878\n",
       "\\item 1.22263642604589\n",
       "\\item 0.900733236845268\n",
       "\\item 1.25007596049332\n",
       "\\item 1.10178571604602\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.883444489222395\n",
       "2. 1.41338956902878\n",
       "3. 1.22263642604589\n",
       "4. 0.900733236845268\n",
       "5. 1.25007596049332\n",
       "6. 1.10178571604602\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.8834445 1.4133896 1.2226364 0.9007332 1.2500760 1.1017857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apply(predthetaf[,1,1,],2,mean)\n",
    "apply(thetafxgbclsres,2,mean)\n",
    "apply(thetafxgbregres,2,mean)\n",
    "apply(thetaflgbclsres,2,mean)\n",
    "apply(thetaflgbregres,2,mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f23d5dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1.25557823136432</li><li>1.60558588043718</li><li>1.40749121698375</li><li>1.27599020350534</li><li>1.43354256593085</li><li>1.11113688892303</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.25557823136432\n",
       "\\item 1.60558588043718\n",
       "\\item 1.40749121698375\n",
       "\\item 1.27599020350534\n",
       "\\item 1.43354256593085\n",
       "\\item 1.11113688892303\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.25557823136432\n",
       "2. 1.60558588043718\n",
       "3. 1.40749121698375\n",
       "4. 1.27599020350534\n",
       "5. 1.43354256593085\n",
       "6. 1.11113688892303\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.255578 1.605586 1.407491 1.275990 1.433543 1.111137"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1.14584998210976</li><li>1.74796751461765</li><li>1.5174141637225</li><li>1.17386429434176</li><li>1.55653938421751</li><li>0.998737459276866</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.14584998210976\n",
       "\\item 1.74796751461765\n",
       "\\item 1.5174141637225\n",
       "\\item 1.17386429434176\n",
       "\\item 1.55653938421751\n",
       "\\item 0.998737459276866\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.14584998210976\n",
       "2. 1.74796751461765\n",
       "3. 1.5174141637225\n",
       "4. 1.17386429434176\n",
       "5. 1.55653938421751\n",
       "6. 0.998737459276866\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.1458500 1.7479675 1.5174142 1.1738643 1.5565394 0.9987375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1.27195180749645</li><li>1.88439828403992</li><li>1.64599648852222</li><li>1.30048998992657</li><li>1.68508918393936</li><li>0.92461901190122</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.27195180749645\n",
       "\\item 1.88439828403992\n",
       "\\item 1.64599648852222\n",
       "\\item 1.30048998992657\n",
       "\\item 1.68508918393936\n",
       "\\item 0.92461901190122\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.27195180749645\n",
       "2. 1.88439828403992\n",
       "3. 1.64599648852222\n",
       "4. 1.30048998992657\n",
       "5. 1.68508918393936\n",
       "6. 0.92461901190122\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.271952 1.884398 1.645996 1.300490 1.685089 0.924619"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-0.177731870770126</li><li>2.03243418719885</li><li>1.85151396463414</li><li>-0.21711100127682</li><li>1.91167037337928</li><li>1.57233166390236</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.177731870770126\n",
       "\\item 2.03243418719885\n",
       "\\item 1.85151396463414\n",
       "\\item -0.21711100127682\n",
       "\\item 1.91167037337928\n",
       "\\item 1.57233166390236\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.177731870770126\n",
       "2. 2.03243418719885\n",
       "3. 1.85151396463414\n",
       "4. -0.21711100127682\n",
       "5. 1.91167037337928\n",
       "6. 1.57233166390236\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.1777319  2.0324342  1.8515140 -0.2171110  1.9116704  1.5723317"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.883444489222395</li><li>1.41338956902878</li><li>1.22263642604589</li><li>0.900733236845268</li><li>1.25007596049332</li><li>1.10178571604602</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.883444489222395\n",
       "\\item 1.41338956902878\n",
       "\\item 1.22263642604589\n",
       "\\item 0.900733236845268\n",
       "\\item 1.25007596049332\n",
       "\\item 1.10178571604602\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.883444489222395\n",
       "2. 1.41338956902878\n",
       "3. 1.22263642604589\n",
       "4. 0.900733236845268\n",
       "5. 1.25007596049332\n",
       "6. 1.10178571604602\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.8834445 1.4133896 1.2226364 0.9007332 1.2500760 1.1017857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apply(predarima[,1,1,],2,mean)\n",
    "apply(arimaxgbclsres,2,mean)\n",
    "apply(arimaxgbregres,2,mean)\n",
    "apply(arimalgbclsres,2,mean)\n",
    "apply(arimalgbregres,2,mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2e4957b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.685964798531064</li><li>1.72574361678204</li><li>1.48876679454696</li><li>0.678934543064283</li><li>1.51899854146154</li><li>1.12033382282429</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.685964798531064\n",
       "\\item 1.72574361678204\n",
       "\\item 1.48876679454696\n",
       "\\item 0.678934543064283\n",
       "\\item 1.51899854146154\n",
       "\\item 1.12033382282429\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.685964798531064\n",
       "2. 1.72574361678204\n",
       "3. 1.48876679454696\n",
       "4. 0.678934543064283\n",
       "5. 1.51899854146154\n",
       "6. 1.12033382282429\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.6859648 1.7257436 1.4887668 0.6789345 1.5189985 1.1203338"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-0.862951979291545</li><li>1.87615920609534</li><li>1.5814980717778</li><li>-0.893363539700555</li><li>1.62456848419328</li><li>1.18762339326536</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.862951979291545\n",
       "\\item 1.87615920609534\n",
       "\\item 1.5814980717778\n",
       "\\item -0.893363539700555\n",
       "\\item 1.62456848419328\n",
       "\\item 1.18762339326536\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.862951979291545\n",
       "2. 1.87615920609534\n",
       "3. 1.5814980717778\n",
       "4. -0.893363539700555\n",
       "5. 1.62456848419328\n",
       "6. 1.18762339326536\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.8629520  1.8761592  1.5814981 -0.8933635  1.6245685  1.1876234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-0.460627114217512</li><li>1.43502959732916</li><li>1.18423650550746</li><li>-0.484229678342951</li><li>1.21659652936541</li><li>0.768388386682734</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.460627114217512\n",
       "\\item 1.43502959732916\n",
       "\\item 1.18423650550746\n",
       "\\item -0.484229678342951\n",
       "\\item 1.21659652936541\n",
       "\\item 0.768388386682734\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.460627114217512\n",
       "2. 1.43502959732916\n",
       "3. 1.18423650550746\n",
       "4. -0.484229678342951\n",
       "5. 1.21659652936541\n",
       "6. 0.768388386682734\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.4606271  1.4350296  1.1842365 -0.4842297  1.2165965  0.7683884"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-0.385455516499363</li><li>1.49973896628473</li><li>1.24230516527404</li><li>-0.409530362331231</li><li>1.27926237329906</li><li>0.925262345309793</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.385455516499363\n",
       "\\item 1.49973896628473\n",
       "\\item 1.24230516527404\n",
       "\\item -0.409530362331231\n",
       "\\item 1.27926237329906\n",
       "\\item 0.925262345309793\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.385455516499363\n",
       "2. 1.49973896628473\n",
       "3. 1.24230516527404\n",
       "4. -0.409530362331231\n",
       "5. 1.27926237329906\n",
       "6. 0.925262345309793\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.3854555  1.4997390  1.2423052 -0.4095304  1.2792624  0.9252623"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-0.275187300428261</li><li>1.37041680587885</li><li>1.13816372065096</li><li>-0.291616824672383</li><li>1.16927521110224</li><li>0.993839538998499</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.275187300428261\n",
       "\\item 1.37041680587885\n",
       "\\item 1.13816372065096\n",
       "\\item -0.291616824672383\n",
       "\\item 1.16927521110224\n",
       "\\item 0.993839538998499\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.275187300428261\n",
       "2. 1.37041680587885\n",
       "3. 1.13816372065096\n",
       "4. -0.291616824672383\n",
       "5. 1.16927521110224\n",
       "6. 0.993839538998499\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.2751873  1.3704168  1.1381637 -0.2916168  1.1692752  0.9938395"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apply(prednnetar[,1,1,],2,mean)\n",
    "apply(nnetarxgbclsres,2,mean)\n",
    "apply(nnetarxgbregres,2,mean)\n",
    "apply(nnetarlgbclsres,2,mean)\n",
    "apply(nnetarlgbregres,2,mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a23a643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alltest=matrix(0,20,6)\n",
    "alltest[1,]=apply(predets[,1,1,],2,mean)\n",
    "alltest[2,]=apply(etsxgbclsres,2,mean)\n",
    "alltest[3,]=apply(etsxgbregres,2,mean)\n",
    "alltest[4,]=apply(etslgbclsres,2,mean)\n",
    "alltest[5,]=apply(etslgbregres,2,mean)\n",
    "\n",
    "alltest[6,]=apply(predthetaf[,1,1,],2,mean)\n",
    "alltest[7,]=apply(thetafxgbclsres,2,mean)\n",
    "alltest[8,]=apply(thetafxgbregres,2,mean)\n",
    "alltest[9,]=apply(thetaflgbclsres,2,mean)\n",
    "alltest[10,]=apply(thetaflgbregres,2,mean)\n",
    "\n",
    "alltest[11,]=apply(predarima[,1,1,],2,mean)\n",
    "alltest[12,]=apply(arimaxgbclsres,2,mean)\n",
    "alltest[13,]=apply(arimaxgbregres,2,mean)\n",
    "alltest[14,]=apply(arimalgbclsres,2,mean)\n",
    "alltest[15,]=apply(arimalgbregres,2,mean)\n",
    "\n",
    "alltest[16,]=apply(prednnetar[,1,1,],2,mean)\n",
    "alltest[17,]=apply(nnetarxgbclsres,2,mean)\n",
    "alltest[18,]=apply(nnetarxgbregres,2,mean)\n",
    "alltest[19,]=apply(nnetarlgbclsres,2,mean)\n",
    "alltest[20,]=apply(nnetarlgbregres,2,mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e6c72a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(alltest,'Imports_gratis_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2333e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be0aa17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
